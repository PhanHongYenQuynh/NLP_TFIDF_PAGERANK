{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37205065",
   "metadata": {},
   "source": [
    "# TÓM TẮT VĂN BẢN BẰNG TF-IDF VÀ TEXTRANK\n",
    "\n",
    "## Các bước thực hiện:\n",
    "\n",
    "1. Đọc file XML và lưu vào Word (input.docx)\n",
    "2. Biểu diễn các câu bằng vector TF-IDF\n",
    "3. Tính độ tương đồng cosine giữa các câu\n",
    "4. Mô hình hóa văn bản dưới dạng đồ thị\n",
    "5. Áp dụng thuật toán TextRank\n",
    "6. Lấy 10% câu có điểm cao nhất\n",
    "7. Lưu bản tóm tắt vào Word (output_summary.docx)\n",
    "8. Đọc DUC_SUM reference và lưu vào Word (Test_DUC_SUM.docx)\n",
    "9. So sánh và đánh giá bằng ROUGE\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d9712",
   "metadata": {},
   "source": [
    "## 1. Setup và Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d366a313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python-docx đã được cài đặt\n",
      "numpy đã sẵn sàng\n",
      "Tất cả thư viện đã được import thành công!\n",
      "Notebook sẵn sàng để chạy tóm tắt văn bản\n"
     ]
    }
   ],
   "source": [
    "# Import các thư viện cơ bản\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import xml.etree.ElementTree as ET\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import spacy\n",
    "\n",
    "# Import thư viện cho Word processing\n",
    "try:\n",
    "    from docx import Document\n",
    "    from docx.shared import Inches\n",
    "    print(\"python-docx đã được cài đặt\")\n",
    "except ImportError:\n",
    "    print(\"Cần cài đặt python-docx: pip install python-docx\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"python-docx\"])\n",
    "    from docx import Document\n",
    "\n",
    "# Cài đặt các thư viện cần thiết nếu chưa có\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"numpy đã sẵn sàng\")\n",
    "except ImportError:\n",
    "    print(\"Cần cài đặt numpy: pip install numpy\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"numpy\"])\n",
    "    import numpy as np\n",
    "\n",
    "print(\"Tất cả thư viện đã được import thành công!\")\n",
    "print(\"Notebook sẵn sàng để chạy tóm tắt văn bản\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9c3f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TextSummarizerTFIDFTextRank đã được khởi tạo\n",
      "  - Damping factor: 0.85\n",
      "  - Max iterations: 100\n",
      "  - Tolerance: 1e-06\n",
      "  Đường dẫn dữ liệu: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK/DUC_TEXT/train\n",
      "  Đường dẫn reference: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK/DUC_SUM\n"
     ]
    }
   ],
   "source": [
    "class TextSummarizerTFIDFTextRank:\n",
    "    \"\"\"\n",
    "    Lớp tóm tắt văn bản sử dụng TF-IDF và TextRank\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, damping_factor=0.85, max_iterations=100, tolerance=1e-6):\n",
    "        self.damping_factor = damping_factor\n",
    "        self.max_iterations = max_iterations\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "        # Dữ liệu câu\n",
    "        self.sentences = []\n",
    "        self.sentence_vectors = []\n",
    "        self.vocabulary = set()\n",
    "        self.word_doc_count = defaultdict(int)\n",
    "        \n",
    "        # Ma trận\n",
    "        self.tfidf_matrix = None\n",
    "        self.cosine_matrix = None\n",
    "        self.adjacency_matrix = None\n",
    "        self.transition_matrix = None\n",
    "        self.textrank_scores = None\n",
    "        \n",
    "        print(\"  TextSummarizerTFIDFTextRank đã được khởi tạo\")\n",
    "        print(f\"  - Damping factor: {damping_factor}\")\n",
    "        print(f\"  - Max iterations: {max_iterations}\")\n",
    "        print(f\"  - Tolerance: {tolerance}\")\n",
    "\n",
    "# Khởi tạo summarizer\n",
    "summarizer = TextSummarizerTFIDFTextRank()\n",
    "\n",
    "# Cấu hình đường dẫn\n",
    "BASE_PATH = \"/Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK\"\n",
    "DUC_TEXT_PATH = os.path.join(BASE_PATH, \"DUC_TEXT\", \"train\")\n",
    "DUC_SUM_PATH = os.path.join(BASE_PATH, \"DUC_SUM\")\n",
    "\n",
    "print(f\"  Đường dẫn dữ liệu: {DUC_TEXT_PATH}\")\n",
    "print(f\"  Đường dẫn reference: {DUC_SUM_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72666e8f",
   "metadata": {},
   "source": [
    "## 2. Đọc File XML và Xử Lý Văn Bản\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd893ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yoliephan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yoliephan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tải spaCy model en_core_web_sm\n",
      "Đã chuẩn bị các thư viện NLTK và spaCy\n",
      "Số lượng stopwords tiếng Anh: 198 từ\n"
     ]
    }
   ],
   "source": [
    "# Cấu hình và tải dữ liệu NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Tải spaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"Đã tải spaCy model en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Cần cài đặt spaCy model: python -m spacy download en_core_web_sm\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Tải bộ stopwords từ nltk\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "print(\"Đã chuẩn bị các thư viện NLTK và spaCy\")\n",
    "print(f\"Số lượng stopwords tiếng Anh: {len(stop_words)} từ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7153afde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm các phương thức xử lý văn bản cải tiến với NLTK\n"
     ]
    }
   ],
   "source": [
    "def load_xml_document(self, file_path):\n",
    "    \"\"\"\n",
    "    Đọc và xử lý file XML từ DUC dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def preprocess_text(self, text):\n",
    "    \"\"\"\n",
    "    Tiền xử lý văn bản (loại bỏ từ dừng, dấu câu dư thừa và khoảng trắng thừa)\n",
    "    \"\"\"\n",
    "    # Loại bỏ thẻ XML/HTML trước\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Chia văn bản thành các câu bằng spaCy\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "    # Token hóa và loại bỏ từ dừng\n",
    "    original_sentences = []\n",
    "    cleaned_sentences = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if len(sentence.strip()) > 10:  # Chỉ giữ câu có ít nhất 10 ký tự\n",
    "            # Lưu câu gốc\n",
    "            original_sentences.append(sentence.strip())\n",
    "            \n",
    "            # Loại bỏ dấu câu dư thừa và khoảng trắng thừa\n",
    "            cleaned_sentence = re.sub(r'[``\"\"\\']', '', sentence)  \n",
    "            cleaned_sentence = re.sub(r'\\s+', ' ', cleaned_sentence).strip()\n",
    "\n",
    "            # Token hóa và chuyển thành chữ thường\n",
    "            words = word_tokenize(cleaned_sentence.lower())\n",
    "            \n",
    "            # Loại bỏ stopwords và giữ chỉ từ alphanumeric\n",
    "            filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "\n",
    "            # Chỉ giữ câu có ít nhất 3 từ sau khi lọc\n",
    "            if len(filtered_words) >= 3:\n",
    "                # Kết hợp lại thành câu đã làm sạch\n",
    "                cleaned_sentences.append(' '.join(filtered_words))\n",
    "            else:\n",
    "                # Nếu câu quá ngắn sau khi lọc, loại bỏ khỏi câu gốc\n",
    "                original_sentences.pop()\n",
    "\n",
    "    # Trả về cả câu gốc và câu đã xử lý\n",
    "    processed_sentences = []\n",
    "    for i in range(len(original_sentences)):\n",
    "        processed_sentences.append({\n",
    "            'original': original_sentences[i],\n",
    "            'processed': cleaned_sentences[i]\n",
    "        })\n",
    "    \n",
    "    return processed_sentences\n",
    "\n",
    "def save_to_word(self, content, filename):\n",
    "    \"\"\"\n",
    "    Lưu nội dung vào file Word\n",
    "    \"\"\"\n",
    "    doc = Document()\n",
    "    doc.add_heading('Document Content', 0)\n",
    "    \n",
    "    if isinstance(content, list):\n",
    "        for i, item in enumerate(content, 1):\n",
    "            if isinstance(item, dict):\n",
    "                doc.add_paragraph(f\"{i}. {item['original']}\")\n",
    "            else:\n",
    "                doc.add_paragraph(f\"{i}. {item}\")\n",
    "    else:\n",
    "        doc.add_paragraph(content)\n",
    "    \n",
    "    doc.save(filename)\n",
    "    print(f\"Đã lưu vào file: {filename}\")\n",
    "\n",
    "# Thêm các phương thức vào class\n",
    "TextSummarizerTFIDFTextRank.load_xml_document = load_xml_document\n",
    "TextSummarizerTFIDFTextRank.preprocess_text = preprocess_text\n",
    "TextSummarizerTFIDFTextRank.save_to_word = save_to_word\n",
    "\n",
    "print(\"Đã thêm các phương thức xử lý văn bản cải tiến với NLTK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85ee3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DANH SÁCH FILE CÓ SẴN TRONG DUC_TEXT:\n",
      "==================================================\n",
      "Tổng cộng: 50 file\n",
      "\n",
      "Các file có sẵn:\n",
      "d061j      d062j      d063j      d064j      d065j      \n",
      "d066j      d067f      d068f      d069f      d070f      \n",
      "d071f      d072f      d073b      d074b      d075b      \n",
      "d076b      d077b      d078b      d079a      d080a      \n",
      "d081a      d082a      d083a      d084a      d085d      \n",
      "d086d      d087d      d089d      d090d      d091c      \n",
      "d092c      d093c      d094c      d095c      d096c      \n",
      "d097e      d098e      d099e      d100e      d101e      \n",
      "d102e      d103g      d104g      d105g      d106g      \n",
      "d107g      d108g      d109h      d110h      d111h      \n",
      "\n",
      "Chọn bất kỳ file nào từ danh sách trên.\n",
      "Ví dụ: d061j, d062j, d063j, ...\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị danh sách file có sẵn trong DUC_TEXT\n",
    "print(\"DANH SÁCH FILE CÓ SẴN TRONG DUC_TEXT:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if os.path.exists(DUC_TEXT_PATH):\n",
    "    files = [f for f in os.listdir(DUC_TEXT_PATH) if not f.startswith('.')]\n",
    "    files.sort()  # Sắp xếp để dễ tìm\n",
    "    \n",
    "    if files:\n",
    "        print(f\"Tổng cộng: {len(files)} file\")\n",
    "        print(\"\\nCác file có sẵn:\")\n",
    "        \n",
    "        # Hiển thị file theo dạng cột\n",
    "        for i, filename in enumerate(files):\n",
    "            if i % 5 == 0 and i > 0:\n",
    "                print()\n",
    "            print(f\"{filename:<10}\", end=\" \")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        print(\"Chọn bất kỳ file nào từ danh sách trên.\")\n",
    "        print(\"Ví dụ: d061j, d062j, d063j, ...\")\n",
    "        \n",
    "        # Lưu danh sách file để sử dụng ở cell tiếp theo\n",
    "        available_files = files\n",
    "        \n",
    "    else:\n",
    "        print(\"Không tìm thấy file nào trong thư mục DUC_TEXT\")\n",
    "        available_files = []\n",
    "else:\n",
    "    print(f\"Thư mục không tồn tại: {DUC_TEXT_PATH}\")\n",
    "    available_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e04755bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHỌN FILE VÀ XỬ LÝ VĂN BẢN:\n",
      "==================================================\n",
      "Đã chọn file: d061j\n",
      "\n",
      "Đang đọc file: d061j\n",
      "Đã đọc 32448 ký tự\n",
      "\n",
      "Đang tiền xử lý văn bản...\n",
      "Đã chọn file: d061j\n",
      "\n",
      "Đang đọc file: d061j\n",
      "Đã đọc 32448 ký tự\n",
      "\n",
      "Đang tiền xử lý văn bản...\n",
      "Đã xử lý thành 183 câu (sau khi loại bỏ stopwords và chuẩn hóa)\n",
      "\n",
      "3 câu đầu tiên sau khi xử lý:\n",
      "Câu 1: hurricane gilbert swept toward dominican republic sunday civil defense alerted heavily populated south coast prepare high winds heavy rains high seas\n",
      "Câu 2: storm approaching southeast sustained winds 75 mph gusting 92 mph\n",
      "Câu 3: need alarm civil defense director eugenio cabral said television alert shortly midnight saturday\n",
      "Đã lưu vào file: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK/input.docx\n",
      "\n",
      "Bước 1 hoàn thành: Đã xử lý 183 câu và lưu vào input.docx\n",
      "File input.docx chứa các câu gốc, văn bản đã được xử lý sẽ dùng cho TF-IDF\n",
      "Đã xử lý thành 183 câu (sau khi loại bỏ stopwords và chuẩn hóa)\n",
      "\n",
      "3 câu đầu tiên sau khi xử lý:\n",
      "Câu 1: hurricane gilbert swept toward dominican republic sunday civil defense alerted heavily populated south coast prepare high winds heavy rains high seas\n",
      "Câu 2: storm approaching southeast sustained winds 75 mph gusting 92 mph\n",
      "Câu 3: need alarm civil defense director eugenio cabral said television alert shortly midnight saturday\n",
      "Đã lưu vào file: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK/input.docx\n",
      "\n",
      "Bước 1 hoàn thành: Đã xử lý 183 câu và lưu vào input.docx\n",
      "File input.docx chứa các câu gốc, văn bản đã được xử lý sẽ dùng cho TF-IDF\n"
     ]
    }
   ],
   "source": [
    "# Chọn file và thực hiện xử lý văn bản\n",
    "if 'available_files' in locals() and available_files:\n",
    "    print(\"CHỌN FILE VÀ XỬ LÝ VĂN BẢN:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Tùy chọn chọn file\n",
    "    demo_file_input = input(\"\\nNhập tên file muốn xử lý (ví dụ: d061j) hoặc nhấn Enter để dùng file đầu tiên: \").strip()\n",
    "    \n",
    "    if demo_file_input and demo_file_input in available_files:\n",
    "        demo_file = demo_file_input\n",
    "        print(f\"Đã chọn file: {demo_file}\")\n",
    "    elif demo_file_input and demo_file_input not in available_files:\n",
    "        print(f\"File '{demo_file_input}' không tồn tại. Sử dụng file đầu tiên: {available_files[0]}\")\n",
    "        demo_file = available_files[0]\n",
    "    else:\n",
    "        demo_file = available_files[0]\n",
    "        print(f\"Sử dụng file mặc định: {demo_file}\")\n",
    "    \n",
    "    file_path = os.path.join(DUC_TEXT_PATH, demo_file)\n",
    "    \n",
    "    print(f\"\\nĐang đọc file: {demo_file}\")\n",
    "    \n",
    "    # Đọc nội dung\n",
    "    content = summarizer.load_xml_document(file_path)\n",
    "    print(f\"Đã đọc {len(content)} ký tự\")\n",
    "    \n",
    "    # Tiền xử lý văn bản với NLTK\n",
    "    print(\"\\nĐang tiền xử lý văn bản...\")\n",
    "    sentences = summarizer.preprocess_text(content)\n",
    "    print(f\"Đã xử lý thành {len(sentences)} câu (sau khi loại bỏ stopwords và chuẩn hóa)\")\n",
    "    \n",
    "    # Lưu câu vào summarizer\n",
    "    summarizer.sentences = sentences\n",
    "    \n",
    "    # Hiển thị 3 câu đầu tiên đã xử lý\n",
    "    if sentences:\n",
    "        print(\"\\n3 câu đầu tiên sau khi xử lý:\")\n",
    "        for i, sent in enumerate(sentences[:3], 1):\n",
    "            print(f\"Câu {i}: {sent['processed']}\")\n",
    "    \n",
    "    # Lưu vào file Word (input.docx) - lưu câu gốc để đọc\n",
    "    input_filename = os.path.join(BASE_PATH, \"input.docx\")\n",
    "    summarizer.save_to_word(sentences, input_filename)\n",
    "    \n",
    "    print(f\"\\nBước 1 hoàn thành: Đã xử lý {len(sentences)} câu và lưu vào input.docx\")\n",
    "    print(\"File input.docx chứa các câu gốc, văn bản đã được xử lý sẽ dùng cho TF-IDF\")\n",
    "    \n",
    "else:\n",
    "    print(\"Không có danh sách file. Hãy chạy cell trước đó để xem danh sách file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053817f",
   "metadata": {},
   "source": [
    "## 3. Biểu Diễn Câu Bằng Vector TF-IDF\n",
    "\n",
    "**Công thức TF-IDF:**\n",
    "\n",
    "- **TF (Term Frequency)** = (số lần xuất hiện của từ trong câu) / (tổng số từ trong câu)\n",
    "- **IDF (Inverse Document Frequency)** = log(tổng số câu / số câu chứa từ đó)\n",
    "- **TF-IDF** = TF × IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77c21dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm các phương thức tính TF-IDF\n"
     ]
    }
   ],
   "source": [
    "def build_vocabulary(self):\n",
    "    \"\"\"\n",
    "    Xây dựng từ vựng từ tất cả các câu\n",
    "    \"\"\"\n",
    "    print(\"Đang xây dựng từ vựng...\")\n",
    "    \n",
    "    # Tách từ từ tất cả các câu\n",
    "    all_words = []\n",
    "    for sentence in self.sentences:\n",
    "        words = sentence['processed'].split()\n",
    "        # Từ đã được lọc stopwords trong preprocess_text\n",
    "        words = [word for word in words if len(word) >= 2]\n",
    "        all_words.extend(words)\n",
    "        \n",
    "        # Cập nhật từ vựng unique\n",
    "        self.vocabulary.update(words)\n",
    "        \n",
    "        # Đếm số câu chứa mỗi từ\n",
    "        unique_words = set(words)\n",
    "        for word in unique_words:\n",
    "            self.word_doc_count[word] += 1\n",
    "    \n",
    "    print(f\"Tổng từ vựng: {len(self.vocabulary)} từ\")\n",
    "    \n",
    "    return list(self.vocabulary)\n",
    "\n",
    "def calculate_tf(self, word, sentence_words):\n",
    "    \"\"\"\n",
    "    Tính Term Frequency (TF) \n",
    "    TF = số lần xuất hiện của từ / tổng số từ trong câu\n",
    "    \"\"\"\n",
    "    word_count = sentence_words.count(word)\n",
    "    total_words = len(sentence_words)\n",
    "    tf = word_count / total_words if total_words > 0 else 0\n",
    "    return tf\n",
    "\n",
    "def calculate_idf(self, word):\n",
    "    \"\"\"\n",
    "    Tính Inverse Document Frequency (IDF) \n",
    "    IDF = log(tổng số câu / số câu chứa từ)\n",
    "    \"\"\"\n",
    "    total_sentences = len(self.sentences)\n",
    "    sentences_with_word = self.word_doc_count[word]\n",
    "    \n",
    "    if sentences_with_word == 0:\n",
    "        return 0\n",
    "    \n",
    "    idf = math.log(total_sentences / sentences_with_word)\n",
    "    return idf\n",
    "\n",
    "def calculate_tfidf(self, word, sentence_words):\n",
    "    \"\"\"\n",
    "    Tính TF-IDF - viết tay công thức\n",
    "    TF-IDF = TF × IDF\n",
    "    \"\"\"\n",
    "    tf = self.calculate_tf(word, sentence_words)\n",
    "    idf = self.calculate_idf(word)\n",
    "    tfidf = tf * idf\n",
    "    return tfidf\n",
    "\n",
    "def build_tfidf_matrix(self):\n",
    "    \"\"\"\n",
    "    Xây dựng ma trận TF-IDF cho tất cả các câu \n",
    "    \"\"\"\n",
    "    print(\"Đang xây dựng ma trận TF-IDF...\")\n",
    "    \n",
    "    # Xây dựng từ vựng\n",
    "    vocab_list = self.build_vocabulary()\n",
    "    vocab_size = len(vocab_list)\n",
    "    \n",
    "    # Khởi tạo ma trận TF-IDF\n",
    "    self.tfidf_matrix = np.zeros((len(self.sentences), vocab_size))\n",
    "    \n",
    "    # Tạo mapping từ word → index\n",
    "    word_to_index = {word: i for i, word in enumerate(vocab_list)}\n",
    "    \n",
    "    # Tính TF-IDF cho từng câu\n",
    "    for sent_idx, sentence in enumerate(self.sentences):\n",
    "        sentence_words = sentence['processed'].split()\n",
    "        # Từ đã được lọc stopwords trong preprocess_text\n",
    "        sentence_words = [word for word in sentence_words if len(word) >= 2]\n",
    "        \n",
    "        # Tính TF-IDF cho mỗi từ trong câu\n",
    "        for word in set(sentence_words):  # Chỉ tính cho từ unique trong câu\n",
    "            if word in word_to_index:\n",
    "                word_idx = word_to_index[word]\n",
    "                self.tfidf_matrix[sent_idx, word_idx] = self.calculate_tfidf(word, sentence_words)\n",
    "    \n",
    "    print(f\"Ma trận TF-IDF: {self.tfidf_matrix.shape} (câu × từ vựng)\")\n",
    "    return self.tfidf_matrix, vocab_list\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.build_vocabulary = build_vocabulary\n",
    "TextSummarizerTFIDFTextRank.calculate_tf = calculate_tf\n",
    "TextSummarizerTFIDFTextRank.calculate_idf = calculate_idf\n",
    "TextSummarizerTFIDFTextRank.calculate_tfidf = calculate_tfidf\n",
    "TextSummarizerTFIDFTextRank.build_tfidf_matrix = build_tfidf_matrix\n",
    "\n",
    "print(\"Đã thêm các phương thức tính TF-IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188d3623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xây dựng ma trận TF-IDF...\n",
      "Đang xây dựng từ vựng...\n",
      "Tổng từ vựng: 913 từ\n",
      "Ma trận TF-IDF: (183, 913) (câu × từ vựng)\n",
      "\n",
      "Minh họa cách tính TF-IDF\n",
      "==================================================\n",
      "Câu: 'Hurricane Gilbert swept toward the Dominican Republic Sunday, and the Civil Defense alerted its heav...'\n",
      "Từ: 'hurricane'\n",
      "\n",
      "1. TF (Term Frequency):\n",
      "   Số lần xuất hiện: 1\n",
      "   Tổng số từ: 21\n",
      "   TF = 1 / 21 = 0.047619\n",
      "\n",
      "2. IDF (Inverse Document Frequency):\n",
      "   Tổng số câu: 183\n",
      "   Số câu chứa 'hurricane': 56\n",
      "   IDF = log(183 / 56) = 1.184134\n",
      "\n",
      "3. TF-IDF:\n",
      "   TF-IDF = 0.047619 × 1.184134 = 0.056387\n",
      "\n",
      "Bước 2 hoàn thành: Đã tạo ma trận TF-IDF (183, 913)\n"
     ]
    }
   ],
   "source": [
    "# Thực nghiệm: Xây dựng ma trận TF-IDF\n",
    "if summarizer.sentences:\n",
    "    # Xây dựng ma trận TF-IDF\n",
    "    tfidf_matrix, vocab_list = summarizer.build_tfidf_matrix()\n",
    "    \n",
    "    # Demo: Hiển thị cách tính TF-IDF cho một từ cụ thể\n",
    "    print(\"\\nMinh họa cách tính TF-IDF\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Chọn câu đầu tiên và từ phổ biến\n",
    "    demo_sentence = summarizer.sentences[0]\n",
    "    demo_words = demo_sentence['processed'].split()\n",
    "    demo_words = [word for word in demo_words if len(word) >= 3]\n",
    "    \n",
    "    if demo_words:\n",
    "        demo_word = demo_words[0]  # Chọn từ đầu tiên\n",
    "        \n",
    "        print(f\"Câu: '{demo_sentence['original'][:100]}...'\")\n",
    "        print(f\"Từ: '{demo_word}'\")\n",
    "        \n",
    "        # Tính từng bước\n",
    "        tf = summarizer.calculate_tf(demo_word, demo_words)\n",
    "        idf = summarizer.calculate_idf(demo_word)\n",
    "        tfidf = summarizer.calculate_tfidf(demo_word, demo_words)\n",
    "        \n",
    "        print(f\"\\n1. TF (Term Frequency):\")\n",
    "        print(f\"   Số lần xuất hiện: {demo_words.count(demo_word)}\")\n",
    "        print(f\"   Tổng số từ: {len(demo_words)}\")\n",
    "        print(f\"   TF = {demo_words.count(demo_word)} / {len(demo_words)} = {tf:.6f}\")\n",
    "        \n",
    "        print(f\"\\n2. IDF (Inverse Document Frequency):\")\n",
    "        print(f\"   Tổng số câu: {len(summarizer.sentences)}\")\n",
    "        print(f\"   Số câu chứa '{demo_word}': {summarizer.word_doc_count[demo_word]}\")\n",
    "        print(f\"   IDF = log({len(summarizer.sentences)} / {summarizer.word_doc_count[demo_word]}) = {idf:.6f}\")\n",
    "        \n",
    "        print(f\"\\n3. TF-IDF:\")\n",
    "        print(f\"   TF-IDF = {tf:.6f} × {idf:.6f} = {tfidf:.6f}\")\n",
    "    \n",
    "    print(f\"\\nBước 2 hoàn thành: Đã tạo ma trận TF-IDF {tfidf_matrix.shape}\")\n",
    "else:\n",
    "    print(\"Chưa có dữ liệu câu để xử lý\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d03573",
   "metadata": {},
   "source": [
    "## 4. Tính Độ Tương Đồng Cosine\n",
    "\n",
    "**Công thức Cosine Similarity:**\n",
    "\n",
    "- **cosine_similarity(A, B)** = (A · B) / (|A| × |B|)\n",
    "- **A · B** = tích vô hướng của hai vector\n",
    "- **|A|** = độ dài (magnitude) của vector A = √(Σ(ai²))\n",
    "- **|B|** = độ dài (magnitude) của vector B = √(Σ(bi²))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e09a7ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm các phương thức tính Cosine Similarity\n"
     ]
    }
   ],
   "source": [
    "def calculate_cosine_similarity(self, vector1, vector2):\n",
    "    \"\"\"\n",
    "    Tính cosine similarity giữa hai vector \n",
    "    cosine_similarity = (A · B) / (|A| × |B|)\n",
    "    \"\"\"\n",
    "    # Tính tích vô hướng (dot product)\n",
    "    dot_product = 0\n",
    "    for i in range(len(vector1)):\n",
    "        dot_product += vector1[i] * vector2[i]\n",
    "    \n",
    "    # Tính độ dài của vector A\n",
    "    magnitude_a = 0\n",
    "    for val in vector1:\n",
    "        magnitude_a += val * val\n",
    "    magnitude_a = math.sqrt(magnitude_a)\n",
    "    \n",
    "    # Tính độ dài của vector B  \n",
    "    magnitude_b = 0\n",
    "    for val in vector2:\n",
    "        magnitude_b += val * val\n",
    "    magnitude_b = math.sqrt(magnitude_b)\n",
    "    \n",
    "    # Tránh chia cho 0\n",
    "    if magnitude_a == 0 or magnitude_b == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Tính cosine similarity\n",
    "    cosine_sim = dot_product / (magnitude_a * magnitude_b)\n",
    "    return cosine_sim\n",
    "\n",
    "def build_cosine_matrix(self):\n",
    "    \"\"\"\n",
    "    Xây dựng ma trận cosine similarity giữa tất cả các câu\n",
    "    \"\"\"\n",
    "    print(\"Đang xây dựng ma trận cosine similarity...\")\n",
    "    \n",
    "    if self.tfidf_matrix is None:\n",
    "        print(\"Chưa có ma trận TF-IDF. Hãy chạy build_tfidf_matrix() trước.\")\n",
    "        return None\n",
    "    \n",
    "    num_sentences = self.tfidf_matrix.shape[0]\n",
    "    self.cosine_matrix = np.zeros((num_sentences, num_sentences))\n",
    "    \n",
    "    # Tính cosine similarity cho mỗi cặp câu\n",
    "    for i in range(num_sentences):\n",
    "        for j in range(num_sentences):\n",
    "            if i == j:\n",
    "                self.cosine_matrix[i, j] = 1.0  # Similarity với chính nó = 1\n",
    "            else:\n",
    "                similarity = self.calculate_cosine_similarity(\n",
    "                    self.tfidf_matrix[i], \n",
    "                    self.tfidf_matrix[j]\n",
    "                )\n",
    "                self.cosine_matrix[i, j] = similarity\n",
    "    \n",
    "    print(f\"  Ma trận cosine similarity: {self.cosine_matrix.shape}\")\n",
    "    return self.cosine_matrix\n",
    "\n",
    "def demonstrate_cosine_calculation(self, sent1_idx=0, sent2_idx=1):\n",
    "    \"\"\"\n",
    "    Minh họa chi tiết cách tính cosine similarity\n",
    "    \"\"\"\n",
    "    if self.tfidf_matrix is None or len(self.sentences) < 2:\n",
    "        print(\"Không đủ dữ liệu để minh họa\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nMinh họa cách tính Cosine Similarity\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Lấy hai vector\n",
    "    vector1 = self.tfidf_matrix[sent1_idx]\n",
    "    vector2 = self.tfidf_matrix[sent2_idx]\n",
    "    \n",
    "    print(f\"Câu 1: '{self.sentences[sent1_idx]['original'][:80]}...'\")\n",
    "    print(f\"Câu 2: '{self.sentences[sent2_idx]['original'][:80]}...'\")\n",
    "    \n",
    "    # Tính từng bước\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    magnitude_a = np.linalg.norm(vector1)\n",
    "    magnitude_b = np.linalg.norm(vector2)\n",
    "    \n",
    "    print(f\"\\n1. Tích vô hướng (A · B):\")\n",
    "    print(f\"   dot_product = Σ(ai × bi) = {dot_product:.6f}\")\n",
    "    \n",
    "    print(f\"\\n2. Độ dài vector:\")\n",
    "    print(f\"   |A| = √(Σ(ai²)) = {magnitude_a:.6f}\")\n",
    "    print(f\"   |B| = √(Σ(bi²)) = {magnitude_b:.6f}\")\n",
    "    \n",
    "    if magnitude_a > 0 and magnitude_b > 0:\n",
    "        cosine_sim = dot_product / (magnitude_a * magnitude_b)\n",
    "        print(f\"\\n3. Cosine Similarity:\")\n",
    "        print(f\"   cosine_sim = {dot_product:.6f} / ({magnitude_a:.6f} × {magnitude_b:.6f})\")\n",
    "        print(f\"   cosine_sim = {cosine_sim:.6f}\")\n",
    "        \n",
    "        # Giải thích ý nghĩa\n",
    "        if cosine_sim > 0.8:\n",
    "            interpretation = \"rất tương tự\"\n",
    "        elif cosine_sim > 0.5:\n",
    "            interpretation = \"tương tự\"\n",
    "        elif cosine_sim > 0.3:\n",
    "            interpretation = \"hơi tương tự\"\n",
    "        else:\n",
    "            interpretation = \"không tương tự\"\n",
    "        print(f\"   → Hai câu {interpretation}\")\n",
    "    else:\n",
    "        print(\"\\nMột trong hai vector có độ dài = 0\")\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.calculate_cosine_similarity = calculate_cosine_similarity\n",
    "TextSummarizerTFIDFTextRank.build_cosine_matrix = build_cosine_matrix\n",
    "TextSummarizerTFIDFTextRank.demonstrate_cosine_calculation = demonstrate_cosine_calculation\n",
    "\n",
    "print(\"Đã thêm các phương thức tính Cosine Similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "839ee630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xây dựng ma trận cosine similarity...\n",
      "  Ma trận cosine similarity: (183, 183)\n",
      "\n",
      "Minh họa cách tính Cosine Similarity\n",
      "============================================================\n",
      "Câu 1: 'Hurricane Gilbert swept toward the Dominican Republic Sunday, and the Civil Defe...'\n",
      "Câu 2: 'The storm was approaching from the southeast with sustained winds of 75 mph gust...'\n",
      "\n",
      "1. Tích vô hướng (A · B):\n",
      "   dot_product = Σ(ai × bi) = 0.017438\n",
      "\n",
      "2. Độ dài vector:\n",
      "   |A| = √(Σ(ai²)) = 0.842203\n",
      "   |B| = √(Σ(bi²)) = 1.208209\n",
      "\n",
      "3. Cosine Similarity:\n",
      "   cosine_sim = 0.017438 / (0.842203 × 1.208209)\n",
      "   cosine_sim = 0.017137\n",
      "   → Hai câu không tương tự\n",
      "\n",
      "Thống kê ma trận Cosine Similarity:\n",
      "   - Kích thước: (183, 183)\n",
      "   - Giá trị trung bình: 0.0205\n",
      "   - Giá trị max (không tính đường chéo): 1.0000\n",
      "   - Giá trị min: 0.0000\n",
      "\n",
      "Ma trận Cosine Similarity (5x5 đầu tiên):\n",
      "      S0       S1       S2       S3       S4       \n",
      "S0    1.000   0.017   0.099   0.000   0.000   \n",
      "S1    0.017   1.000   0.000   0.000   0.000   \n",
      "S2    0.099   0.000   1.000   0.099   0.000   \n",
      "S3    0.000   0.000   0.099   1.000   0.187   \n",
      "S4    0.000   0.000   0.000   0.187   1.000   \n",
      "\n",
      "Bước 3 hoàn thành: Đã tạo ma trận cosine similarity\n",
      "  Ma trận cosine similarity: (183, 183)\n",
      "\n",
      "Minh họa cách tính Cosine Similarity\n",
      "============================================================\n",
      "Câu 1: 'Hurricane Gilbert swept toward the Dominican Republic Sunday, and the Civil Defe...'\n",
      "Câu 2: 'The storm was approaching from the southeast with sustained winds of 75 mph gust...'\n",
      "\n",
      "1. Tích vô hướng (A · B):\n",
      "   dot_product = Σ(ai × bi) = 0.017438\n",
      "\n",
      "2. Độ dài vector:\n",
      "   |A| = √(Σ(ai²)) = 0.842203\n",
      "   |B| = √(Σ(bi²)) = 1.208209\n",
      "\n",
      "3. Cosine Similarity:\n",
      "   cosine_sim = 0.017438 / (0.842203 × 1.208209)\n",
      "   cosine_sim = 0.017137\n",
      "   → Hai câu không tương tự\n",
      "\n",
      "Thống kê ma trận Cosine Similarity:\n",
      "   - Kích thước: (183, 183)\n",
      "   - Giá trị trung bình: 0.0205\n",
      "   - Giá trị max (không tính đường chéo): 1.0000\n",
      "   - Giá trị min: 0.0000\n",
      "\n",
      "Ma trận Cosine Similarity (5x5 đầu tiên):\n",
      "      S0       S1       S2       S3       S4       \n",
      "S0    1.000   0.017   0.099   0.000   0.000   \n",
      "S1    0.017   1.000   0.000   0.000   0.000   \n",
      "S2    0.099   0.000   1.000   0.099   0.000   \n",
      "S3    0.000   0.000   0.099   1.000   0.187   \n",
      "S4    0.000   0.000   0.000   0.187   1.000   \n",
      "\n",
      "Bước 3 hoàn thành: Đã tạo ma trận cosine similarity\n"
     ]
    }
   ],
   "source": [
    "# Thực nghiệm: Xây dựng ma trận cosine similarity\n",
    "if summarizer.tfidf_matrix is not None:\n",
    "    # Xây dựng ma trận cosine\n",
    "    cosine_matrix = summarizer.build_cosine_matrix()\n",
    "    \n",
    "    # Minh họa cách tính cosine similarity\n",
    "    if len(summarizer.sentences) >= 2:\n",
    "        summarizer.demonstrate_cosine_calculation(0, 1)\n",
    "    \n",
    "    # Hiển thị thống kê ma trận cosine\n",
    "    print(f\"\\nThống kê ma trận Cosine Similarity:\")\n",
    "    print(f\"   - Kích thước: {cosine_matrix.shape}\")\n",
    "    print(f\"   - Giá trị trung bình: {np.mean(cosine_matrix):.4f}\")\n",
    "    print(f\"   - Giá trị max (không tính đường chéo): {np.max(cosine_matrix - np.eye(len(cosine_matrix))):.4f}\")\n",
    "    print(f\"   - Giá trị min: {np.min(cosine_matrix):.4f}\")\n",
    "    \n",
    "    # Hiển thị ma trận 5x5 đầu tiên\n",
    "    display_size = min(5, len(summarizer.sentences))\n",
    "    print(f\"\\nMa trận Cosine Similarity ({display_size}x{display_size} đầu tiên):\")\n",
    "    print(\"      \", end=\"\")\n",
    "    for j in range(display_size):\n",
    "        print(f\"S{j:<8}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for i in range(display_size):\n",
    "        print(f\"S{i:<4} \", end=\"\")\n",
    "        for j in range(display_size):\n",
    "            print(f\"{cosine_matrix[i,j]:<8.3f}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"\\nBước 3 hoàn thành: Đã tạo ma trận cosine similarity\")\n",
    "else:\n",
    "    print(\"Chưa có ma trận TF-IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff03d8",
   "metadata": {},
   "source": [
    "## 5. Mô Hình Hóa Đồ Thị\n",
    "\n",
    "Mô hình hóa văn bản dưới dạng đồ thị:\n",
    "\n",
    "- **Đỉnh (Vertices)**: Mỗi câu là một đỉnh\n",
    "- **Cạnh (Edges)**: Trọng số cosine similarity giữa các câu\n",
    "- **Ngưỡng (Threshold)**: Chỉ tạo cạnh khi similarity > threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0588b609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm các phương thức mô hình hóa đồ thị\n"
     ]
    }
   ],
   "source": [
    "def create_adjacency_matrix(self, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Tạo ma trận kề từ ma trận cosine similarity\n",
    "    Nếu similarity > threshold thì có cạnh (giá trị = 1)\n",
    "    \"\"\"\n",
    "    print(f\"Đang tạo đồ thị với ngưỡng similarity: {threshold}\")\n",
    "    \n",
    "    if self.cosine_matrix is None:\n",
    "        print(\"Chưa có ma trận cosine similarity\")\n",
    "        return None\n",
    "    \n",
    "    n = self.cosine_matrix.shape[0]\n",
    "    self.adjacency_matrix = np.zeros((n, n))\n",
    "    \n",
    "    # Tạo cạnh dựa trên ngưỡng similarity\n",
    "    edge_count = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j and self.cosine_matrix[i, j] > threshold:\n",
    "                self.adjacency_matrix[i, j] = 1\n",
    "                edge_count += 1\n",
    "    \n",
    "    print(f\"Đã tạo {edge_count} cạnh trong đồ thị\")\n",
    "    print(f\"Ma trận kề: {self.adjacency_matrix.shape}\")\n",
    "    \n",
    "    return self.adjacency_matrix\n",
    "\n",
    "def create_transition_matrix(self):\n",
    "    \"\"\"\n",
    "    Tạo ma trận chuyển tiếp cho TextRank\n",
    "    Mỗi hàng được chuẩn hóa sao cho tổng = 1\n",
    "    \"\"\"\n",
    "    print(\"Đang tạo ma trận chuyển tiếp...\")\n",
    "    \n",
    "    if self.adjacency_matrix is None:\n",
    "        print(\"Chưa có ma trận kề\")\n",
    "        return None\n",
    "    \n",
    "    n = self.adjacency_matrix.shape[0]\n",
    "    self.transition_matrix = np.copy(self.adjacency_matrix).astype(float)\n",
    "    \n",
    "    # Chuẩn hóa từng hàng\n",
    "    for i in range(n):\n",
    "        row_sum = np.sum(self.transition_matrix[i])\n",
    "        if row_sum > 0:\n",
    "            # Có cạnh ra → chuẩn hóa\n",
    "            self.transition_matrix[i] = self.transition_matrix[i] / row_sum\n",
    "        else:\n",
    "            # Không có cạnh ra → phân bố đều cho tất cả đỉnh\n",
    "            self.transition_matrix[i] = np.ones(n) / n\n",
    "    \n",
    "    print(f\"Ma trận chuyển tiếp: {self.transition_matrix.shape}\")\n",
    "    \n",
    "    # Kiểm tra tính chuẩn hóa\n",
    "    row_sums = np.sum(self.transition_matrix, axis=1)\n",
    "    print(f\"Kiểm tra chuẩn hóa: tổng hàng = {row_sums[0]:.6f} (should be 1.0)\")\n",
    "    \n",
    "    return self.transition_matrix\n",
    "\n",
    "def visualize_graph_info(self):\n",
    "    \"\"\"\n",
    "    Hiển thị thông tin về đồ thị\n",
    "    \"\"\"\n",
    "    if self.adjacency_matrix is None:\n",
    "        print(\"Chưa có ma trận kề\")\n",
    "        return\n",
    "    \n",
    "    n = len(self.sentences)\n",
    "    total_edges = np.sum(self.adjacency_matrix)\n",
    "    \n",
    "    print(f\"\\nThông tin đồ thị:\")\n",
    "    print(f\"   - Số đỉnh (câu): {n}\")\n",
    "    print(f\"   - Số cạnh: {int(total_edges)}\")\n",
    "    print(f\"   - Mật độ: {total_edges / (n * (n-1)):.4f}\")\n",
    "    \n",
    "    # Hiển thị degree của từng đỉnh\n",
    "    in_degrees = np.sum(self.adjacency_matrix, axis=0)  # Số cạnh vào\n",
    "    out_degrees = np.sum(self.adjacency_matrix, axis=1)  # Số cạnh ra\n",
    "    \n",
    "    print(f\"\\nThống kê degree:\")\n",
    "    print(f\"   - In-degree trung bình: {np.mean(in_degrees):.2f}\")\n",
    "    print(f\"   - Out-degree trung bình: {np.mean(out_degrees):.2f}\")\n",
    "    print(f\"   - Max in-degree: {int(np.max(in_degrees))}\")\n",
    "    print(f\"   - Max out-degree: {int(np.max(out_degrees))}\")\n",
    "    \n",
    "    # Hiển thị một vài câu có degree cao nhất\n",
    "    high_degree_indices = np.argsort(in_degrees)[-3:][::-1]\n",
    "    print(f\"\\nTop 3 câu có nhiều liên kết nhất:\")\n",
    "    for i, idx in enumerate(high_degree_indices, 1):\n",
    "        sentence_preview = self.sentences[idx]['original'][:60]\n",
    "        print(f\"   {i}. Câu {idx}: degree={int(in_degrees[idx])} - '{sentence_preview}...'\")\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.create_adjacency_matrix = create_adjacency_matrix\n",
    "TextSummarizerTFIDFTextRank.create_transition_matrix = create_transition_matrix\n",
    "TextSummarizerTFIDFTextRank.visualize_graph_info = visualize_graph_info\n",
    "\n",
    "print(\"Đã thêm các phương thức mô hình hóa đồ thị\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a66df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tạo đồ thị với ngưỡng similarity: 0.1\n",
      "Đã tạo 1178 cạnh trong đồ thị\n",
      "Ma trận kề: (183, 183)\n",
      "Đang tạo ma trận chuyển tiếp...\n",
      "Ma trận chuyển tiếp: (183, 183)\n",
      "Kiểm tra chuẩn hóa: tổng hàng = 1.000000 (should be 1.0)\n",
      "\n",
      "Thông tin đồ thị:\n",
      "   - Số đỉnh (câu): 183\n",
      "   - Số cạnh: 1178\n",
      "   - Mật độ: 0.0354\n",
      "\n",
      "Thống kê degree:\n",
      "   - In-degree trung bình: 6.44\n",
      "   - Out-degree trung bình: 6.44\n",
      "   - Max in-degree: 22\n",
      "   - Max out-degree: 22\n",
      "\n",
      "Top 3 câu có nhiều liên kết nhất:\n",
      "   1. Câu 44: degree=22 - 'Heavy rain and stiff winds downed power lines and caused flo...'\n",
      "   2. Câu 56: degree=21 - 'A National Weather Service report said the hurricane was mov...'\n",
      "   3. Câu 127: degree=20 - 'On Sunday, Monday and Tuesday, Gilbert pounded the Dominican...'\n",
      "\n",
      "Ma trận kề (5x5 đầu tiên):\n",
      "      S0   S1   S2   S3   S4   \n",
      "S0    0   0   0   0   0   \n",
      "S1    0   0   0   0   0   \n",
      "S2    0   0   0   0   0   \n",
      "S3    0   0   0   0   1   \n",
      "S4    0   0   0   1   0   \n",
      "\n",
      "Ma trận chuyển tiếp (5x5 đầu tiên):\n",
      "      S0       S1       S2       S3       S4       \n",
      "S0    0.000   0.000   0.000   0.000   0.000   \n",
      "S1    0.000   0.000   0.000   0.000   0.000   \n",
      "S2    0.000   0.000   0.000   0.000   0.000   \n",
      "S3    0.000   0.000   0.000   0.000   0.500   \n",
      "S4    0.000   0.000   0.000   0.200   0.000   \n",
      "\n",
      "Kiểm tra chuẩn hóa ma trận chuyển tiếp:\n",
      "   Hàng 0: tổng = 1.000000 (phải = 1.0)\n",
      "   Hàng 1: tổng = 1.000000 (phải = 1.0)\n",
      "   Hàng 2: tổng = 1.000000 (phải = 1.0)\n",
      "\n",
      "Bước 4 hoàn thành: Đã mô hình hóa văn bản thành đồ thị\n"
     ]
    }
   ],
   "source": [
    "# Thực nghiệm: Tạo đồ thị từ ma trận cosine similarity\n",
    "if summarizer.cosine_matrix is not None:\n",
    "    # Tạo ma trận kề với ngưỡng phù hợp\n",
    "    threshold = 0.1  # Có thể điều chỉnh\n",
    "    adjacency_matrix = summarizer.create_adjacency_matrix(threshold)\n",
    "    \n",
    "    # Tạo ma trận chuyển tiếp\n",
    "    transition_matrix = summarizer.create_transition_matrix()\n",
    "    \n",
    "    # Hiển thị thông tin đồ thị\n",
    "    summarizer.visualize_graph_info()\n",
    "    \n",
    "    # DEMO CHI TIẾT: Minh họa cách tính ma trận kề và ma trận chuyển tiếp\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"DEMO: MINH HỌA CÁCH TÍNH MA TRẬN KỀ VÀ MA TRẬN CHUYỂN TIẾP\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    display_size = min(5, len(summarizer.sentences))\n",
    "    \n",
    "    # 1. Hiển thị ma trận cosine similarity trước\n",
    "    print(f\"\\n1. MA TRẬN COSINE SIMILARITY ({display_size}x{display_size} đầu tiên):\")\n",
    "    print(\"      \", end=\"\")\n",
    "    for j in range(display_size):\n",
    "        print(f\"S{j:<8}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for i in range(display_size):\n",
    "        print(f\"S{i:<4} \", end=\"\")\n",
    "        for j in range(display_size):\n",
    "            print(f\"{summarizer.cosine_matrix[i,j]:<8.3f}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    # 2. Giải thích cách tạo ma trận kề\n",
    "    print(f\"\\n2. CÁCH TẠO MA TRẬN KỀ (threshold = {threshold}):\")\n",
    "    print(f\"   Quy tắc: Nếu cosine_similarity > {threshold} thì tạo cạnh (giá trị = 1)\")\n",
    "    print(f\"            Ngược lại không có cạnh (giá trị = 0)\")\n",
    "    \n",
    "    # Hiển thị ma trận kề\n",
    "    print(f\"\\nMa trận kề ({display_size}x{display_size} đầu tiên):\")\n",
    "    print(\"      \", end=\"\")\n",
    "    for j in range(display_size):\n",
    "        print(f\"S{j:<4}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for i in range(display_size):\n",
    "        print(f\"S{i:<4} \", end=\"\")\n",
    "        for j in range(display_size):\n",
    "            print(f\"{int(adjacency_matrix[i,j]):<4}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    # 3. Giải thích chi tiết cho từng hàng\n",
    "    print(f\"\\n3. PHÂN TÍCH CHI TIẾT TỪNG HÀNG:\")\n",
    "    for i in range(min(3, display_size)):\n",
    "        print(f\"\\nHàng {i} (Câu {i}):\")\n",
    "        \n",
    "        # Đếm số cạnh ra\n",
    "        outgoing_edges = 0\n",
    "        connections = []\n",
    "        for j in range(display_size):\n",
    "            if i != j and adjacency_matrix[i, j] == 1:\n",
    "                outgoing_edges += 1\n",
    "                connections.append(f\"S{j}\")\n",
    "        \n",
    "        print(f\"   - Câu: '{summarizer.sentences[i]['original'][:60]}...'\")\n",
    "        print(f\"   - Cosine similarity với các câu khác:\")\n",
    "        for j in range(display_size):\n",
    "            if i != j:\n",
    "                sim_value = summarizer.cosine_matrix[i, j]\n",
    "                edge_status = \"CÓ CẠNH\" if sim_value > threshold else \"KHÔNG CÓ CẠNH\"\n",
    "                print(f\"     + với S{j}: {sim_value:.3f} → {edge_status}\")\n",
    "        \n",
    "        print(f\"   - Tổng số cạnh ra: {outgoing_edges}\")\n",
    "        if connections:\n",
    "            print(f\"   - Liên kết đến: {', '.join(connections)}\")\n",
    "        else:\n",
    "            print(f\"   - Không có liên kết ra\")\n",
    "    \n",
    "    # 4. Giải thích cách tạo ma trận chuyển tiếp\n",
    "    print(f\"\\n4. CÁCH TẠO MA TRẬN CHUYỂN TIẾP:\")\n",
    "    print(f\"   Quy tắc chuẩn hóa:\")\n",
    "    print(f\"   - Nếu hàng có cạnh ra: chia mỗi phần tử cho tổng hàng\")\n",
    "    print(f\"   - Nếu hàng không có cạnh ra: phân bố đều = 1/N cho tất cả\")\n",
    "    \n",
    "    # Hiển thị ma trận chuyển tiếp\n",
    "    print(f\"\\nMa trận chuyển tiếp ({display_size}x{display_size} đầu tiên):\")\n",
    "    print(\"      \", end=\"\")\n",
    "    for j in range(display_size):\n",
    "        print(f\"S{j:<8}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for i in range(display_size):\n",
    "        print(f\"S{i:<4} \", end=\"\")\n",
    "        for j in range(display_size):\n",
    "            print(f\"{transition_matrix[i,j]:<8.3f}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    # 5. Giải thích chi tiết quá trình chuẩn hóa\n",
    "    print(f\"\\n5. GIẢI THÍCH QUÁ TRÌNH CHUẨN HÓA:\")\n",
    "    for i in range(min(3, display_size)):\n",
    "        row_sum_adj = sum(adjacency_matrix[i])\n",
    "        row_sum_trans = sum(transition_matrix[i])\n",
    "        \n",
    "        print(f\"\\nHàng {i}:\")\n",
    "        print(f\"   - Ma trận kề: {[int(x) for x in adjacency_matrix[i][:display_size]]}\")\n",
    "        print(f\"   - Tổng hàng ma trận kề: {row_sum_adj}\")\n",
    "        \n",
    "        if row_sum_adj > 0:\n",
    "            print(f\"   - Có {int(row_sum_adj)} cạnh ra → Chuẩn hóa: chia cho {row_sum_adj}\")\n",
    "            print(f\"   - Ma trận chuyển tiếp: {[f'{x:.3f}' for x in transition_matrix[i][:display_size]]}\")\n",
    "        else:\n",
    "            print(f\"   - Không có cạnh ra → Phân bố đều: 1/{display_size} = {1/display_size:.3f}\")\n",
    "            print(f\"   - Ma trận chuyển tiếp: {[f'{x:.3f}' for x in transition_matrix[i][:display_size]]}\")\n",
    "        \n",
    "        print(f\"   - Tổng hàng ma trận chuyển tiếp: {row_sum_trans:.6f} (phải = 1.0)\")\n",
    "        \n",
    "        # Giải thích ý nghĩa\n",
    "        if row_sum_adj == 0:\n",
    "            print(f\"   - Ý nghĩa: Câu {i} sẽ 'nhảy ngẫu nhiên' đến tất cả câu khác với xác suất bằng nhau\")\n",
    "        else:\n",
    "            print(f\"   - Ý nghĩa: Câu {i} sẽ chuyển tiếp theo tỷ lệ cạnh có sẵn\")\n",
    "    \n",
    "    print(f\"\\nBước 4 hoàn thành: Đã mô hình hóa văn bản thành đồ thị\")\n",
    "else:\n",
    "    print(\"Chưa có ma trận cosine similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6ee64e",
   "metadata": {},
   "source": [
    "## 6. Thuật Toán TextRank\n",
    "\n",
    "**Công thức TextRank (dựa trên PageRank):**\n",
    "\n",
    "**TR(Vi) = (1-d) + d × Σ(TR(Vj)/C(Vj))**\n",
    "\n",
    "Trong đó:\n",
    "\n",
    "- **TR(Vi)**: Điểm TextRank của câu Vi\n",
    "- **d**: Damping factor (thường = 0.85)\n",
    "- **Vj**: Các câu có liên kết đến Vi\n",
    "- **C(Vj)**: Số liên kết ra từ câu Vj\n",
    "\n",
    "**Phương pháp Power Iteration:**\n",
    "\n",
    "- Khởi tạo: TR₀ = [1/N, 1/N, ..., 1/N]\n",
    "- Lặp: TR\\_{k+1} = (1-d)/N + d × M^T × TR_k\n",
    "- Dừng khi: ||TR\\_{k+1} - TR_k|| < tolerance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f39065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm thuật toán TextRank\n"
     ]
    }
   ],
   "source": [
    "def calculate_textrank(self):\n",
    "    \"\"\"\n",
    "    Tính TextRank bằng Power Iteration \n",
    "    \"\"\"\n",
    "    print(\"Đang tính TextRank bằng Power Iteration...\")\n",
    "    \n",
    "    if self.transition_matrix is None:\n",
    "        print(\"Chưa có ma trận chuyển tiếp\")\n",
    "        return None\n",
    "    \n",
    "    n = self.transition_matrix.shape[0]\n",
    "    \n",
    "    # Khởi tạo vector TextRank (phân bố đều)\n",
    "    textrank_vector = np.ones(n) / n\n",
    "    print(f\"Khởi tạo: TR₀ = [1/{n}, 1/{n}, ..., 1/{n}] = {1/n:.6f}\")\n",
    "    \n",
    "    print(f\"\\nCông thức TextRank:\")\n",
    "    print(f\"   TR_new = (1-d)/N + d × M^T × TR_old\")\n",
    "    print(f\"   Với d = {self.damping_factor}, N = {n}\")\n",
    "    print(f\"   Teleport term = (1-d)/N = {(1-self.damping_factor)/n:.6f}\")\n",
    "    \n",
    "    # Lưu lịch sử hội tụ\n",
    "    history = []\n",
    "    \n",
    "    print(f\"\\nQuá trình lặp:\")\n",
    "    print(f\"{'Vòng':<6} {'Thay đổi':<15} {'Top 3 điểm':<25}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for iteration in range(self.max_iterations):\n",
    "        # Lưu vector cũ\n",
    "        old_textrank = np.copy(textrank_vector)\n",
    "        \n",
    "        # Áp dụng công thức TextRank\n",
    "        # TR = (1-d)/N + d * M^T * TR_old\n",
    "        teleport_term = (1 - self.damping_factor) / n\n",
    "        random_walk_term = self.damping_factor * np.dot(self.transition_matrix.T, textrank_vector)\n",
    "        textrank_vector = teleport_term + random_walk_term\n",
    "        \n",
    "        # Tính sự thay đổi (norm L2)\n",
    "        change = 0\n",
    "        for i in range(len(textrank_vector)):\n",
    "            diff = textrank_vector[i] - old_textrank[i]\n",
    "            change += diff * diff\n",
    "        change = math.sqrt(change)\n",
    "        \n",
    "        # Lưu lịch sử\n",
    "        history.append((iteration + 1, change, np.copy(textrank_vector)))\n",
    "        \n",
    "        # Hiển thị top 3 điểm cao nhất\n",
    "        top_indices = np.argsort(textrank_vector)[-3:][::-1]\n",
    "        top_scores = [f\"{textrank_vector[i]:.4f}\" for i in top_indices]\n",
    "        top_info = \", \".join(top_scores)\n",
    "        \n",
    "        print(f\"{iteration+1:<6} {change:<15.8f} {top_info:<25}\")\n",
    "        \n",
    "        # Kiểm tra hội tụ\n",
    "        if change < self.tolerance:\n",
    "            print(f\"\\nHội tụ sau {iteration + 1} vòng lặp!\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"\\nĐạt giới hạn {self.max_iterations} vòng lặp\")\n",
    "    \n",
    "    self.textrank_scores = textrank_vector\n",
    "    \n",
    "    return textrank_vector, history\n",
    "\n",
    "def demonstrate_textrank_calculation(self, sentence_idx=0):\n",
    "    \"\"\"\n",
    "    Minh họa chi tiết cách tính TextRank cho một câu cụ thể\n",
    "    \"\"\"\n",
    "    if self.textrank_scores is None or self.adjacency_matrix is None:\n",
    "        print(\"Chưa tính TextRank\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nMinh họa cách tính TextRank cho câu {sentence_idx}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    sentence = self.sentences[sentence_idx]['original'][:80]\n",
    "    print(f\"Câu: '{sentence}...'\")\n",
    "    \n",
    "    n = len(self.sentences)\n",
    "    \n",
    "    # Tìm các câu liên kết đến câu này\n",
    "    incoming_links = []\n",
    "    for i in range(n):\n",
    "        if self.adjacency_matrix[i, sentence_idx] == 1:\n",
    "            incoming_links.append(i)\n",
    "    \n",
    "    print(f\"\\n1. CÁC CÂU LIÊN KẾT ĐẾN:\")\n",
    "    if incoming_links:\n",
    "        for link_idx in incoming_links:\n",
    "            link_sentence = self.sentences[link_idx]['original'][:50]\n",
    "            outgoing_count = np.sum(self.adjacency_matrix[link_idx])\n",
    "            print(f\"   - Câu {link_idx}: '{link_sentence}...' (có {int(outgoing_count)} liên kết ra)\")\n",
    "    else:\n",
    "        print(\"   - Không có liên kết đến\")\n",
    "    \n",
    "    print(f\"\\n2. CÔNG THỨC TEXTRANK:\")\n",
    "    print(f\"   TR(S{sentence_idx}) = (1-d)/N + d × Σ(TR(Si)/C(Si))\")\n",
    "    \n",
    "    # Tính từng thành phần\n",
    "    teleport_term = (1 - self.damping_factor) / n\n",
    "    print(f\"\\n3. TÍNH TOÁN CHI TIẾT:\")\n",
    "    print(f\"   a) Teleport term = (1-d)/N = (1-{self.damping_factor})/{n} = {teleport_term:.6f}\")\n",
    "    \n",
    "    link_contribution = 0\n",
    "    print(f\"   b) Link contribution:\")\n",
    "    if incoming_links:\n",
    "        for link_idx in incoming_links:\n",
    "            tr_link = self.textrank_scores[link_idx]\n",
    "            outgoing_count = np.sum(self.adjacency_matrix[link_idx])\n",
    "            contribution = tr_link / outgoing_count if outgoing_count > 0 else 0\n",
    "            link_contribution += contribution\n",
    "            print(f\"      - Từ câu {link_idx}: TR = {tr_link:.6f}, \"\n",
    "                  f\"C = {int(outgoing_count)}, \"\n",
    "                  f\"Contribution = {tr_link:.6f}/{int(outgoing_count)} = {contribution:.6f}\")\n",
    "        \n",
    "        print(f\"      Tổng link contribution = {link_contribution:.6f}\")\n",
    "    else:\n",
    "        print(f\"      Không có liên kết → contribution = 0\")\n",
    "    \n",
    "    final_textrank = teleport_term + self.damping_factor * link_contribution\n",
    "    actual_textrank = self.textrank_scores[sentence_idx]\n",
    "    \n",
    "    print(f\"\\n4. KẾT QUẢ CUỐI CÙNG:\")\n",
    "    print(f\"   TR(S{sentence_idx}) = {teleport_term:.6f} + {self.damping_factor} × {link_contribution:.6f}\")\n",
    "    print(f\"   TR(S{sentence_idx}) = {teleport_term:.6f} + {self.damping_factor * link_contribution:.6f}\")\n",
    "    print(f\"   TR(S{sentence_idx}) = {final_textrank:.6f}\")\n",
    "    print(f\"   TextRank thực tế: {actual_textrank:.6f}\")\n",
    "    print(f\"   Sai số: {abs(final_textrank - actual_textrank):.8f}\")\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.calculate_textrank = calculate_textrank\n",
    "TextSummarizerTFIDFTextRank.demonstrate_textrank_calculation = demonstrate_textrank_calculation\n",
    "\n",
    "print(\"Đã thêm thuật toán TextRank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f268b910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tính TextRank bằng Power Iteration...\n",
      "Khởi tạo: TR₀ = [1/183, 1/183, ..., 1/183] = 0.005464\n",
      "\n",
      "Công thức TextRank:\n",
      "   TR_new = (1-d)/N + d × M^T × TR_old\n",
      "   Với d = 0.85, N = 183\n",
      "   Teleport term = (1-d)/N = 0.000820\n",
      "\n",
      "Quá trình lặp:\n",
      "Vòng   Thay đổi        Top 3 điểm               \n",
      "--------------------------------------------------\n",
      "1      0.03483103      0.0145, 0.0137, 0.0115   \n",
      "2      0.01351002      0.0122, 0.0115, 0.0111   \n",
      "3      0.00575640      0.0137, 0.0123, 0.0123   \n",
      "4      0.00326619      0.0137, 0.0128, 0.0120   \n",
      "5      0.00180431      0.0140, 0.0131, 0.0123   \n",
      "6      0.00116358      0.0141, 0.0133, 0.0123   \n",
      "7      0.00071747      0.0142, 0.0134, 0.0125   \n",
      "8      0.00049179      0.0142, 0.0135, 0.0125   \n",
      "9      0.00032288      0.0143, 0.0136, 0.0126   \n",
      "10     0.00022801      0.0143, 0.0136, 0.0126   \n",
      "11     0.00015580      0.0143, 0.0136, 0.0126   \n",
      "12     0.00011194      0.0143, 0.0137, 0.0126   \n",
      "13     0.00007853      0.0143, 0.0137, 0.0126   \n",
      "14     0.00005709      0.0143, 0.0137, 0.0127   \n",
      "15     0.00004077      0.0143, 0.0137, 0.0127   \n",
      "16     0.00002990      0.0143, 0.0137, 0.0127   \n",
      "17     0.00002163      0.0143, 0.0137, 0.0127   \n",
      "18     0.00001597      0.0143, 0.0137, 0.0127   \n",
      "19     0.00001167      0.0143, 0.0137, 0.0127   \n",
      "20     0.00000866      0.0143, 0.0137, 0.0127   \n",
      "21     0.00000638      0.0143, 0.0137, 0.0127   \n",
      "22     0.00000476      0.0143, 0.0137, 0.0127   \n",
      "23     0.00000352      0.0143, 0.0137, 0.0127   \n",
      "24     0.00000264      0.0143, 0.0137, 0.0127   \n",
      "25     0.00000197      0.0143, 0.0137, 0.0127   \n",
      "26     0.00000148      0.0143, 0.0137, 0.0127   \n",
      "27     0.00000111      0.0143, 0.0137, 0.0127   \n",
      "28     0.00000083      0.0143, 0.0137, 0.0127   \n",
      "\n",
      "Hội tụ sau 28 vòng lặp!\n",
      "\n",
      "Minh họa cách tính TextRank cho câu 0\n",
      "======================================================================\n",
      "Câu: 'Hurricane Gilbert swept toward the Dominican Republic Sunday, and the Civil Defe...'\n",
      "\n",
      "1. CÁC CÂU LIÊN KẾT ĐẾN:\n",
      "   - Câu 10: 'San Juan, on the north coast, had heavy rains and ...' (có 13 liên kết ra)\n",
      "   - Câu 44: 'Heavy rain and stiff winds downed power lines and ...' (có 22 liên kết ra)\n",
      "   - Câu 46: 'Flights were canceled Sunday in the Dominican Repu...' (có 15 liên kết ra)\n",
      "   - Câu 61: 'Hurricane warnings were issued Monday for the sout...' (có 17 liên kết ra)\n",
      "   - Câu 62: 'High winds and heavy rain preceding the storm dren...' (có 5 liên kết ra)\n",
      "   - Câu 106: 'The Mexican National Weather Service reported wind...' (có 16 liên kết ra)\n",
      "   - Câu 119: 'In Mexico City, the National Civil Defense System ...' (có 10 liên kết ra)\n",
      "   - Câu 127: 'On Sunday, Monday and Tuesday, Gilbert pounded the...' (có 20 liên kết ra)\n",
      "   - Câu 129: 'Officials in the Dominican Republic, sideswiped Su...' (có 9 liên kết ra)\n",
      "   - Câu 166: 'Hurricane Gilbert swept toward Jamaica yesterday w...' (có 19 liên kết ra)\n",
      "\n",
      "2. CÔNG THỨC TEXTRANK:\n",
      "   TR(S0) = (1-d)/N + d × Σ(TR(Si)/C(Si))\n",
      "\n",
      "3. TÍNH TOÁN CHI TIẾT:\n",
      "   a) Teleport term = (1-d)/N = (1-0.85)/183 = 0.000820\n",
      "   b) Link contribution:\n",
      "      - Từ câu 10: TR = 0.009761, C = 13, Contribution = 0.009761/13 = 0.000751\n",
      "      - Từ câu 44: TR = 0.013717, C = 22, Contribution = 0.013717/22 = 0.000624\n",
      "      - Từ câu 46: TR = 0.010089, C = 15, Contribution = 0.010089/15 = 0.000673\n",
      "      - Từ câu 61: TR = 0.010499, C = 17, Contribution = 0.010499/17 = 0.000618\n",
      "      - Từ câu 62: TR = 0.004163, C = 5, Contribution = 0.004163/5 = 0.000833\n",
      "      - Từ câu 106: TR = 0.011129, C = 16, Contribution = 0.011129/16 = 0.000696\n",
      "      - Từ câu 119: TR = 0.008384, C = 10, Contribution = 0.008384/10 = 0.000838\n",
      "      - Từ câu 127: TR = 0.012679, C = 20, Contribution = 0.012679/20 = 0.000634\n",
      "      - Từ câu 129: TR = 0.005829, C = 9, Contribution = 0.005829/9 = 0.000648\n",
      "      - Từ câu 166: TR = 0.012012, C = 19, Contribution = 0.012012/19 = 0.000632\n",
      "      Tổng link contribution = 0.006945\n",
      "\n",
      "4. KẾT QUẢ CUỐI CÙNG:\n",
      "   TR(S0) = 0.000820 + 0.85 × 0.006945\n",
      "   TR(S0) = 0.000820 + 0.005903\n",
      "   TR(S0) = 0.006723\n",
      "   TextRank thực tế: 0.006750\n",
      "   Sai số: 0.00002751\n",
      "\n",
      "KẾT QUẢ TEXTRANK:\n",
      "============================================================\n",
      "Hạng   Điểm TR      Câu                                                         \n",
      "--------------------------------------------------------------------------------\n",
      "1      0.014347     A National Weather Service report said the hurricane wa...\n",
      "2      0.013717     Heavy rain and stiff winds downed power lines and cause...\n",
      "3      0.012679     On Sunday, Monday and Tuesday, Gilbert pounded the Domi...\n",
      "4      0.012653     Hurricane Gilbert, packing 110 mph winds and torrential...\n",
      "5      0.012646     Forecasters said the hurricane's track would take it ab...\n",
      "6      0.012357     Gilbert reached Jamaica after skirting southern Puerto ...\n",
      "7      0.012012     Hurricane Gilbert swept toward Jamaica yesterday with 1...\n",
      "8      0.011872     Maximum sustained winds were near 110 mph, with tropica...\n",
      "9      0.011558     Warnings were discontinued for the Dominican Republic....\n",
      "10     0.011129     The Mexican National Weather Service reported winds gus...\n",
      "\n",
      "Thống kê TextRank:\n",
      "   - Tổng điểm: 1.000000\n",
      "   - Điểm trung bình: 0.005464\n",
      "   - Độ lệch chuẩn: 0.002822\n",
      "   - Điểm cao nhất: 0.014347\n",
      "   - Điểm thấp nhất: 0.000847\n",
      "\n",
      "Bước 5 hoàn thành: Đã tính TextRank cho 183 câu\n"
     ]
    }
   ],
   "source": [
    "# Thực nghiệm: Tính TextRank\n",
    "if summarizer.transition_matrix is not None:\n",
    "    # Tính TextRank\n",
    "    textrank_scores, history = summarizer.calculate_textrank()\n",
    "    \n",
    "    # Minh họa cách tính cho một câu\n",
    "    if len(summarizer.sentences) > 0:\n",
    "        summarizer.demonstrate_textrank_calculation(0)\n",
    "    \n",
    "    # Hiển thị kết quả TextRank\n",
    "    print(f\"\\nKẾT QUẢ TEXTRANK:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Tạo danh sách kết quả\n",
    "    results = []\n",
    "    for i, score in enumerate(textrank_scores):\n",
    "        results.append({\n",
    "            'index': i,\n",
    "            'score': score,\n",
    "            'sentence': summarizer.sentences[i]['original']\n",
    "        })\n",
    "    \n",
    "    # Sắp xếp theo điểm giảm dần\n",
    "    results.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    print(f\"{'Hạng':<6} {'Điểm TR':<12} {'Câu':<60}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Hiển thị top 10\n",
    "    for rank, result in enumerate(results[:10], 1):\n",
    "        sentence_preview = result['sentence'][:55]\n",
    "        print(f\"{rank:<6} {result['score']:<12.6f} {sentence_preview}...\")\n",
    "    \n",
    "    # Thống kê\n",
    "    print(f\"\\nThống kê TextRank:\")\n",
    "    print(f\"   - Tổng điểm: {np.sum(textrank_scores):.6f}\")\n",
    "    print(f\"   - Điểm trung bình: {np.mean(textrank_scores):.6f}\")\n",
    "    print(f\"   - Độ lệch chuẩn: {np.std(textrank_scores):.6f}\")\n",
    "    print(f\"   - Điểm cao nhất: {np.max(textrank_scores):.6f}\")\n",
    "    print(f\"   - Điểm thấp nhất: {np.min(textrank_scores):.6f}\")\n",
    "    \n",
    "    print(f\"\\nBước 5 hoàn thành: Đã tính TextRank cho {len(textrank_scores)} câu\")\n",
    "else:\n",
    "    print(\"Chưa có ma trận chuyển tiếp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a03746",
   "metadata": {},
   "source": [
    "## 7. Tạo Bản Tóm Tắt (Lấy 10% Câu Quan Trọng Nhất)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dd02d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Đã thêm các phương thức tạo tóm tắt\n"
     ]
    }
   ],
   "source": [
    "def generate_summary(self, summary_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Tạo bản tóm tắt bằng cách chọn top câu có điểm TextRank cao nhất\n",
    "    \"\"\"\n",
    "    print(f\"Đang tạo bản tóm tắt với tỷ lệ {summary_ratio*100}%...\")\n",
    "    \n",
    "    if self.textrank_scores is None:\n",
    "        print(\"Chưa tính TextRank\")\n",
    "        return None\n",
    "    \n",
    "    total_sentences = len(self.sentences)\n",
    "    num_summary_sentences = max(1, int(total_sentences * summary_ratio))\n",
    "    \n",
    "    print(f\"Chọn {num_summary_sentences} câu từ {total_sentences} câu gốc\")\n",
    "    \n",
    "    # Tạo danh sách câu với điểm số và vị trí gốc\n",
    "    sentence_scores = []\n",
    "    for i, score in enumerate(self.textrank_scores):\n",
    "        sentence_scores.append({\n",
    "            'index': i,\n",
    "            'score': score,\n",
    "            'sentence': self.sentences[i]['original']\n",
    "        })\n",
    "    \n",
    "    # Sắp xếp theo điểm TextRank giảm dần\n",
    "    sentence_scores.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # Chọn top câu\n",
    "    selected_sentences = sentence_scores[:num_summary_sentences]\n",
    "    \n",
    "    # Sắp xếp lại theo thứ tự xuất hiện trong văn bản gốc\n",
    "    selected_sentences.sort(key=lambda x: x['index'])\n",
    "    \n",
    "    # Tạo văn bản tóm tắt\n",
    "    summary_text = []\n",
    "    for item in selected_sentences:\n",
    "        summary_text.append(item['sentence'])\n",
    "    \n",
    "    summary = {\n",
    "        'sentences': selected_sentences,\n",
    "        'text': ' '.join(summary_text),\n",
    "        'ratio': summary_ratio,\n",
    "        'original_count': total_sentences,\n",
    "        'summary_count': num_summary_sentences\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def display_summary(self, summary):\n",
    "    \"\"\"\n",
    "    Hiển thị bản tóm tắt\n",
    "    \"\"\"\n",
    "    if summary is None:\n",
    "        print(\"Không có bản tóm tắt\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nBẢN TÓM TẮT:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Tỷ lệ: {summary['ratio']*100}% ({summary['summary_count']}/{summary['original_count']} câu)\")\n",
    "    print(f\"Độ dài: {len(summary['text'])} ký tự\")\n",
    "    print()\n",
    "    \n",
    "    # Hiển thị từng câu được chọn\n",
    "    print(\"Các câu được chọn:\")\n",
    "    for i, item in enumerate(summary['sentences'], 1):\n",
    "        print(f\"{i}. [Câu {item['index']}, Điểm: {item['score']:.4f}]\")\n",
    "        print(f\"   {item['sentence']}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"Văn bản tóm tắt liên tục:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(summary['text'])\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.generate_summary = generate_summary\n",
    "TextSummarizerTFIDFTextRank.display_summary = display_summary\n",
    "\n",
    "print(\"  Đã thêm các phương thức tạo tóm tắt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "837fc6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tạo bản tóm tắt với tỷ lệ 10.0%...\n",
      "Chọn 18 câu từ 183 câu gốc\n",
      "\n",
      "BẢN TÓM TẮT:\n",
      "======================================================================\n",
      "Tỷ lệ: 10.0% (18/183 câu)\n",
      "Độ dài: 2381 ký tự\n",
      "\n",
      "Các câu được chọn:\n",
      "1. [Câu 10, Điểm: 0.0098]\n",
      "   San Juan, on the north coast, had heavy rains and gusts Saturday, but they subsided during the night.\n",
      "\n",
      "2. [Câu 15, Điểm: 0.0127]\n",
      "   Hurricane Gilbert, packing 110 mph winds and torrential rain, moved over this capital city today after skirting Puerto Rico, Haiti and the Dominican Republic.\n",
      "\n",
      "3. [Câu 26, Điểm: 0.0116]\n",
      "   Warnings were discontinued for the Dominican Republic.\n",
      "\n",
      "4. [Câu 37, Điểm: 0.0119]\n",
      "   Maximum sustained winds were near 110 mph, with tropical-storm force winds extending up to 250 miles to the north and 100 miles to the south.\n",
      "\n",
      "5. [Câu 44, Điểm: 0.0137]\n",
      "   Heavy rain and stiff winds downed power lines and caused flooding in the Dominican Republic on Sunday night as the hurricane's center passed just south of the Barahona peninsula, then less than 100 miles from neighboring Haiti.\n",
      "\n",
      "6. [Câu 45, Điểm: 0.0095]\n",
      "   The storm ripped the roofs off houses and flooded coastal areas of southwestern Puerto Rico after reaching hurricane strength off the island's southeast Saturday night.\n",
      "\n",
      "7. [Câu 46, Điểm: 0.0101]\n",
      "   Flights were canceled Sunday in the Dominican Republic, where civil defense director Eugenio Cabral reported some flooding in parts of the capital of Santo Domingo and power outages there and in other southern areas .\n",
      "\n",
      "8. [Câu 56, Điểm: 0.0143]\n",
      "   A National Weather Service report said the hurricane was moving west at 17 mph with maximum sustained winds of 115 mph.\n",
      "\n",
      "9. [Câu 60, Điểm: 0.0124]\n",
      "   Gilbert reached Jamaica after skirting southern Puerto Rico, Haiti and the Dominican Republic.\n",
      "\n",
      "10. [Câu 61, Điểm: 0.0105]\n",
      "   Hurricane warnings were issued Monday for the south coast of Cuba east of Camaguey, the Cayman Islands, and Haiti, while warnings were discontinued for the Dominican Republic.\n",
      "\n",
      "11. [Câu 87, Điểm: 0.0105]\n",
      "   More than 120,000 people on the northeast Yucatan coast were evacuated, the Yucatan state government said.\n",
      "\n",
      "12. [Câu 105, Điểm: 0.0108]\n",
      "   Gilbert was moving west-northwest at 15 mph and winds had decreased to 125 mph.\n",
      "\n",
      "13. [Câu 106, Điểm: 0.0111]\n",
      "   The Mexican National Weather Service reported winds gusting as high as 218 mph earlier Wednesday with sustained winds of 179 mph.\n",
      "\n",
      "14. [Câu 127, Điểm: 0.0127]\n",
      "   On Sunday, Monday and Tuesday, Gilbert pounded the Dominican Republic, Jamaica and the Cayman Islands.\n",
      "\n",
      "15. [Câu 141, Điểm: 0.0101]\n",
      "   When sustained winds reach 39 mph, the system becomes a named tropical storm.\n",
      "\n",
      "16. [Câu 166, Điểm: 0.0120]\n",
      "   Hurricane Gilbert swept toward Jamaica yesterday with 100-mile-an-hour winds, and officials issued warnings to residents on the southern coasts of the Dominican Republic, Haiti and Cuba.\n",
      "\n",
      "17. [Câu 172, Điểm: 0.0108]\n",
      "   At 3 p.m. EDT, the center of the hurricane was about 100 miles south of the Dominican Republic and 425 miles east of Kingston, Jamaica.\n",
      "\n",
      "18. [Câu 174, Điểm: 0.0126]\n",
      "   Forecasters said the hurricane's track would take it about 50 miles south of southwestern Haiti.\n",
      "\n",
      "Văn bản tóm tắt liên tục:\n",
      "--------------------------------------------------\n",
      "San Juan, on the north coast, had heavy rains and gusts Saturday, but they subsided during the night. Hurricane Gilbert, packing 110 mph winds and torrential rain, moved over this capital city today after skirting Puerto Rico, Haiti and the Dominican Republic. Warnings were discontinued for the Dominican Republic. Maximum sustained winds were near 110 mph, with tropical-storm force winds extending up to 250 miles to the north and 100 miles to the south. Heavy rain and stiff winds downed power lines and caused flooding in the Dominican Republic on Sunday night as the hurricane's center passed just south of the Barahona peninsula, then less than 100 miles from neighboring Haiti. The storm ripped the roofs off houses and flooded coastal areas of southwestern Puerto Rico after reaching hurricane strength off the island's southeast Saturday night. Flights were canceled Sunday in the Dominican Republic, where civil defense director Eugenio Cabral reported some flooding in parts of the capital of Santo Domingo and power outages there and in other southern areas . A National Weather Service report said the hurricane was moving west at 17 mph with maximum sustained winds of 115 mph. Gilbert reached Jamaica after skirting southern Puerto Rico, Haiti and the Dominican Republic. Hurricane warnings were issued Monday for the south coast of Cuba east of Camaguey, the Cayman Islands, and Haiti, while warnings were discontinued for the Dominican Republic. More than 120,000 people on the northeast Yucatan coast were evacuated, the Yucatan state government said. Gilbert was moving west-northwest at 15 mph and winds had decreased to 125 mph. The Mexican National Weather Service reported winds gusting as high as 218 mph earlier Wednesday with sustained winds of 179 mph. On Sunday, Monday and Tuesday, Gilbert pounded the Dominican Republic, Jamaica and the Cayman Islands. When sustained winds reach 39 mph, the system becomes a named tropical storm. Hurricane Gilbert swept toward Jamaica yesterday with 100-mile-an-hour winds, and officials issued warnings to residents on the southern coasts of the Dominican Republic, Haiti and Cuba. At 3 p.m. EDT, the center of the hurricane was about 100 miles south of the Dominican Republic and 425 miles east of Kingston, Jamaica. Forecasters said the hurricane's track would take it about 50 miles south of southwestern Haiti.\n",
      "\n",
      "Đã lưu bản tóm tắt vào: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK/output_summary.docx\n",
      "\n",
      "Bước 6-7 hoàn thành: Đã tạo và lưu bản tóm tắt\n"
     ]
    }
   ],
   "source": [
    "# Thực nghiệm: Tạo bản tóm tắt và lưu vào Word\n",
    "if summarizer.textrank_scores is not None:\n",
    "    # Tạo tóm tắt với 10% câu\n",
    "    summary = summarizer.generate_summary(summary_ratio=0.1)\n",
    "    \n",
    "    # Hiển thị tóm tắt\n",
    "    summarizer.display_summary(summary)\n",
    "    \n",
    "    # Lưu tóm tắt vào file Word (output_summary.docx)\n",
    "    if summary:\n",
    "        output_filename = os.path.join(BASE_PATH, \"output_summary.docx\")\n",
    "        \n",
    "        # Tạo document Word với format đẹp\n",
    "        doc = Document()\n",
    "        doc.add_heading('BẢN TÓM TẮT VĂN BẢN BẰNG TEXTRANK', 0)\n",
    "        \n",
    "        # Thông tin tóm tắt\n",
    "        doc.add_heading('Thông tin tóm tắt:', level=1)\n",
    "        info_para = doc.add_paragraph()\n",
    "        info_para.add_run(f\"• Tỷ lệ tóm tắt: {summary['ratio']*100}%\\n\")\n",
    "        info_para.add_run(f\"• Số câu gốc: {summary['original_count']}\\n\")\n",
    "        info_para.add_run(f\"• Số câu tóm tắt: {summary['summary_count']}\\n\")\n",
    "        info_para.add_run(f\"• Độ dài: {len(summary['text'])} ký tự\\n\")\n",
    "        \n",
    "        # Văn bản tóm tắt\n",
    "        doc.add_heading('Văn bản tóm tắt:', level=1)\n",
    "        doc.add_paragraph(summary['text'])\n",
    "        \n",
    "        # Chi tiết các câu được chọn\n",
    "        doc.add_heading('Chi tiết các câu được chọn:', level=1)\n",
    "        for i, item in enumerate(summary['sentences'], 1):\n",
    "            para = doc.add_paragraph()\n",
    "            para.add_run(f\"{i}. \").bold = True\n",
    "            para.add_run(f\"[Câu {item['index']}, Điểm TextRank: {item['score']:.4f}]\\n\")\n",
    "            para.add_run(item['sentence'])\n",
    "        \n",
    "        doc.save(output_filename)\n",
    "        print(f\"\\nĐã lưu bản tóm tắt vào: {output_filename}\")\n",
    "        \n",
    "        print(f\"\\nBước 6-7 hoàn thành: Đã tạo và lưu bản tóm tắt\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Không thể tạo tóm tắt\")\n",
    "        \n",
    "else:\n",
    "    print(\"Chưa tính TextRank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d8fe4",
   "metadata": {},
   "source": [
    "## 8. Đọc DUC Reference Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08a3b8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tìm DUC reference cho: d061j\n",
      "  Đã đọc reference: 2409 ký tự\n",
      "  Preview: Tropical Storm Gilbert formed in the eastern Caribbean and strengthened into a hurricane Saturday ni...\n",
      "Đã lưu DUC reference vào: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK/Test_DUC_SUM.docx\n",
      "\n",
      "Bước 8 hoàn thành: Đã đọc và lưu DUC reference summary\n"
     ]
    }
   ],
   "source": [
    "# Bước 8: Đọc DUC reference summary tương ứng\n",
    "def load_duc_reference(doc_filename):\n",
    "    \"\"\"\n",
    "    Đọc file DUC reference summary tương ứng với tài liệu\n",
    "    \"\"\"\n",
    "    print(f\"Đang tìm DUC reference cho: {doc_filename}\")\n",
    "    \n",
    "    # Tìm file reference tương ứng\n",
    "    reference_path = os.path.join(DUC_SUM_PATH, doc_filename)\n",
    "    \n",
    "    if os.path.exists(reference_path):\n",
    "        try:\n",
    "            with open(reference_path, 'r', encoding='utf-8') as f:\n",
    "                reference_content = f.read()\n",
    "            \n",
    "            # Làm sạch nội dung reference\n",
    "            reference_content = re.sub(r'<[^>]+>', '', reference_content)\n",
    "            reference_content = reference_content.strip()\n",
    "            \n",
    "            print(f\"  Đã đọc reference: {len(reference_content)} ký tự\")\n",
    "            print(f\"  Preview: {reference_content[:100]}...\")\n",
    "            \n",
    "            return reference_content\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc reference: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Không tìm thấy file reference: {reference_path}\")\n",
    "        return None\n",
    "\n",
    "# Demo: Đọc DUC reference và lưu vào Word\n",
    "if os.path.exists(DUC_TEXT_PATH):\n",
    "    files = [f for f in os.listdir(DUC_TEXT_PATH) if not f.startswith('.')]\n",
    "    if files and 'demo_file' in locals():\n",
    "        # Sử dụng cùng file đã chọn ở bước 1\n",
    "        \n",
    "        # Đọc reference\n",
    "        reference_content = load_duc_reference(demo_file)\n",
    "        \n",
    "        if reference_content:\n",
    "            # Lưu reference vào file Word (Test_DUC_SUM.docx)\n",
    "            reference_filename = os.path.join(BASE_PATH, \"Test_DUC_SUM.docx\")\n",
    "            \n",
    "            doc = Document()\n",
    "            doc.add_heading('DUC REFERENCE SUMMARY', 0)\n",
    "            \n",
    "            # Thông tin file\n",
    "            doc.add_heading('Thông tin:', level=1)\n",
    "            info_para = doc.add_paragraph()\n",
    "            info_para.add_run(f\"• File gốc: {demo_file}\\n\")\n",
    "            info_para.add_run(f\"• Đường dẫn reference: {os.path.join(DUC_SUM_PATH, demo_file)}\\n\")\n",
    "            info_para.add_run(f\"• Độ dài: {len(reference_content)} ký tự\\n\")\n",
    "            \n",
    "            # Nội dung reference\n",
    "            doc.add_heading('Nội dung reference summary:', level=1)\n",
    "            doc.add_paragraph(reference_content)\n",
    "            \n",
    "            doc.save(reference_filename)\n",
    "            print(f\"Đã lưu DUC reference vào: {reference_filename}\")\n",
    "            \n",
    "            # Lưu vào biến để sử dụng trong evaluation\n",
    "            duc_reference = reference_content\n",
    "            \n",
    "            print(f\"\\nBước 8 hoàn thành: Đã đọc và lưu DUC reference summary\")\n",
    "        else:\n",
    "            duc_reference = None\n",
    "            print(\"Không thể đọc DUC reference\")\n",
    "    else:\n",
    "        print(\"Không có file để xử lý\")\n",
    "        duc_reference = None\n",
    "else:\n",
    "    print(f\"Thư mục không tồn tại: {DUC_TEXT_PATH}\")\n",
    "    duc_reference = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8d9ca",
   "metadata": {},
   "source": [
    "## 9. Đánh Giá Bằng ROUGE Metrics\n",
    "\n",
    "**ROUGE (Recall-Oriented Understudy for Gisting Evaluation):**\n",
    "\n",
    "- **ROUGE-1**: Đo overlap của unigrams (từ đơn)\n",
    "- **ROUGE-2**: Đo overlap của bigrams (cặp từ)\n",
    "- **ROUGE-L**: Đo Longest Common Subsequence (LCS)\n",
    "\n",
    "**Công thức:**\n",
    "\n",
    "- **Precision** = (số từ chung) / (số từ trong summary)\n",
    "- **Recall** = (số từ chung) / (số từ trong reference)\n",
    "- **F1-Score** = 2 × (Precision × Recall) / (Precision + Recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9f31592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Đã thêm các phương thức đánh giá ROUGE\n"
     ]
    }
   ],
   "source": [
    "def calculate_rouge_1(generated_summary, reference_summary):\n",
    "    \"\"\"\n",
    "    Tính ROUGE-1 (unigram overlap)\n",
    "    \"\"\"\n",
    "    # Tách từ và làm sạch\n",
    "    gen_words = re.findall(r'\\b\\w+\\b', generated_summary.lower())\n",
    "    ref_words = re.findall(r'\\b\\w+\\b', reference_summary.lower())\n",
    "    \n",
    "    # Đếm từ\n",
    "    gen_word_count = Counter(gen_words)\n",
    "    ref_word_count = Counter(ref_words)\n",
    "    \n",
    "    # Tính overlap\n",
    "    overlap = 0\n",
    "    for word in gen_word_count:\n",
    "        if word in ref_word_count:\n",
    "            overlap += min(gen_word_count[word], ref_word_count[word])\n",
    "    \n",
    "    # Tính precision, recall, f1\n",
    "    precision = overlap / len(gen_words) if len(gen_words) > 0 else 0\n",
    "    recall = overlap / len(ref_words) if len(ref_words) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'overlap': overlap,\n",
    "        'gen_length': len(gen_words),\n",
    "        'ref_length': len(ref_words)\n",
    "    }\n",
    "\n",
    "def calculate_rouge_2(generated_summary, reference_summary):\n",
    "    \"\"\"\n",
    "    Tính ROUGE-2 (bigram overlap) \n",
    "    \"\"\"\n",
    "    # Tách từ\n",
    "    gen_words = re.findall(r'\\b\\w+\\b', generated_summary.lower())\n",
    "    ref_words = re.findall(r'\\b\\w+\\b', reference_summary.lower())\n",
    "    \n",
    "    # Tạo bigrams\n",
    "    gen_bigrams = []\n",
    "    for i in range(len(gen_words) - 1):\n",
    "        gen_bigrams.append((gen_words[i], gen_words[i+1]))\n",
    "    \n",
    "    ref_bigrams = []\n",
    "    for i in range(len(ref_words) - 1):\n",
    "        ref_bigrams.append((ref_words[i], ref_words[i+1]))\n",
    "    \n",
    "    # Đếm bigrams\n",
    "    gen_bigram_count = Counter(gen_bigrams)\n",
    "    ref_bigram_count = Counter(ref_bigrams)\n",
    "    \n",
    "    # Tính overlap\n",
    "    overlap = 0\n",
    "    for bigram in gen_bigram_count:\n",
    "        if bigram in ref_bigram_count:\n",
    "            overlap += min(gen_bigram_count[bigram], ref_bigram_count[bigram])\n",
    "    \n",
    "    # Tính precision, recall, f1\n",
    "    precision = overlap / len(gen_bigrams) if len(gen_bigrams) > 0 else 0\n",
    "    recall = overlap / len(ref_bigrams) if len(ref_bigrams) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'overlap': overlap,\n",
    "        'gen_length': len(gen_bigrams),\n",
    "        'ref_length': len(ref_bigrams)\n",
    "    }\n",
    "\n",
    "def calculate_lcs_length(seq1, seq2):\n",
    "    \"\"\"\n",
    "    Tính độ dài Longest Common Subsequence \n",
    "    \"\"\"\n",
    "    m, n = len(seq1), len(seq2)\n",
    "    \n",
    "    # Tạo bảng DP\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    \n",
    "    # Fill bảng DP\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if seq1[i-1] == seq2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
    "    \n",
    "    return dp[m][n]\n",
    "\n",
    "def calculate_rouge_l(generated_summary, reference_summary):\n",
    "    \"\"\"\n",
    "    Tính ROUGE-L (LCS-based) \n",
    "    \"\"\"\n",
    "    # Tách từ\n",
    "    gen_words = re.findall(r'\\b\\w+\\b', generated_summary.lower())\n",
    "    ref_words = re.findall(r'\\b\\w+\\b', reference_summary.lower())\n",
    "    \n",
    "    # Tính LCS\n",
    "    lcs_length = calculate_lcs_length(gen_words, ref_words)\n",
    "    \n",
    "    # Tính precision, recall, f1\n",
    "    precision = lcs_length / len(gen_words) if len(gen_words) > 0 else 0\n",
    "    recall = lcs_length / len(ref_words) if len(ref_words) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'lcs_length': lcs_length,\n",
    "        'gen_length': len(gen_words),\n",
    "        'ref_length': len(ref_words)\n",
    "    }\n",
    "\n",
    "def evaluate_summary(generated_summary, reference_summary):\n",
    "    \"\"\"\n",
    "    Đánh giá toàn diện bằng ROUGE metrics\n",
    "    \"\"\"\n",
    "    print(\"Đang đánh giá bằng ROUGE metrics...\")\n",
    "    \n",
    "    # Tính các ROUGE scores\n",
    "    rouge_1 = calculate_rouge_1(generated_summary, reference_summary)\n",
    "    rouge_2 = calculate_rouge_2(generated_summary, reference_summary)\n",
    "    rouge_l = calculate_rouge_l(generated_summary, reference_summary)\n",
    "    \n",
    "    # Hiển thị kết quả\n",
    "    print(f\"\\nKẾT QUẢ ĐÁNH GIÁ ROUGE:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nROUGE-1 (Unigram Overlap):\")\n",
    "    print(f\"   Precision: {rouge_1['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {rouge_1['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {rouge_1['f1']:.4f}\")\n",
    "    print(f\"   Overlap:   {rouge_1['overlap']}/{rouge_1['gen_length']} vs {rouge_1['ref_length']} words\")\n",
    "    \n",
    "    print(f\"\\nROUGE-2 (Bigram Overlap):\")\n",
    "    print(f\"   Precision: {rouge_2['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {rouge_2['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {rouge_2['f1']:.4f}\")\n",
    "    print(f\"   Overlap:   {rouge_2['overlap']}/{rouge_2['gen_length']} vs {rouge_2['ref_length']} bigrams\")\n",
    "    \n",
    "    print(f\"\\nROUGE-L (LCS-based):\")\n",
    "    print(f\"   Precision: {rouge_l['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {rouge_l['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {rouge_l['f1']:.4f}\")\n",
    "    print(f\"   LCS:       {rouge_l['lcs_length']}/{rouge_l['gen_length']} vs {rouge_l['ref_length']} words\")\n",
    "    \n",
    "    # Tính điểm tổng hợp\n",
    "    overall_f1 = (rouge_1['f1'] + rouge_2['f1'] + rouge_l['f1']) / 3\n",
    "    print(f\"\\nĐIỂM TỔNG HỢP:\")\n",
    "    print(f\"   Overall F1-Score: {overall_f1:.4f}\")\n",
    "    \n",
    "    # Đánh giá chất lượng\n",
    "    if overall_f1 >= 0.5:\n",
    "        quality = \"Xuất sắc\"\n",
    "    elif overall_f1 >= 0.3:\n",
    "        quality = \"Tốt\"\n",
    "    elif overall_f1 >= 0.2:\n",
    "        quality = \"Khá\"\n",
    "    elif overall_f1 >= 0.1:\n",
    "        quality = \"Trung bình\"\n",
    "    else:\n",
    "        quality = \"Cần cải thiện\"\n",
    "    \n",
    "    print(f\"   Chất lượng tóm tắt: {quality}\")\n",
    "    \n",
    "    return {\n",
    "        'rouge_1': rouge_1,\n",
    "        'rouge_2': rouge_2,\n",
    "        'rouge_l': rouge_l,\n",
    "        'overall_f1': overall_f1,\n",
    "        'quality': quality\n",
    "    }\n",
    "\n",
    "print(\"  Đã thêm các phương thức đánh giá ROUGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eeff4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu đánh giá so sánh...\n",
      "======================================================================\n",
      "Generated Summary:\n",
      "------------------------------\n",
      "San Juan, on the north coast, had heavy rains and gusts Saturday, but they subsided during the night. Hurricane Gilbert, packing 110 mph winds and torrential rain, moved over this capital city today after skirting Puerto Rico, Haiti and the Dominican Republic. Warnings were discontinued for the Domi...\n",
      "\n",
      "DUC Reference Summary:\n",
      "------------------------------\n",
      "Tropical Storm Gilbert formed in the eastern Caribbean and strengthened into a hurricane Saturday night.\n",
      " Why Gilbert organized and strengthened while other systems didn't ``is a mystery more or less,'' said University of Miami meteorology Professor Rainer Bleck.\n",
      " Gilbert reached Jamaica after skirt...\n",
      "Đang đánh giá bằng ROUGE metrics...\n",
      "\n",
      "KẾT QUẢ ĐÁNH GIÁ ROUGE:\n",
      "============================================================\n",
      "\n",
      "ROUGE-1 (Unigram Overlap):\n",
      "   Precision: 0.5466\n",
      "   Recall:    0.5383\n",
      "   F1-Score:  0.5424\n",
      "   Overlap:   211/386 vs 392 words\n",
      "\n",
      "ROUGE-2 (Bigram Overlap):\n",
      "   Precision: 0.2675\n",
      "   Recall:    0.2634\n",
      "   F1-Score:  0.2655\n",
      "   Overlap:   103/385 vs 391 bigrams\n",
      "\n",
      "ROUGE-L (LCS-based):\n",
      "   Precision: 0.2720\n",
      "   Recall:    0.2679\n",
      "   F1-Score:  0.2699\n",
      "   LCS:       105/386 vs 392 words\n",
      "\n",
      "ĐIỂM TỔNG HỢP:\n",
      "   Overall F1-Score: 0.3593\n",
      "   Chất lượng tóm tắt: Tốt\n",
      "\n",
      "Minh họa cách tính ROUGE-1\n",
      "==================================================\n",
      "Generated words: 386 từ\n",
      "Reference words: 392 từ\n",
      "Từ chung (overlap): 211 từ\n",
      "\n",
      "Công thức ROUGE-1:\n",
      "Precision = overlap / gen_length = 211 / 386 = 0.5466\n",
      "Recall = overlap / ref_length = 211 / 392 = 0.5383\n",
      "F1 = 2 × P × R / (P + R) = 0.5424\n",
      "\n",
      "Bước 9 hoàn thành: Đã đánh giá tóm tắt bằng ROUGE metrics\n"
     ]
    }
   ],
   "source": [
    "# Thực nghiệm: Đánh giá tóm tắt bằng ROUGE\n",
    "if 'summary' in locals() and summary and 'duc_reference' in locals() and duc_reference:\n",
    "    print(\"Bắt đầu đánh giá so sánh...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Hiển thị hai văn bản cần so sánh\n",
    "    print(\"Generated Summary:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(summary['text'][:300] + \"...\" if len(summary['text']) > 300 else summary['text'])\n",
    "    \n",
    "    print(f\"\\nDUC Reference Summary:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(duc_reference[:300] + \"...\" if len(duc_reference) > 300 else duc_reference)\n",
    "    \n",
    "    # Đánh giá ROUGE\n",
    "    evaluation_results = evaluate_summary(summary['text'], duc_reference)\n",
    "    \n",
    "    # Demo: Minh họa cách tính ROUGE-1 chi tiết\n",
    "    print(f\"\\nMinh họa cách tính ROUGE-1\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    gen_words = re.findall(r'\\b\\w+\\b', summary['text'].lower())\n",
    "    ref_words = re.findall(r'\\b\\w+\\b', duc_reference.lower())\n",
    "    \n",
    "    print(f\"Generated words: {len(gen_words)} từ\")\n",
    "    print(f\"Reference words: {len(ref_words)} từ\")\n",
    "    print(f\"Từ chung (overlap): {evaluation_results['rouge_1']['overlap']} từ\")\n",
    "    \n",
    "    print(f\"\\nCông thức ROUGE-1:\")\n",
    "    print(f\"Precision = overlap / gen_length = {evaluation_results['rouge_1']['overlap']} / {len(gen_words)} = {evaluation_results['rouge_1']['precision']:.4f}\")\n",
    "    print(f\"Recall = overlap / ref_length = {evaluation_results['rouge_1']['overlap']} / {len(ref_words)} = {evaluation_results['rouge_1']['recall']:.4f}\")\n",
    "    print(f\"F1 = 2 × P × R / (P + R) = {evaluation_results['rouge_1']['f1']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nBước 9 hoàn thành: Đã đánh giá tóm tắt bằng ROUGE metrics\")\n",
    "    \n",
    "elif 'summary' not in locals() or not summary:\n",
    "    print(\"Chưa có bản tóm tắt để đánh giá\")\n",
    "elif 'duc_reference' not in locals() or not duc_reference:\n",
    "    print(\"Chưa có DUC reference để so sánh\")\n",
    "else:\n",
    "    print(\"Thiếu dữ liệu để đánh giá\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
