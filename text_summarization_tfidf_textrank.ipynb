{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37205065",
   "metadata": {},
   "source": [
    "# TÓM TẮT VĂN BẢN BẰNG TF-IDF VÀ TEXTRANK\n",
    "\n",
    "## Các bước thực hiện:\n",
    "\n",
    "1. Đọc file XML và lưu vào Word (input.docx)\n",
    "2. Biểu diễn các câu bằng vector TF-IDF\n",
    "3. Tính độ tương đồng cosine giữa các câu\n",
    "4. Mô hình hóa văn bản dưới dạng đồ thị\n",
    "5. Áp dụng thuật toán TextRank\n",
    "6. Lấy 10% câu có điểm cao nhất\n",
    "7. Lưu bản tóm tắt vào Word (output_summary.docx)\n",
    "8. Đọc DUC_SUM reference và lưu vào Word (Test_DUC_SUM.docx)\n",
    "9. So sánh và đánh giá bằng ROUGE\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d9712",
   "metadata": {},
   "source": [
    "## 1. Setup và Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d366a313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ python-docx đã được cài đặt\n",
      "✓ numpy đã sẵn sàng\n",
      "✓ Tất cả thư viện đã được import thành công!\n",
      "✓ Notebook sẵn sàng để chạy tóm tắt văn bản\n"
     ]
    }
   ],
   "source": [
    "# Import các thư viện cơ bản\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import xml.etree.ElementTree as ET\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import thư viện cho Word processing\n",
    "try:\n",
    "    from docx import Document\n",
    "    from docx.shared import Inches\n",
    "    print(\"✓ python-docx đã được cài đặt\")\n",
    "except ImportError:\n",
    "    print(\"Cần cài đặt python-docx: pip install python-docx\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"python-docx\"])\n",
    "    from docx import Document\n",
    "\n",
    "# Cài đặt các thư viện cần thiết nếu chưa có\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"✓ numpy đã sẵn sàng\")\n",
    "except ImportError:\n",
    "    print(\"Cần cài đặt numpy: pip install numpy\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"numpy\"])\n",
    "    import numpy as np\n",
    "\n",
    "print(\"✓ Tất cả thư viện đã được import thành công!\")\n",
    "print(\"✓ Notebook sẵn sàng để chạy tóm tắt văn bản\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9c3f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TextSummarizerTFIDFTextRank đã được khởi tạo\n",
      "  - Damping factor: 0.85\n",
      "  - Max iterations: 100\n",
      "  - Tolerance: 1e-06\n",
      "✓ Đường dẫn dữ liệu: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK/DUC_TEXT/train\n",
      "✓ Đường dẫn reference: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK/DUC_SUM\n"
     ]
    }
   ],
   "source": [
    "class TextSummarizerTFIDFTextRank:\n",
    "    \"\"\"\n",
    "    Lớp tóm tắt văn bản sử dụng TF-IDF và TextRank\n",
    "    Viết tay các công thức toán học để minh họa cách tính\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, damping_factor=0.85, max_iterations=100, tolerance=1e-6):\n",
    "        self.damping_factor = damping_factor\n",
    "        self.max_iterations = max_iterations\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "        # Dữ liệu câu\n",
    "        self.sentences = []\n",
    "        self.sentence_vectors = []\n",
    "        self.vocabulary = set()\n",
    "        self.word_doc_count = defaultdict(int)\n",
    "        \n",
    "        # Ma trận\n",
    "        self.tfidf_matrix = None\n",
    "        self.cosine_matrix = None\n",
    "        self.adjacency_matrix = None\n",
    "        self.transition_matrix = None\n",
    "        self.textrank_scores = None\n",
    "        \n",
    "        print(\"✓ TextSummarizerTFIDFTextRank đã được khởi tạo\")\n",
    "        print(f\"  - Damping factor: {damping_factor}\")\n",
    "        print(f\"  - Max iterations: {max_iterations}\")\n",
    "        print(f\"  - Tolerance: {tolerance}\")\n",
    "\n",
    "# Khởi tạo summarizer\n",
    "summarizer = TextSummarizerTFIDFTextRank()\n",
    "\n",
    "# Cấu hình đường dẫn\n",
    "BASE_PATH = \"/Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK\"\n",
    "DUC_TEXT_PATH = os.path.join(BASE_PATH, \"DUC_TEXT\", \"train\")\n",
    "DUC_SUM_PATH = os.path.join(BASE_PATH, \"DUC_SUM\")\n",
    "\n",
    "print(f\"✓ Đường dẫn dữ liệu: {DUC_TEXT_PATH}\")\n",
    "print(f\"✓ Đường dẫn reference: {DUC_SUM_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72666e8f",
   "metadata": {},
   "source": [
    "## 2. Bước 1: Đọc File XML và Xử Lý Văn Bản\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7153afde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Đã thêm các phương thức xử lý văn bản\n"
     ]
    }
   ],
   "source": [
    "def load_xml_document(self, file_path):\n",
    "    \"\"\"\n",
    "    Đọc và xử lý file XML từ DUC dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def preprocess_text(self, text):\n",
    "    \"\"\"\n",
    "    Tiền xử lý văn bản:\n",
    "    - Loại bỏ thẻ XML/HTML\n",
    "    - Tách câu dựa trên dấu câu\n",
    "    - Làm sạch văn bản\n",
    "    \"\"\"\n",
    "    # Loại bỏ thẻ XML/HTML\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Tách câu dựa trên dấu chấm, chấm than, chấm hỏi\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    \n",
    "    # Làm sạch từng câu\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Loại bỏ khoảng trắng thừa\n",
    "        sentence = sentence.strip()\n",
    "        if len(sentence) > 10:  # Chỉ giữ câu có ít nhất 10 ký tự\n",
    "            # Chuyển về chữ thường cho việc xử lý\n",
    "            sentence_clean = sentence.lower()\n",
    "            # Loại bỏ ký tự đặc biệt nhưng giữ nguyên câu gốc để hiển thị\n",
    "            cleaned_sentences.append({\n",
    "                'original': sentence,\n",
    "                'processed': re.sub(r'[^a-zA-Z0-9\\s]', '', sentence_clean)\n",
    "            })\n",
    "    \n",
    "    return cleaned_sentences\n",
    "\n",
    "def save_to_word(self, content, filename):\n",
    "    \"\"\"\n",
    "    Lưu nội dung vào file Word\n",
    "    \"\"\"\n",
    "    doc = Document()\n",
    "    doc.add_heading('Document Content', 0)\n",
    "    \n",
    "    if isinstance(content, list):\n",
    "        for i, item in enumerate(content, 1):\n",
    "            if isinstance(item, dict):\n",
    "                doc.add_paragraph(f\"{i}. {item['original']}\")\n",
    "            else:\n",
    "                doc.add_paragraph(f\"{i}. {item}\")\n",
    "    else:\n",
    "        doc.add_paragraph(content)\n",
    "    \n",
    "    doc.save(filename)\n",
    "    print(f\"✓ Đã lưu vào file: {filename}\")\n",
    "\n",
    "# Thêm các phương thức vào class\n",
    "TextSummarizerTFIDFTextRank.load_xml_document = load_xml_document\n",
    "TextSummarizerTFIDFTextRank.preprocess_text = preprocess_text\n",
    "TextSummarizerTFIDFTextRank.save_to_word = save_to_word\n",
    "\n",
    "print(\"✓ Đã thêm các phương thức xử lý văn bản\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c8c8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DANH SÁCH FILE CÓ SẴN TRONG DUC_TEXT:\n",
      "==================================================\n",
      "Tổng cộng: 50 file\n",
      "\n",
      "Các file có sẵn:\n",
      "d061j      d062j      d063j      d064j      d065j      \n",
      "d066j      d067f      d068f      d069f      d070f      \n",
      "d071f      d072f      d073b      d074b      d075b      \n",
      "d076b      d077b      d078b      d079a      d080a      \n",
      "d081a      d082a      d083a      d084a      d085d      \n",
      "d086d      d087d      d089d      d090d      d091c      \n",
      "d092c      d093c      d094c      d095c      d096c      \n",
      "d097e      d098e      d099e      d100e      d101e      \n",
      "d102e      d103g      d104g      d105g      d106g      \n",
      "d107g      d108g      d109h      d110h      d111h      \n",
      "\n",
      "Bạn có thể chọn bất kỳ file nào từ danh sách trên.\n",
      "Ví dụ: d061j, d062j, d063j, ...\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị danh sách tất cả file có sẵn\n",
    "print(\"DANH SÁCH FILE CÓ SẴN TRONG DUC_TEXT:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if os.path.exists(DUC_TEXT_PATH):\n",
    "    all_files = [f for f in os.listdir(DUC_TEXT_PATH) if not f.startswith('.')]\n",
    "    all_files.sort()\n",
    "    \n",
    "    print(f\"Tổng cộng: {len(all_files)} file\")\n",
    "    print(\"\\nCác file có sẵn:\")\n",
    "    \n",
    "    # Hiển thị file theo dạng cột\n",
    "    for i, filename in enumerate(all_files):\n",
    "        if i % 5 == 0 and i > 0:\n",
    "            print()\n",
    "        print(f\"{filename:<10}\", end=\" \")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Bạn có thể chọn bất kỳ file nào từ danh sách trên.\")\n",
    "    print(\"Ví dụ: d061j, d062j, d063j, ...\")\n",
    "else:\n",
    "    print(f\"Thư mục không tồn tại: {DUC_TEXT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b85ee3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Có 50 file có sẵn trong DUC_TEXT:\n",
      "Một số file mẫu: ['d061j', 'd062j', 'd063j', 'd064j', 'd065j', 'd066j', 'd067f', 'd068f', 'd069f', 'd070f']\n",
      "Đã chọn file: d061j\n",
      "Đang đọc file: d061j\n",
      "✓ Đã đọc 32448 ký tự\n",
      "Đã tách thành 201 câu\n",
      "\n",
      "3 câu đầu tiên sau khi xử lý:\n",
      "1. Hurricane Gilbert swept toward the Dominican Republic Sunday, and the Civil Defense alerted its heavily populated south coast to prepare for high winds, heavy rains and high seas\n",
      "2. The storm was approaching from the southeast with sustained winds of 75 mph gusting to 92 mph\n",
      "3. ``There is no need for alarm,'' Civil Defense Director Eugenio Cabral said in a television alert shortly before midnight Saturday\n",
      "✓ Đã lưu vào file: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK/input.docx\n",
      "\n",
      "Bước 1 hoàn thành: Đã xử lý 201 câu và lưu vào input.docx\n"
     ]
    }
   ],
   "source": [
    "# Demo: Đọc file XML với tùy chọn chọn file\n",
    "if os.path.exists(DUC_TEXT_PATH):\n",
    "    files = [f for f in os.listdir(DUC_TEXT_PATH) if not f.startswith('.')]\n",
    "    files.sort()  # Sắp xếp để dễ tìm\n",
    "    \n",
    "    if files:\n",
    "        print(f\"Có {len(files)} file có sẵn trong DUC_TEXT:\")\n",
    "        print(\"Một số file mẫu:\", files[:10])  # Hiển thị 10 file đầu\n",
    "        \n",
    "        # Tùy chọn chọn file\n",
    "        demo_file_input = input(\"\\nNhập tên file muốn xử lý (ví dụ: d061j) hoặc nhấn Enter để dùng file đầu tiên: \").strip()\n",
    "        \n",
    "        if demo_file_input and demo_file_input in files:\n",
    "            demo_file = demo_file_input\n",
    "            print(f\"Đã chọn file: {demo_file}\")\n",
    "        elif demo_file_input and demo_file_input not in files:\n",
    "            print(f\"File '{demo_file_input}' không tồn tại. Sử dụng file đầu tiên: {files[0]}\")\n",
    "            demo_file = files[0]\n",
    "        else:\n",
    "            demo_file = files[0]\n",
    "            print(f\"Sử dụng file mặc định: {demo_file}\")\n",
    "        \n",
    "        file_path = os.path.join(DUC_TEXT_PATH, demo_file)\n",
    "        \n",
    "        print(f\"Đang đọc file: {demo_file}\")\n",
    "        \n",
    "        # Đọc nội dung\n",
    "        content = summarizer.load_xml_document(file_path)\n",
    "        print(f\"✓ Đã đọc {len(content)} ký tự\")\n",
    "        \n",
    "        # Tiền xử lý và tách câu\n",
    "        sentences = summarizer.preprocess_text(content)\n",
    "        print(f\"Đã tách thành {len(sentences)} câu\")\n",
    "        \n",
    "        # Lưu câu gốc vào summarizer\n",
    "        summarizer.sentences = sentences\n",
    "        \n",
    "        # Hiển thị 3 câu đầu tiên\n",
    "        print(\"\\n3 câu đầu tiên sau khi xử lý:\")\n",
    "        for i, sent in enumerate(sentences[:3], 1):\n",
    "            print(f\"{i}. {sent['original']}\")\n",
    "        \n",
    "        # Lưu vào file Word (input.docx)\n",
    "        input_filename = os.path.join(BASE_PATH, \"input.docx\")\n",
    "        summarizer.save_to_word(sentences, input_filename)\n",
    "        \n",
    "        print(f\"\\nBước 1 hoàn thành: Đã xử lý {len(sentences)} câu và lưu vào input.docx\")\n",
    "    else:\n",
    "        print(\"Không tìm thấy file nào trong thư mục DUC_TEXT\")\n",
    "else:\n",
    "    print(f\"Thư mục không tồn tại: {DUC_TEXT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053817f",
   "metadata": {},
   "source": [
    "## 3. Bước 2: Biểu Diễn Câu Bằng Vector TF-IDF\n",
    "\n",
    "**Công thức TF-IDF:**\n",
    "\n",
    "- **TF (Term Frequency)** = (số lần xuất hiện của từ trong câu) / (tổng số từ trong câu)\n",
    "- **IDF (Inverse Document Frequency)** = log(tổng số câu / số câu chứa từ đó)\n",
    "- **TF-IDF** = TF × IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77c21dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm các phương thức tính TF-IDF\n"
     ]
    }
   ],
   "source": [
    "def build_vocabulary(self):\n",
    "    \"\"\"\n",
    "    Xây dựng từ vựng từ tất cả các câu\n",
    "    \"\"\"\n",
    "    print(\"Đang xây dựng từ vựng...\")\n",
    "    \n",
    "    # Tách từ từ tất cả các câu\n",
    "    all_words = []\n",
    "    for sentence in self.sentences:\n",
    "        words = sentence['processed'].split()\n",
    "        # Lọc từ có ít nhất 2 ký tự\n",
    "        words = [word for word in words if len(word) >= 2]\n",
    "        all_words.extend(words)\n",
    "        \n",
    "        # Cập nhật từ vựng unique\n",
    "        self.vocabulary.update(words)\n",
    "        \n",
    "        # Đếm số câu chứa mỗi từ\n",
    "        unique_words = set(words)\n",
    "        for word in unique_words:\n",
    "            self.word_doc_count[word] += 1\n",
    "    \n",
    "    print(f\"Tổng từ vựng: {len(self.vocabulary)} từ\")\n",
    "    print(f\"Tổng từ (có lặp): {len(all_words)} từ\")\n",
    "    \n",
    "    return list(self.vocabulary)\n",
    "\n",
    "def calculate_tf(self, word, sentence_words):\n",
    "    \"\"\"\n",
    "    Tính Term Frequency (TF) \n",
    "    TF = số lần xuất hiện của từ / tổng số từ trong câu\n",
    "    \"\"\"\n",
    "    word_count = sentence_words.count(word)\n",
    "    total_words = len(sentence_words)\n",
    "    tf = word_count / total_words if total_words > 0 else 0\n",
    "    return tf\n",
    "\n",
    "def calculate_idf(self, word):\n",
    "    \"\"\"\n",
    "    Tính Inverse Document Frequency (IDF) \n",
    "    IDF = log(tổng số câu / số câu chứa từ)\n",
    "    \"\"\"\n",
    "    total_sentences = len(self.sentences)\n",
    "    sentences_with_word = self.word_doc_count[word]\n",
    "    \n",
    "    if sentences_with_word == 0:\n",
    "        return 0\n",
    "    \n",
    "    idf = math.log(total_sentences / sentences_with_word)\n",
    "    return idf\n",
    "\n",
    "def calculate_tfidf(self, word, sentence_words):\n",
    "    \"\"\"\n",
    "    Tính TF-IDF - viết tay công thức\n",
    "    TF-IDF = TF × IDF\n",
    "    \"\"\"\n",
    "    tf = self.calculate_tf(word, sentence_words)\n",
    "    idf = self.calculate_idf(word)\n",
    "    tfidf = tf * idf\n",
    "    return tfidf\n",
    "\n",
    "def build_tfidf_matrix(self):\n",
    "    \"\"\"\n",
    "    Xây dựng ma trận TF-IDF cho tất cả các câu\n",
    "    \"\"\"\n",
    "    print(\"Đang xây dựng ma trận TF-IDF...\")\n",
    "    \n",
    "    # Xây dựng từ vựng\n",
    "    vocab_list = self.build_vocabulary()\n",
    "    vocab_size = len(vocab_list)\n",
    "    \n",
    "    # Khởi tạo ma trận TF-IDF\n",
    "    self.tfidf_matrix = np.zeros((len(self.sentences), vocab_size))\n",
    "    \n",
    "    # Tạo mapping từ word → index\n",
    "    word_to_index = {word: i for i, word in enumerate(vocab_list)}\n",
    "    \n",
    "    # Tính TF-IDF cho từng câu\n",
    "    for sent_idx, sentence in enumerate(self.sentences):\n",
    "        sentence_words = sentence['processed'].split()\n",
    "        sentence_words = [word for word in sentence_words if len(word) >= 2]\n",
    "        \n",
    "        # Tính TF-IDF cho mỗi từ trong câu\n",
    "        for word in set(sentence_words):  # Chỉ tính cho từ unique trong câu\n",
    "            if word in word_to_index:\n",
    "                word_idx = word_to_index[word]\n",
    "                self.tfidf_matrix[sent_idx, word_idx] = self.calculate_tfidf(word, sentence_words)\n",
    "    \n",
    "    print(f\"✓ Ma trận TF-IDF: {self.tfidf_matrix.shape} (câu × từ vựng)\")\n",
    "    return self.tfidf_matrix, vocab_list\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.build_vocabulary = build_vocabulary\n",
    "TextSummarizerTFIDFTextRank.calculate_tf = calculate_tf\n",
    "TextSummarizerTFIDFTextRank.calculate_idf = calculate_idf\n",
    "TextSummarizerTFIDFTextRank.calculate_tfidf = calculate_tfidf\n",
    "TextSummarizerTFIDFTextRank.build_tfidf_matrix = build_tfidf_matrix\n",
    "\n",
    "print(\"Đã thêm các phương thức tính TF-IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188d3623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xây dựng ma trận TF-IDF...\n",
      "Đang xây dựng từ vựng...\n",
      "Tổng từ vựng: 927 từ\n",
      "Tổng từ (có lặp): 3062 từ\n",
      "✓ Ma trận TF-IDF: (160, 927) (câu × từ vựng)\n",
      "\n",
      "DEMO: Minh họa cách tính TF-IDF\n",
      "==================================================\n",
      "Câu demo: 'Former East German leader Erich Honecker may be moved to a monastery to protect him from a possible ...'\n",
      "Từ demo: 'former'\n",
      "\n",
      "1. TF (Term Frequency):\n",
      "   Số lần xuất hiện: 1\n",
      "   Tổng số từ: 19\n",
      "   TF = 1 / 19 = 0.052632\n",
      "\n",
      "2. IDF (Inverse Document Frequency):\n",
      "   Tổng số câu: 160\n",
      "   Số câu chứa 'former': 23\n",
      "   IDF = log(160 / 23) = 1.939680\n",
      "\n",
      "3. TF-IDF:\n",
      "   TF-IDF = 0.052632 × 1.939680 = 0.102088\n",
      "\n",
      "Bước 2 hoàn thành: Đã tạo ma trận TF-IDF (160, 927)\n"
     ]
    }
   ],
   "source": [
    "# Demo: Xây dựng ma trận TF-IDF\n",
    "if summarizer.sentences:\n",
    "    # Xây dựng ma trận TF-IDF\n",
    "    tfidf_matrix, vocab_list = summarizer.build_tfidf_matrix()\n",
    "    \n",
    "    # Demo: Hiển thị cách tính TF-IDF cho một từ cụ thể\n",
    "    print(\"\\nDEMO: Minh họa cách tính TF-IDF\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Chọn câu đầu tiên và từ phổ biến\n",
    "    demo_sentence = summarizer.sentences[0]\n",
    "    demo_words = demo_sentence['processed'].split()\n",
    "    demo_words = [word for word in demo_words if len(word) >= 3]\n",
    "    \n",
    "    if demo_words:\n",
    "        demo_word = demo_words[0]  # Chọn từ đầu tiên\n",
    "        \n",
    "        print(f\"Câu demo: '{demo_sentence['original'][:100]}...'\")\n",
    "        print(f\"Từ demo: '{demo_word}'\")\n",
    "        \n",
    "        # Tính từng bước\n",
    "        tf = summarizer.calculate_tf(demo_word, demo_words)\n",
    "        idf = summarizer.calculate_idf(demo_word)\n",
    "        tfidf = summarizer.calculate_tfidf(demo_word, demo_words)\n",
    "        \n",
    "        print(f\"\\n1. TF (Term Frequency):\")\n",
    "        print(f\"   Số lần xuất hiện: {demo_words.count(demo_word)}\")\n",
    "        print(f\"   Tổng số từ: {len(demo_words)}\")\n",
    "        print(f\"   TF = {demo_words.count(demo_word)} / {len(demo_words)} = {tf:.6f}\")\n",
    "        \n",
    "        print(f\"\\n2. IDF (Inverse Document Frequency):\")\n",
    "        print(f\"   Tổng số câu: {len(summarizer.sentences)}\")\n",
    "        print(f\"   Số câu chứa '{demo_word}': {summarizer.word_doc_count[demo_word]}\")\n",
    "        print(f\"   IDF = log({len(summarizer.sentences)} / {summarizer.word_doc_count[demo_word]}) = {idf:.6f}\")\n",
    "        \n",
    "        print(f\"\\n3. TF-IDF:\")\n",
    "        print(f\"   TF-IDF = {tf:.6f} × {idf:.6f} = {tfidf:.6f}\")\n",
    "    \n",
    "    print(f\"\\nBước 2 hoàn thành: Đã tạo ma trận TF-IDF {tfidf_matrix.shape}\")\n",
    "else:\n",
    "    print(\"Chưa có dữ liệu câu để xử lý\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d03573",
   "metadata": {},
   "source": [
    "## 4. Bước 3: Tính Độ Tương Đồng Cosine\n",
    "\n",
    "**Công thức Cosine Similarity:**\n",
    "\n",
    "- **cosine_similarity(A, B)** = (A · B) / (|A| × |B|)\n",
    "- **A · B** = tích vô hướng của hai vector\n",
    "- **|A|** = độ dài (magnitude) của vector A = √(Σ(ai²))\n",
    "- **|B|** = độ dài (magnitude) của vector B = √(Σ(bi²))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e09a7ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm các phương thức tính Cosine Similarity\n"
     ]
    }
   ],
   "source": [
    "def calculate_cosine_similarity(self, vector1, vector2):\n",
    "    \"\"\"\n",
    "    Tính cosine similarity giữa hai vector - viết tay công thức\n",
    "    cosine_similarity = (A · B) / (|A| × |B|)\n",
    "    \"\"\"\n",
    "    # Tính tích vô hướng (dot product)\n",
    "    dot_product = 0\n",
    "    for i in range(len(vector1)):\n",
    "        dot_product += vector1[i] * vector2[i]\n",
    "    \n",
    "    # Tính độ dài của vector A\n",
    "    magnitude_a = 0\n",
    "    for val in vector1:\n",
    "        magnitude_a += val * val\n",
    "    magnitude_a = math.sqrt(magnitude_a)\n",
    "    \n",
    "    # Tính độ dài của vector B  \n",
    "    magnitude_b = 0\n",
    "    for val in vector2:\n",
    "        magnitude_b += val * val\n",
    "    magnitude_b = math.sqrt(magnitude_b)\n",
    "    \n",
    "    # Tránh chia cho 0\n",
    "    if magnitude_a == 0 or magnitude_b == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Tính cosine similarity\n",
    "    cosine_sim = dot_product / (magnitude_a * magnitude_b)\n",
    "    return cosine_sim\n",
    "\n",
    "def build_cosine_matrix(self):\n",
    "    \"\"\"\n",
    "    Xây dựng ma trận cosine similarity giữa tất cả các câu\n",
    "    \"\"\"\n",
    "    print(\"Đang xây dựng ma trận cosine similarity...\")\n",
    "    \n",
    "    if self.tfidf_matrix is None:\n",
    "        print(\"Chưa có ma trận TF-IDF. Hãy chạy build_tfidf_matrix() trước.\")\n",
    "        return None\n",
    "    \n",
    "    num_sentences = self.tfidf_matrix.shape[0]\n",
    "    self.cosine_matrix = np.zeros((num_sentences, num_sentences))\n",
    "    \n",
    "    # Tính cosine similarity cho mỗi cặp câu\n",
    "    for i in range(num_sentences):\n",
    "        for j in range(num_sentences):\n",
    "            if i == j:\n",
    "                self.cosine_matrix[i, j] = 1.0  # Similarity với chính nó = 1\n",
    "            else:\n",
    "                similarity = self.calculate_cosine_similarity(\n",
    "                    self.tfidf_matrix[i], \n",
    "                    self.tfidf_matrix[j]\n",
    "                )\n",
    "                self.cosine_matrix[i, j] = similarity\n",
    "    \n",
    "    print(f\"✓ Ma trận cosine similarity: {self.cosine_matrix.shape}\")\n",
    "    return self.cosine_matrix\n",
    "\n",
    "def demonstrate_cosine_calculation(self, sent1_idx=0, sent2_idx=1):\n",
    "    \"\"\"\n",
    "    Minh họa chi tiết cách tính cosine similarity\n",
    "    \"\"\"\n",
    "    if self.tfidf_matrix is None or len(self.sentences) < 2:\n",
    "        print(\"Không đủ dữ liệu để minh họa\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nDEMO: Minh họa cách tính Cosine Similarity\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Lấy hai vector\n",
    "    vector1 = self.tfidf_matrix[sent1_idx]\n",
    "    vector2 = self.tfidf_matrix[sent2_idx]\n",
    "    \n",
    "    print(f\"Câu 1: '{self.sentences[sent1_idx]['original'][:80]}...'\")\n",
    "    print(f\"Câu 2: '{self.sentences[sent2_idx]['original'][:80]}...'\")\n",
    "    \n",
    "    # Tính từng bước\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    magnitude_a = np.linalg.norm(vector1)\n",
    "    magnitude_b = np.linalg.norm(vector2)\n",
    "    \n",
    "    print(f\"\\n1. Tích vô hướng (A · B):\")\n",
    "    print(f\"   dot_product = Σ(ai × bi) = {dot_product:.6f}\")\n",
    "    \n",
    "    print(f\"\\n2. Độ dài vector:\")\n",
    "    print(f\"   |A| = √(Σ(ai²)) = {magnitude_a:.6f}\")\n",
    "    print(f\"   |B| = √(Σ(bi²)) = {magnitude_b:.6f}\")\n",
    "    \n",
    "    if magnitude_a > 0 and magnitude_b > 0:\n",
    "        cosine_sim = dot_product / (magnitude_a * magnitude_b)\n",
    "        print(f\"\\n3. Cosine Similarity:\")\n",
    "        print(f\"   cosine_sim = {dot_product:.6f} / ({magnitude_a:.6f} × {magnitude_b:.6f})\")\n",
    "        print(f\"   cosine_sim = {cosine_sim:.6f}\")\n",
    "        \n",
    "        # Giải thích ý nghĩa\n",
    "        if cosine_sim > 0.8:\n",
    "            interpretation = \"rất tương tự\"\n",
    "        elif cosine_sim > 0.5:\n",
    "            interpretation = \"tương tự\"\n",
    "        elif cosine_sim > 0.3:\n",
    "            interpretation = \"hơi tương tự\"\n",
    "        else:\n",
    "            interpretation = \"không tương tự\"\n",
    "        print(f\"   → Hai câu {interpretation}\")\n",
    "    else:\n",
    "        print(\"\\nMột trong hai vector có độ dài = 0\")\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.calculate_cosine_similarity = calculate_cosine_similarity\n",
    "TextSummarizerTFIDFTextRank.build_cosine_matrix = build_cosine_matrix\n",
    "TextSummarizerTFIDFTextRank.demonstrate_cosine_calculation = demonstrate_cosine_calculation\n",
    "\n",
    "print(\"Đã thêm các phương thức tính Cosine Similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "839ee630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xây dựng ma trận cosine similarity...\n",
      "✓ Ma trận cosine similarity: (160, 160)\n",
      "\n",
      "DEMO: Minh họa cách tính Cosine Similarity\n",
      "============================================================\n",
      "Câu 1: 'Former East German leader Erich Honecker may be moved to a monastery to protect ...'\n",
      "Câu 2: 'In a front-page story, the mass-circulation Bild newspaper said ``Lynch Danger _...'\n",
      "\n",
      "1. Tích vô hướng (A · B):\n",
      "   dot_product = Σ(ai × bi) = 0.030483\n",
      "\n",
      "2. Độ dài vector:\n",
      "   |A| = √(Σ(ai²)) = 0.644133\n",
      "   |B| = √(Σ(bi²)) = 0.913182\n",
      "\n",
      "3. Cosine Similarity:\n",
      "   cosine_sim = 0.030483 / (0.644133 × 0.913182)\n",
      "   cosine_sim = 0.051823\n",
      "   → Hai câu không tương tự\n",
      "\n",
      "Thống kê ma trận Cosine Similarity:\n",
      "   - Kích thước: (160, 160)\n",
      "   - Giá trị trung bình: 0.0330\n",
      "   - Giá trị max (không tính đường chéo): 1.0000\n",
      "   - Giá trị min: 0.0000\n",
      "\n",
      "Ma trận Cosine Similarity (5x5 đầu tiên):\n",
      "      S0       S1       S2       S3       S4       \n",
      "S0    1.000   0.052   0.006   0.037   0.027   \n",
      "S1    0.052   1.000   0.006   0.007   0.012   \n",
      "S2    0.006   0.006   1.000   0.000   0.031   \n",
      "S3    0.037   0.007   0.000   1.000   0.095   \n",
      "S4    0.027   0.012   0.031   0.095   1.000   \n",
      "\n",
      "Bước 3 hoàn thành: Đã tạo ma trận cosine similarity\n",
      "✓ Ma trận cosine similarity: (160, 160)\n",
      "\n",
      "DEMO: Minh họa cách tính Cosine Similarity\n",
      "============================================================\n",
      "Câu 1: 'Former East German leader Erich Honecker may be moved to a monastery to protect ...'\n",
      "Câu 2: 'In a front-page story, the mass-circulation Bild newspaper said ``Lynch Danger _...'\n",
      "\n",
      "1. Tích vô hướng (A · B):\n",
      "   dot_product = Σ(ai × bi) = 0.030483\n",
      "\n",
      "2. Độ dài vector:\n",
      "   |A| = √(Σ(ai²)) = 0.644133\n",
      "   |B| = √(Σ(bi²)) = 0.913182\n",
      "\n",
      "3. Cosine Similarity:\n",
      "   cosine_sim = 0.030483 / (0.644133 × 0.913182)\n",
      "   cosine_sim = 0.051823\n",
      "   → Hai câu không tương tự\n",
      "\n",
      "Thống kê ma trận Cosine Similarity:\n",
      "   - Kích thước: (160, 160)\n",
      "   - Giá trị trung bình: 0.0330\n",
      "   - Giá trị max (không tính đường chéo): 1.0000\n",
      "   - Giá trị min: 0.0000\n",
      "\n",
      "Ma trận Cosine Similarity (5x5 đầu tiên):\n",
      "      S0       S1       S2       S3       S4       \n",
      "S0    1.000   0.052   0.006   0.037   0.027   \n",
      "S1    0.052   1.000   0.006   0.007   0.012   \n",
      "S2    0.006   0.006   1.000   0.000   0.031   \n",
      "S3    0.037   0.007   0.000   1.000   0.095   \n",
      "S4    0.027   0.012   0.031   0.095   1.000   \n",
      "\n",
      "Bước 3 hoàn thành: Đã tạo ma trận cosine similarity\n"
     ]
    }
   ],
   "source": [
    "# Demo: Xây dựng ma trận cosine similarity\n",
    "if summarizer.tfidf_matrix is not None:\n",
    "    # Xây dựng ma trận cosine\n",
    "    cosine_matrix = summarizer.build_cosine_matrix()\n",
    "    \n",
    "    # Minh họa cách tính cosine similarity\n",
    "    if len(summarizer.sentences) >= 2:\n",
    "        summarizer.demonstrate_cosine_calculation(0, 1)\n",
    "    \n",
    "    # Hiển thị thống kê ma trận cosine\n",
    "    print(f\"\\nThống kê ma trận Cosine Similarity:\")\n",
    "    print(f\"   - Kích thước: {cosine_matrix.shape}\")\n",
    "    print(f\"   - Giá trị trung bình: {np.mean(cosine_matrix):.4f}\")\n",
    "    print(f\"   - Giá trị max (không tính đường chéo): {np.max(cosine_matrix - np.eye(len(cosine_matrix))):.4f}\")\n",
    "    print(f\"   - Giá trị min: {np.min(cosine_matrix):.4f}\")\n",
    "    \n",
    "    # Hiển thị ma trận 5x5 đầu tiên\n",
    "    display_size = min(5, len(summarizer.sentences))\n",
    "    print(f\"\\nMa trận Cosine Similarity ({display_size}x{display_size} đầu tiên):\")\n",
    "    print(\"      \", end=\"\")\n",
    "    for j in range(display_size):\n",
    "        print(f\"S{j:<8}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for i in range(display_size):\n",
    "        print(f\"S{i:<4} \", end=\"\")\n",
    "        for j in range(display_size):\n",
    "            print(f\"{cosine_matrix[i,j]:<8.3f}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"\\nBước 3 hoàn thành: Đã tạo ma trận cosine similarity\")\n",
    "else:\n",
    "    print(\"Chưa có ma trận TF-IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff03d8",
   "metadata": {},
   "source": [
    "## 5. Bước 4: Mô Hình Hóa Đồ Thị\n",
    "\n",
    "Mô hình hóa văn bản dưới dạng đồ thị:\n",
    "\n",
    "- **Đỉnh (Vertices)**: Mỗi câu là một đỉnh\n",
    "- **Cạnh (Edges)**: Trọng số cosine similarity giữa các câu\n",
    "- **Ngưỡng (Threshold)**: Chỉ tạo cạnh khi similarity > threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0588b609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm các phương thức mô hình hóa đồ thị\n"
     ]
    }
   ],
   "source": [
    "def create_adjacency_matrix(self, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Tạo ma trận kề từ ma trận cosine similarity\n",
    "    Nếu similarity > threshold thì có cạnh (giá trị = 1)\n",
    "    \"\"\"\n",
    "    print(f\"Đang tạo đồ thị với ngưỡng similarity: {threshold}\")\n",
    "    \n",
    "    if self.cosine_matrix is None:\n",
    "        print(\"Chưa có ma trận cosine similarity\")\n",
    "        return None\n",
    "    \n",
    "    n = self.cosine_matrix.shape[0]\n",
    "    self.adjacency_matrix = np.zeros((n, n))\n",
    "    \n",
    "    # Tạo cạnh dựa trên ngưỡng similarity\n",
    "    edge_count = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j and self.cosine_matrix[i, j] > threshold:\n",
    "                self.adjacency_matrix[i, j] = 1\n",
    "                edge_count += 1\n",
    "    \n",
    "    print(f\"Đã tạo {edge_count} cạnh trong đồ thị\")\n",
    "    print(f\"Ma trận kề: {self.adjacency_matrix.shape}\")\n",
    "    \n",
    "    return self.adjacency_matrix\n",
    "\n",
    "def create_transition_matrix(self):\n",
    "    \"\"\"\n",
    "    Tạo ma trận chuyển tiếp cho TextRank\n",
    "    Mỗi hàng được chuẩn hóa sao cho tổng = 1\n",
    "    \"\"\"\n",
    "    print(\"Đang tạo ma trận chuyển tiếp...\")\n",
    "    \n",
    "    if self.adjacency_matrix is None:\n",
    "        print(\"Chưa có ma trận kề\")\n",
    "        return None\n",
    "    \n",
    "    n = self.adjacency_matrix.shape[0]\n",
    "    self.transition_matrix = np.copy(self.adjacency_matrix).astype(float)\n",
    "    \n",
    "    # Chuẩn hóa từng hàng\n",
    "    for i in range(n):\n",
    "        row_sum = np.sum(self.transition_matrix[i])\n",
    "        if row_sum > 0:\n",
    "            # Có cạnh ra → chuẩn hóa\n",
    "            self.transition_matrix[i] = self.transition_matrix[i] / row_sum\n",
    "        else:\n",
    "            # Không có cạnh ra → phân bố đều cho tất cả đỉnh\n",
    "            self.transition_matrix[i] = np.ones(n) / n\n",
    "    \n",
    "    print(f\"Ma trận chuyển tiếp: {self.transition_matrix.shape}\")\n",
    "    \n",
    "    # Kiểm tra tính chuẩn hóa\n",
    "    row_sums = np.sum(self.transition_matrix, axis=1)\n",
    "    print(f\"Kiểm tra chuẩn hóa: tổng hàng = {row_sums[0]:.6f} (should be 1.0)\")\n",
    "    \n",
    "    return self.transition_matrix\n",
    "\n",
    "def visualize_graph_info(self):\n",
    "    \"\"\"\n",
    "    Hiển thị thông tin về đồ thị\n",
    "    \"\"\"\n",
    "    if self.adjacency_matrix is None:\n",
    "        print(\"Chưa có ma trận kề\")\n",
    "        return\n",
    "    \n",
    "    n = len(self.sentences)\n",
    "    total_edges = np.sum(self.adjacency_matrix)\n",
    "    \n",
    "    print(f\"\\nThông tin đồ thị:\")\n",
    "    print(f\"   - Số đỉnh (câu): {n}\")\n",
    "    print(f\"   - Số cạnh: {int(total_edges)}\")\n",
    "    print(f\"   - Mật độ: {total_edges / (n * (n-1)):.4f}\")\n",
    "    \n",
    "    # Hiển thị degree của từng đỉnh\n",
    "    in_degrees = np.sum(self.adjacency_matrix, axis=0)  # Số cạnh vào\n",
    "    out_degrees = np.sum(self.adjacency_matrix, axis=1)  # Số cạnh ra\n",
    "    \n",
    "    print(f\"\\nThống kê degree:\")\n",
    "    print(f\"   - In-degree trung bình: {np.mean(in_degrees):.2f}\")\n",
    "    print(f\"   - Out-degree trung bình: {np.mean(out_degrees):.2f}\")\n",
    "    print(f\"   - Max in-degree: {int(np.max(in_degrees))}\")\n",
    "    print(f\"   - Max out-degree: {int(np.max(out_degrees))}\")\n",
    "    \n",
    "    # Hiển thị một vài câu có degree cao nhất\n",
    "    high_degree_indices = np.argsort(in_degrees)[-3:][::-1]\n",
    "    print(f\"\\nTop 3 câu có nhiều liên kết nhất:\")\n",
    "    for i, idx in enumerate(high_degree_indices, 1):\n",
    "        sentence_preview = self.sentences[idx]['original'][:60]\n",
    "        print(f\"   {i}. Câu {idx}: degree={int(in_degrees[idx])} - '{sentence_preview}...'\")\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.create_adjacency_matrix = create_adjacency_matrix\n",
    "TextSummarizerTFIDFTextRank.create_transition_matrix = create_transition_matrix\n",
    "TextSummarizerTFIDFTextRank.visualize_graph_info = visualize_graph_info\n",
    "\n",
    "print(\"Đã thêm các phương thức mô hình hóa đồ thị\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a66df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tạo đồ thị với ngưỡng similarity: 0.1\n",
      "Đã tạo 1166 cạnh trong đồ thị\n",
      "Ma trận kề: (160, 160)\n",
      "Đang tạo ma trận chuyển tiếp...\n",
      "Ma trận chuyển tiếp: (160, 160)\n",
      "Kiểm tra chuẩn hóa: tổng hàng = 1.000000 (should be 1.0)\n",
      "\n",
      "Thông tin đồ thị:\n",
      "   - Số đỉnh (câu): 160\n",
      "   - Số cạnh: 1166\n",
      "   - Mật độ: 0.0458\n",
      "\n",
      "Thống kê degree:\n",
      "   - In-degree trung bình: 7.29\n",
      "   - Out-degree trung bình: 7.29\n",
      "   - Max in-degree: 25\n",
      "   - Max out-degree: 25\n",
      "\n",
      "Top 3 câu có nhiều liên kết nhất:\n",
      "   1. Câu 54: degree=25 - 'Ousted East German leader Erich Honecker was arrested and ta...'\n",
      "   2. Câu 42: degree=24 - 'Ousted East German leader Erich Honecker, who is expected to...'\n",
      "   3. Câu 75: degree=23 - 'East Germany's deposed Communist leader Erich Honecker is to...'\n",
      "\n",
      "Ma trận kề (5x5 đầu tiên):\n",
      "      S0   S1   S2   S3   S4   \n",
      "S0    0   0   0   0   0   \n",
      "S1    0   0   0   0   0   \n",
      "S2    0   0   0   0   0   \n",
      "S3    0   0   0   0   0   \n",
      "S4    0   0   0   0   0   \n",
      "\n",
      "Bước 4 hoàn thành: Đã mô hình hóa văn bản thành đồ thị\n"
     ]
    }
   ],
   "source": [
    "# Demo: Tạo đồ thị từ ma trận cosine similarity\n",
    "if summarizer.cosine_matrix is not None:\n",
    "    # Tạo ma trận kề với ngưỡng phù hợp\n",
    "    threshold = 0.1  # Có thể điều chỉnh\n",
    "    adjacency_matrix = summarizer.create_adjacency_matrix(threshold)\n",
    "    \n",
    "    # Tạo ma trận chuyển tiếp\n",
    "    transition_matrix = summarizer.create_transition_matrix()\n",
    "    \n",
    "    # Hiển thị thông tin đồ thị\n",
    "    summarizer.visualize_graph_info()\n",
    "    \n",
    "    # Hiển thị ma trận kề (5x5 đầu tiên)\n",
    "    display_size = min(5, len(summarizer.sentences))\n",
    "    print(f\"\\nMa trận kề ({display_size}x{display_size} đầu tiên):\")\n",
    "    print(\"      \", end=\"\")\n",
    "    for j in range(display_size):\n",
    "        print(f\"S{j:<4}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for i in range(display_size):\n",
    "        print(f\"S{i:<4} \", end=\"\")\n",
    "        for j in range(display_size):\n",
    "            print(f\"{int(adjacency_matrix[i,j]):<4}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"\\nBước 4 hoàn thành: Đã mô hình hóa văn bản thành đồ thị\")\n",
    "else:\n",
    "    print(\"Chưa có ma trận cosine similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6ee64e",
   "metadata": {},
   "source": [
    "## 6. Bước 5: Thuật Toán TextRank\n",
    "\n",
    "**Công thức TextRank (dựa trên PageRank):**\n",
    "\n",
    "**TR(Vi) = (1-d) + d × Σ(TR(Vj)/C(Vj))**\n",
    "\n",
    "Trong đó:\n",
    "\n",
    "- **TR(Vi)**: Điểm TextRank của câu Vi\n",
    "- **d**: Damping factor (thường = 0.85)\n",
    "- **Vj**: Các câu có liên kết đến Vi\n",
    "- **C(Vj)**: Số liên kết ra từ câu Vj\n",
    "\n",
    "**Phương pháp Power Iteration:**\n",
    "\n",
    "- Khởi tạo: TR₀ = [1/N, 1/N, ..., 1/N]\n",
    "- Lặp: TR\\_{k+1} = (1-d)/N + d × M^T × TR_k\n",
    "- Dừng khi: ||TR\\_{k+1} - TR_k|| < tolerance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f39065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm thuật toán TextRank\n"
     ]
    }
   ],
   "source": [
    "def calculate_textrank(self):\n",
    "    \"\"\"\n",
    "    Tính TextRank bằng Power Iteration \n",
    "    \"\"\"\n",
    "    print(\"Đang tính TextRank bằng Power Iteration...\")\n",
    "    \n",
    "    if self.transition_matrix is None:\n",
    "        print(\"Chưa có ma trận chuyển tiếp\")\n",
    "        return None\n",
    "    \n",
    "    n = self.transition_matrix.shape[0]\n",
    "    \n",
    "    # Khởi tạo vector TextRank (phân bố đều)\n",
    "    textrank_vector = np.ones(n) / n\n",
    "    print(f\"Khởi tạo: TR₀ = [1/{n}, 1/{n}, ..., 1/{n}] = {1/n:.6f}\")\n",
    "    \n",
    "    print(f\"\\nCông thức TextRank:\")\n",
    "    print(f\"   TR_new = (1-d)/N + d × M^T × TR_old\")\n",
    "    print(f\"   Với d = {self.damping_factor}, N = {n}\")\n",
    "    print(f\"   Teleport term = (1-d)/N = {(1-self.damping_factor)/n:.6f}\")\n",
    "    \n",
    "    # Lưu lịch sử hội tụ\n",
    "    history = []\n",
    "    \n",
    "    print(f\"\\nQuá trình lặp:\")\n",
    "    print(f\"{'Vòng':<6} {'Thay đổi':<15} {'Top 3 điểm':<25}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for iteration in range(self.max_iterations):\n",
    "        # Lưu vector cũ\n",
    "        old_textrank = np.copy(textrank_vector)\n",
    "        \n",
    "        # Áp dụng công thức TextRank\n",
    "        # TR = (1-d)/N + d * M^T * TR_old\n",
    "        teleport_term = (1 - self.damping_factor) / n\n",
    "        random_walk_term = self.damping_factor * np.dot(self.transition_matrix.T, textrank_vector)\n",
    "        textrank_vector = teleport_term + random_walk_term\n",
    "        \n",
    "        # Tính sự thay đổi (norm L2)\n",
    "        change = 0\n",
    "        for i in range(len(textrank_vector)):\n",
    "            diff = textrank_vector[i] - old_textrank[i]\n",
    "            change += diff * diff\n",
    "        change = math.sqrt(change)\n",
    "        \n",
    "        # Lưu lịch sử\n",
    "        history.append((iteration + 1, change, np.copy(textrank_vector)))\n",
    "        \n",
    "        # Hiển thị top 3 điểm cao nhất\n",
    "        top_indices = np.argsort(textrank_vector)[-3:][::-1]\n",
    "        top_scores = [f\"{textrank_vector[i]:.4f}\" for i in top_indices]\n",
    "        top_info = \", \".join(top_scores)\n",
    "        \n",
    "        print(f\"{iteration+1:<6} {change:<15.8f} {top_info:<25}\")\n",
    "        \n",
    "        # Kiểm tra hội tụ\n",
    "        if change < self.tolerance:\n",
    "            print(f\"\\nHội tụ sau {iteration + 1} vòng lặp!\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"\\nĐạt giới hạn {self.max_iterations} vòng lặp\")\n",
    "    \n",
    "    self.textrank_scores = textrank_vector\n",
    "    \n",
    "    return textrank_vector, history\n",
    "\n",
    "def demonstrate_textrank_calculation(self, sentence_idx=0):\n",
    "    \"\"\"\n",
    "    Minh họa chi tiết cách tính TextRank cho một câu cụ thể\n",
    "    \"\"\"\n",
    "    if self.textrank_scores is None or self.adjacency_matrix is None:\n",
    "        print(\"Chưa tính TextRank\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nDEMO: Minh họa cách tính TextRank cho câu {sentence_idx}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    sentence = self.sentences[sentence_idx]['original'][:80]\n",
    "    print(f\"Câu: '{sentence}...'\")\n",
    "    \n",
    "    n = len(self.sentences)\n",
    "    \n",
    "    # Tìm các câu liên kết đến câu này\n",
    "    incoming_links = []\n",
    "    for i in range(n):\n",
    "        if self.adjacency_matrix[i, sentence_idx] == 1:\n",
    "            incoming_links.append(i)\n",
    "    \n",
    "    print(f\"\\n1. CÁC CÂU LIÊN KẾT ĐẾN:\")\n",
    "    if incoming_links:\n",
    "        for link_idx in incoming_links:\n",
    "            link_sentence = self.sentences[link_idx]['original'][:50]\n",
    "            outgoing_count = np.sum(self.adjacency_matrix[link_idx])\n",
    "            print(f\"   - Câu {link_idx}: '{link_sentence}...' (có {int(outgoing_count)} liên kết ra)\")\n",
    "    else:\n",
    "        print(\"   - Không có liên kết đến\")\n",
    "    \n",
    "    print(f\"\\n2. CÔNG THỨC TEXTRANK:\")\n",
    "    print(f\"   TR(S{sentence_idx}) = (1-d)/N + d × Σ(TR(Si)/C(Si))\")\n",
    "    \n",
    "    # Tính từng thành phần\n",
    "    teleport_term = (1 - self.damping_factor) / n\n",
    "    print(f\"\\n3. TÍNH TOÁN CHI TIẾT:\")\n",
    "    print(f\"   a) Teleport term = (1-d)/N = (1-{self.damping_factor})/{n} = {teleport_term:.6f}\")\n",
    "    \n",
    "    link_contribution = 0\n",
    "    print(f\"   b) Link contribution:\")\n",
    "    if incoming_links:\n",
    "        for link_idx in incoming_links:\n",
    "            tr_link = self.textrank_scores[link_idx]\n",
    "            outgoing_count = np.sum(self.adjacency_matrix[link_idx])\n",
    "            contribution = tr_link / outgoing_count if outgoing_count > 0 else 0\n",
    "            link_contribution += contribution\n",
    "            print(f\"      - Từ câu {link_idx}: TR = {tr_link:.6f}, \"\n",
    "                  f\"C = {int(outgoing_count)}, \"\n",
    "                  f\"Contribution = {tr_link:.6f}/{int(outgoing_count)} = {contribution:.6f}\")\n",
    "        \n",
    "        print(f\"      Tổng link contribution = {link_contribution:.6f}\")\n",
    "    else:\n",
    "        print(f\"      Không có liên kết → contribution = 0\")\n",
    "    \n",
    "    final_textrank = teleport_term + self.damping_factor * link_contribution\n",
    "    actual_textrank = self.textrank_scores[sentence_idx]\n",
    "    \n",
    "    print(f\"\\n4. KẾT QUẢ CUỐI CÙNG:\")\n",
    "    print(f\"   TR(S{sentence_idx}) = {teleport_term:.6f} + {self.damping_factor} × {link_contribution:.6f}\")\n",
    "    print(f\"   TR(S{sentence_idx}) = {teleport_term:.6f} + {self.damping_factor * link_contribution:.6f}\")\n",
    "    print(f\"   TR(S{sentence_idx}) = {final_textrank:.6f}\")\n",
    "    print(f\"   TextRank thực tế: {actual_textrank:.6f}\")\n",
    "    print(f\"   Sai số: {abs(final_textrank - actual_textrank):.8f}\")\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.calculate_textrank = calculate_textrank\n",
    "TextSummarizerTFIDFTextRank.demonstrate_textrank_calculation = demonstrate_textrank_calculation\n",
    "\n",
    "print(\"Đã thêm thuật toán TextRank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f268b910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tính TextRank bằng Power Iteration...\n",
      "Khởi tạo: TR₀ = [1/160, 1/160, ..., 1/160] = 0.006250\n",
      "\n",
      "Công thức TextRank:\n",
      "   TR_new = (1-d)/N + d × M^T × TR_old\n",
      "   Với d = 0.85, N = 160\n",
      "   Teleport term = (1-d)/N = 0.000938\n",
      "\n",
      "Quá trình lặp:\n",
      "Vòng   Thay đổi        Top 3 điểm               \n",
      "--------------------------------------------------\n",
      "1      0.04420761      0.0159, 0.0154, 0.0154   \n",
      "2      0.01440684      0.0172, 0.0160, 0.0146   \n",
      "3      0.00521308      0.0175, 0.0166, 0.0158   \n",
      "4      0.00290653      0.0179, 0.0169, 0.0161   \n",
      "5      0.00138195      0.0179, 0.0170, 0.0163   \n",
      "6      0.00087208      0.0181, 0.0171, 0.0164   \n",
      "7      0.00044022      0.0181, 0.0172, 0.0164   \n",
      "8      0.00029009      0.0181, 0.0172, 0.0165   \n",
      "9      0.00015133      0.0181, 0.0172, 0.0165   \n",
      "10     0.00010186      0.0181, 0.0172, 0.0165   \n",
      "11     0.00005503      0.0181, 0.0173, 0.0165   \n",
      "12     0.00003745      0.0181, 0.0173, 0.0165   \n",
      "13     0.00002103      0.0181, 0.0173, 0.0165   \n",
      "14     0.00001437      0.0181, 0.0173, 0.0165   \n",
      "15     0.00000838      0.0181, 0.0173, 0.0165   \n",
      "16     0.00000572      0.0181, 0.0173, 0.0165   \n",
      "17     0.00000345      0.0181, 0.0173, 0.0165   \n",
      "18     0.00000235      0.0181, 0.0173, 0.0165   \n",
      "19     0.00000145      0.0181, 0.0173, 0.0165   \n",
      "20     0.00000098      0.0181, 0.0173, 0.0165   \n",
      "\n",
      "Hội tụ sau 20 vòng lặp!\n",
      "\n",
      "DEMO: Minh họa cách tính TextRank cho câu 0\n",
      "======================================================================\n",
      "Câu: 'Former East German leader Erich Honecker may be moved to a monastery to protect ...'\n",
      "\n",
      "1. CÁC CÂU LIÊN KẾT ĐẾN:\n",
      "   - Câu 8: '``This is the only possibility to protect Erich Ho...' (có 16 liên kết ra)\n",
      "   - Câu 13: '``Sources say the ailing ex-leader may be placed i...' (có 1 liên kết ra)\n",
      "   - Câu 14: 'As protests gathered strength last fall, East Germ...' (có 14 liên kết ra)\n",
      "   - Câu 42: 'Ousted East German leader Erich Honecker, who is e...' (có 24 liên kết ra)\n",
      "   - Câu 77: 'But a medical exam by a team of doctors found him ...' (có 8 liên kết ra)\n",
      "   - Câu 97: 'Ousted East German leader Erich Honecker will not ...' (có 22 liên kết ra)\n",
      "   - Câu 109: 'East Germany's ousted secret police chief threaten...' (có 19 liên kết ra)\n",
      "   - Câu 111: '82-year-old former security chief Erich Mielke sho...' (có 12 liên kết ra)\n",
      "   - Câu 125: 'Bild said Mielke and other members of Honecker's r...' (có 21 liên kết ra)\n",
      "   - Câu 126: 'Honecker also will be moved to the same jail if hi...' (có 12 liên kết ra)\n",
      "\n",
      "2. CÔNG THỨC TEXTRANK:\n",
      "   TR(S0) = (1-d)/N + d × Σ(TR(Si)/C(Si))\n",
      "\n",
      "3. TÍNH TOÁN CHI TIẾT:\n",
      "   a) Teleport term = (1-d)/N = (1-0.85)/160 = 0.000938\n",
      "   b) Link contribution:\n",
      "      - Từ câu 8: TR = 0.012777, C = 16, Contribution = 0.012777/16 = 0.000799\n",
      "      - Từ câu 13: TR = 0.001678, C = 1, Contribution = 0.001678/1 = 0.001678\n",
      "      - Từ câu 14: TR = 0.010476, C = 14, Contribution = 0.010476/14 = 0.000748\n",
      "      - Từ câu 42: TR = 0.017264, C = 24, Contribution = 0.017264/24 = 0.000719\n",
      "      - Từ câu 77: TR = 0.006061, C = 8, Contribution = 0.006061/8 = 0.000758\n",
      "      - Từ câu 97: TR = 0.015738, C = 22, Contribution = 0.015738/22 = 0.000715\n",
      "      - Từ câu 109: TR = 0.014499, C = 19, Contribution = 0.014499/19 = 0.000763\n",
      "      - Từ câu 111: TR = 0.009076, C = 12, Contribution = 0.009076/12 = 0.000756\n",
      "      - Từ câu 125: TR = 0.015131, C = 21, Contribution = 0.015131/21 = 0.000721\n",
      "      - Từ câu 126: TR = 0.009416, C = 12, Contribution = 0.009416/12 = 0.000785\n",
      "      Tổng link contribution = 0.008442\n",
      "\n",
      "4. KẾT QUẢ CUỐI CÙNG:\n",
      "   TR(S0) = 0.000938 + 0.85 × 0.008442\n",
      "   TR(S0) = 0.000938 + 0.007176\n",
      "   TR(S0) = 0.008113\n",
      "   TextRank thực tế: 0.008160\n",
      "   Sai số: 0.00004707\n",
      "\n",
      "KẾT QUẢ TEXTRANK:\n",
      "============================================================\n",
      "Hạng   Điểm TR      Câu                                                         \n",
      "--------------------------------------------------------------------------------\n",
      "1      0.018131     Ousted East German leader Erich Honecker was arrested a...\n",
      "2      0.017264     Ousted East German leader Erich Honecker, who is expect...\n",
      "3      0.016524     East Germany's deposed Communist leader Erich Honecker ...\n",
      "4      0.015738     Ousted East German leader Erich Honecker will not stand...\n",
      "5      0.015131     Bild said Mielke and other members of Honecker's ruling...\n",
      "6      0.015017     Honecker, 78, was ousted as East Germany's leader on Oc...\n",
      "7      0.014499     East Germany's ousted secret police chief threatened to...\n",
      "8      0.014022     Earlier this month, East German prosecutors said Honeck...\n",
      "9      0.013323     On Sunday, West Germany's mass-circulation Bild newspap...\n",
      "10     0.013323     On Sunday, West Germany's mass-circulation Bild newspap...\n",
      "\n",
      "Thống kê TextRank:\n",
      "   - Tổng điểm: 1.000000\n",
      "   - Điểm trung bình: 0.006250\n",
      "   - Độ lệch chuẩn: 0.003729\n",
      "   - Điểm cao nhất: 0.018131\n",
      "   - Điểm thấp nhất: 0.000985\n",
      "\n",
      "Bước 5 hoàn thành: Đã tính TextRank cho 160 câu\n"
     ]
    }
   ],
   "source": [
    "# Demo: Tính TextRank\n",
    "if summarizer.transition_matrix is not None:\n",
    "    # Tính TextRank\n",
    "    textrank_scores, history = summarizer.calculate_textrank()\n",
    "    \n",
    "    # Minh họa cách tính cho một câu\n",
    "    if len(summarizer.sentences) > 0:\n",
    "        summarizer.demonstrate_textrank_calculation(0)\n",
    "    \n",
    "    # Hiển thị kết quả TextRank\n",
    "    print(f\"\\nKẾT QUẢ TEXTRANK:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Tạo danh sách kết quả\n",
    "    results = []\n",
    "    for i, score in enumerate(textrank_scores):\n",
    "        results.append({\n",
    "            'index': i,\n",
    "            'score': score,\n",
    "            'sentence': summarizer.sentences[i]['original']\n",
    "        })\n",
    "    \n",
    "    # Sắp xếp theo điểm giảm dần\n",
    "    results.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    print(f\"{'Hạng':<6} {'Điểm TR':<12} {'Câu':<60}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Hiển thị top 10\n",
    "    for rank, result in enumerate(results[:10], 1):\n",
    "        sentence_preview = result['sentence'][:55]\n",
    "        print(f\"{rank:<6} {result['score']:<12.6f} {sentence_preview}...\")\n",
    "    \n",
    "    # Thống kê\n",
    "    print(f\"\\nThống kê TextRank:\")\n",
    "    print(f\"   - Tổng điểm: {np.sum(textrank_scores):.6f}\")\n",
    "    print(f\"   - Điểm trung bình: {np.mean(textrank_scores):.6f}\")\n",
    "    print(f\"   - Độ lệch chuẩn: {np.std(textrank_scores):.6f}\")\n",
    "    print(f\"   - Điểm cao nhất: {np.max(textrank_scores):.6f}\")\n",
    "    print(f\"   - Điểm thấp nhất: {np.min(textrank_scores):.6f}\")\n",
    "    \n",
    "    print(f\"\\nBước 5 hoàn thành: Đã tính TextRank cho {len(textrank_scores)} câu\")\n",
    "else:\n",
    "    print(\"Chưa có ma trận chuyển tiếp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a03746",
   "metadata": {},
   "source": [
    "## 7. Bước 6: Tạo Bản Tóm Tắt (Lấy 10% Câu Quan Trọng Nhất)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dd02d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Đã thêm các phương thức tạo tóm tắt\n"
     ]
    }
   ],
   "source": [
    "def generate_summary(self, summary_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Tạo bản tóm tắt bằng cách chọn top câu có điểm TextRank cao nhất\n",
    "    \"\"\"\n",
    "    print(f\"Đang tạo bản tóm tắt với tỷ lệ {summary_ratio*100}%...\")\n",
    "    \n",
    "    if self.textrank_scores is None:\n",
    "        print(\"Chưa tính TextRank\")\n",
    "        return None\n",
    "    \n",
    "    total_sentences = len(self.sentences)\n",
    "    num_summary_sentences = max(1, int(total_sentences * summary_ratio))\n",
    "    \n",
    "    print(f\"Chọn {num_summary_sentences} câu từ {total_sentences} câu gốc\")\n",
    "    \n",
    "    # Tạo danh sách câu với điểm số và vị trí gốc\n",
    "    sentence_scores = []\n",
    "    for i, score in enumerate(self.textrank_scores):\n",
    "        sentence_scores.append({\n",
    "            'index': i,\n",
    "            'score': score,\n",
    "            'sentence': self.sentences[i]['original']\n",
    "        })\n",
    "    \n",
    "    # Sắp xếp theo điểm TextRank giảm dần\n",
    "    sentence_scores.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # Chọn top câu\n",
    "    selected_sentences = sentence_scores[:num_summary_sentences]\n",
    "    \n",
    "    # Sắp xếp lại theo thứ tự xuất hiện trong văn bản gốc\n",
    "    selected_sentences.sort(key=lambda x: x['index'])\n",
    "    \n",
    "    # Tạo văn bản tóm tắt\n",
    "    summary_text = []\n",
    "    for item in selected_sentences:\n",
    "        summary_text.append(item['sentence'])\n",
    "    \n",
    "    summary = {\n",
    "        'sentences': selected_sentences,\n",
    "        'text': ' '.join(summary_text),\n",
    "        'ratio': summary_ratio,\n",
    "        'original_count': total_sentences,\n",
    "        'summary_count': num_summary_sentences\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def display_summary(self, summary):\n",
    "    \"\"\"\n",
    "    Hiển thị bản tóm tắt\n",
    "    \"\"\"\n",
    "    if summary is None:\n",
    "        print(\"Không có bản tóm tắt\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nBẢN TÓM TẮT:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Tỷ lệ: {summary['ratio']*100}% ({summary['summary_count']}/{summary['original_count']} câu)\")\n",
    "    print(f\"Độ dài: {len(summary['text'])} ký tự\")\n",
    "    print()\n",
    "    \n",
    "    # Hiển thị từng câu được chọn\n",
    "    print(\"Các câu được chọn:\")\n",
    "    for i, item in enumerate(summary['sentences'], 1):\n",
    "        print(f\"{i}. [Câu {item['index']}, Điểm: {item['score']:.4f}]\")\n",
    "        print(f\"   {item['sentence']}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"Văn bản tóm tắt liên tục:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(summary['text'])\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.generate_summary = generate_summary\n",
    "TextSummarizerTFIDFTextRank.display_summary = display_summary\n",
    "\n",
    "print(\"✓ Đã thêm các phương thức tạo tóm tắt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "837fc6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tạo bản tóm tắt với tỷ lệ 10.0%...\n",
      "Chọn 16 câu từ 160 câu gốc\n",
      "\n",
      "BẢN TÓM TẮT:\n",
      "======================================================================\n",
      "Tỷ lệ: 10.0% (16/160 câu)\n",
      "Độ dài: 2508 ký tự\n",
      "\n",
      "Các câu được chọn:\n",
      "1. [Câu 4, Điểm: 0.0120]\n",
      "   In December, seven former Politburo members were arrested, and Honecker was placed under house arrest in the government housing area of Wandlitz outside East Berlin\n",
      "\n",
      "2. [Câu 8, Điểm: 0.0128]\n",
      "   ``This is the only possibility to protect Erich Honecker from the rage of the East German people,'' Bild quoted the source as saying\n",
      "\n",
      "3. [Câu 42, Điểm: 0.0173]\n",
      "   Ousted East German leader Erich Honecker, who is expected to be indicted for high treason, was arrested Monday morning upon release from a hospital and taken to prison, the official news agency ADN said\n",
      "\n",
      "4. [Câu 46, Điểm: 0.0140]\n",
      "   Earlier this month, East German prosecutors said Honecker and former state security chief Erich Mielke would be charged with treason and corruption charges for misuse of their positions and state funds\n",
      "\n",
      "5. [Câu 51, Điểm: 0.0133]\n",
      "   On Sunday, West Germany's mass-circulation Bild newspaper said Honecker would be arrested, but that he would be held at a prison hospital because of his condition\n",
      "\n",
      "6. [Câu 54, Điểm: 0.0181]\n",
      "   Ousted East German leader Erich Honecker was arrested and taken to prison today, and a prosecutor said he will tried for high treason in March\n",
      "\n",
      "7. [Câu 72, Điểm: 0.0133]\n",
      "   On Sunday, West Germany's mass-circulation Bild newspaper said Honecker would be arrested but that he would be held at a prison hospital because of his condition\n",
      "\n",
      "8. [Câu 75, Điểm: 0.0165]\n",
      "   East Germany's deposed Communist leader Erich Honecker is too sick to be held in jail but is fit enough to be tried, the official news agency ADN reported Monday\n",
      "\n",
      "9. [Câu 76, Điểm: 0.0121]\n",
      "   ADN, quoting a Health Ministry statement, said Honecker was still recovering from surgery for kidney cancer in January and was not well enough to be incarcerated\n",
      "\n",
      "10. [Câu 94, Điểm: 0.0130]\n",
      "   Last month, a medical panel ruled that Honecker was too ill to be jailed pending investigation but fit enough to be prosecuted\n",
      "\n",
      "11. [Câu 97, Điểm: 0.0157]\n",
      "   Ousted East German leader Erich Honecker will not stand trial in East Germany as long as the formerly Communist country exists, a West German newspaper reported\n",
      "\n",
      "12. [Câu 100, Điểm: 0.0132]\n",
      "   However, Seidel said that the investigation was not far enough along to determine whether charges could be filed against Honecker before East Germany merges with West Germany on Oct\n",
      "\n",
      "13. [Câu 102, Điểm: 0.0150]\n",
      "   Honecker, 78, was ousted as East Germany's leader on Oct\n",
      "\n",
      "14. [Câu 109, Điểm: 0.0145]\n",
      "   East Germany's ousted secret police chief threatened to break former Communist leader Erich Honecker's neck when the two faced each other in jail, a West German newspaper reported Wednesday\n",
      "\n",
      "15. [Câu 117, Điểm: 0.0129]\n",
      "   After the popular revolt last fall that ousted the Communist regime and opened the way to German unification, Mielke and other former Communist leaders were jailed\n",
      "\n",
      "16. [Câu 125, Điểm: 0.0151]\n",
      "   Bild said Mielke and other members of Honecker's ruling circle will be moved to a West Berlin prison after German unification on Oct\n",
      "\n",
      "Văn bản tóm tắt liên tục:\n",
      "--------------------------------------------------\n",
      "In December, seven former Politburo members were arrested, and Honecker was placed under house arrest in the government housing area of Wandlitz outside East Berlin ``This is the only possibility to protect Erich Honecker from the rage of the East German people,'' Bild quoted the source as saying Ousted East German leader Erich Honecker, who is expected to be indicted for high treason, was arrested Monday morning upon release from a hospital and taken to prison, the official news agency ADN said Earlier this month, East German prosecutors said Honecker and former state security chief Erich Mielke would be charged with treason and corruption charges for misuse of their positions and state funds On Sunday, West Germany's mass-circulation Bild newspaper said Honecker would be arrested, but that he would be held at a prison hospital because of his condition Ousted East German leader Erich Honecker was arrested and taken to prison today, and a prosecutor said he will tried for high treason in March On Sunday, West Germany's mass-circulation Bild newspaper said Honecker would be arrested but that he would be held at a prison hospital because of his condition East Germany's deposed Communist leader Erich Honecker is too sick to be held in jail but is fit enough to be tried, the official news agency ADN reported Monday ADN, quoting a Health Ministry statement, said Honecker was still recovering from surgery for kidney cancer in January and was not well enough to be incarcerated Last month, a medical panel ruled that Honecker was too ill to be jailed pending investigation but fit enough to be prosecuted Ousted East German leader Erich Honecker will not stand trial in East Germany as long as the formerly Communist country exists, a West German newspaper reported However, Seidel said that the investigation was not far enough along to determine whether charges could be filed against Honecker before East Germany merges with West Germany on Oct Honecker, 78, was ousted as East Germany's leader on Oct East Germany's ousted secret police chief threatened to break former Communist leader Erich Honecker's neck when the two faced each other in jail, a West German newspaper reported Wednesday After the popular revolt last fall that ousted the Communist regime and opened the way to German unification, Mielke and other former Communist leaders were jailed Bild said Mielke and other members of Honecker's ruling circle will be moved to a West Berlin prison after German unification on Oct\n",
      "\n",
      "Đã lưu bản tóm tắt vào: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK/output_summary.docx\n",
      "\n",
      "Bước 6-7 hoàn thành: Đã tạo và lưu bản tóm tắt\n"
     ]
    }
   ],
   "source": [
    "# Demo: Tạo bản tóm tắt và lưu vào Word\n",
    "if summarizer.textrank_scores is not None:\n",
    "    # Tạo tóm tắt với 10% câu\n",
    "    summary = summarizer.generate_summary(summary_ratio=0.1)\n",
    "    \n",
    "    # Hiển thị tóm tắt\n",
    "    summarizer.display_summary(summary)\n",
    "    \n",
    "    # Lưu tóm tắt vào file Word (output_summary.docx)\n",
    "    if summary:\n",
    "        output_filename = os.path.join(BASE_PATH, \"output_summary.docx\")\n",
    "        \n",
    "        # Tạo document Word với format đẹp\n",
    "        doc = Document()\n",
    "        doc.add_heading('BẢN TÓM TẮT VĂN BẢN BẰNG TEXTRANK', 0)\n",
    "        \n",
    "        # Thông tin tóm tắt\n",
    "        doc.add_heading('Thông tin tóm tắt:', level=1)\n",
    "        info_para = doc.add_paragraph()\n",
    "        info_para.add_run(f\"• Tỷ lệ tóm tắt: {summary['ratio']*100}%\\n\")\n",
    "        info_para.add_run(f\"• Số câu gốc: {summary['original_count']}\\n\")\n",
    "        info_para.add_run(f\"• Số câu tóm tắt: {summary['summary_count']}\\n\")\n",
    "        info_para.add_run(f\"• Độ dài: {len(summary['text'])} ký tự\\n\")\n",
    "        \n",
    "        # Văn bản tóm tắt\n",
    "        doc.add_heading('Văn bản tóm tắt:', level=1)\n",
    "        doc.add_paragraph(summary['text'])\n",
    "        \n",
    "        # Chi tiết các câu được chọn\n",
    "        doc.add_heading('Chi tiết các câu được chọn:', level=1)\n",
    "        for i, item in enumerate(summary['sentences'], 1):\n",
    "            para = doc.add_paragraph()\n",
    "            para.add_run(f\"{i}. \").bold = True\n",
    "            para.add_run(f\"[Câu {item['index']}, Điểm TextRank: {item['score']:.4f}]\\n\")\n",
    "            para.add_run(item['sentence'])\n",
    "        \n",
    "        doc.save(output_filename)\n",
    "        print(f\"\\nĐã lưu bản tóm tắt vào: {output_filename}\")\n",
    "        \n",
    "        print(f\"\\nBước 6-7 hoàn thành: Đã tạo và lưu bản tóm tắt\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Không thể tạo tóm tắt\")\n",
    "        \n",
    "else:\n",
    "    print(\"Chưa tính TextRank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d8fe4",
   "metadata": {},
   "source": [
    "## 8. Bước 8: Đọc DUC Reference Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08a3b8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tìm DUC reference cho: d070f\n",
      "✓ Đã đọc reference: 2453 ký tự\n",
      "✓ Preview: Ousted East German leader Erich Honecker, who is expected to be indicted for high treason, was arres...\n",
      "Đã lưu DUC reference vào: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK/Test_DUC_SUM.docx\n",
      "\n",
      "Bước 8 hoàn thành: Đã đọc và lưu DUC reference summary\n",
      "Đã lưu DUC reference vào: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/NLP_TFIDF_PAGERANK/Test_DUC_SUM.docx\n",
      "\n",
      "Bước 8 hoàn thành: Đã đọc và lưu DUC reference summary\n"
     ]
    }
   ],
   "source": [
    "# Bước 8: Đọc DUC reference summary tương ứng\n",
    "def load_duc_reference(doc_filename):\n",
    "    \"\"\"\n",
    "    Đọc file DUC reference summary tương ứng với tài liệu\n",
    "    \"\"\"\n",
    "    print(f\"Đang tìm DUC reference cho: {doc_filename}\")\n",
    "    \n",
    "    # Tìm file reference tương ứng\n",
    "    reference_path = os.path.join(DUC_SUM_PATH, doc_filename)\n",
    "    \n",
    "    if os.path.exists(reference_path):\n",
    "        try:\n",
    "            with open(reference_path, 'r', encoding='utf-8') as f:\n",
    "                reference_content = f.read()\n",
    "            \n",
    "            # Làm sạch nội dung reference\n",
    "            reference_content = re.sub(r'<[^>]+>', '', reference_content)\n",
    "            reference_content = reference_content.strip()\n",
    "            \n",
    "            print(f\"✓ Đã đọc reference: {len(reference_content)} ký tự\")\n",
    "            print(f\"✓ Preview: {reference_content[:100]}...\")\n",
    "            \n",
    "            return reference_content\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc reference: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Không tìm thấy file reference: {reference_path}\")\n",
    "        return None\n",
    "\n",
    "# Demo: Đọc DUC reference và lưu vào Word\n",
    "if os.path.exists(DUC_TEXT_PATH):\n",
    "    files = [f for f in os.listdir(DUC_TEXT_PATH) if not f.startswith('.')]\n",
    "    if files and 'demo_file' in locals():\n",
    "        # Sử dụng cùng file đã chọn ở bước 1\n",
    "        \n",
    "        # Đọc reference\n",
    "        reference_content = load_duc_reference(demo_file)\n",
    "        \n",
    "        if reference_content:\n",
    "            # Lưu reference vào file Word (Test_DUC_SUM.docx)\n",
    "            reference_filename = os.path.join(BASE_PATH, \"Test_DUC_SUM.docx\")\n",
    "            \n",
    "            doc = Document()\n",
    "            doc.add_heading('DUC REFERENCE SUMMARY', 0)\n",
    "            \n",
    "            # Thông tin file\n",
    "            doc.add_heading('Thông tin:', level=1)\n",
    "            info_para = doc.add_paragraph()\n",
    "            info_para.add_run(f\"• File gốc: {demo_file}\\n\")\n",
    "            info_para.add_run(f\"• Đường dẫn reference: {os.path.join(DUC_SUM_PATH, demo_file)}\\n\")\n",
    "            info_para.add_run(f\"• Độ dài: {len(reference_content)} ký tự\\n\")\n",
    "            \n",
    "            # Nội dung reference\n",
    "            doc.add_heading('Nội dung reference summary:', level=1)\n",
    "            doc.add_paragraph(reference_content)\n",
    "            \n",
    "            doc.save(reference_filename)\n",
    "            print(f\"Đã lưu DUC reference vào: {reference_filename}\")\n",
    "            \n",
    "            # Lưu vào biến để sử dụng trong evaluation\n",
    "            duc_reference = reference_content\n",
    "            \n",
    "            print(f\"\\nBước 8 hoàn thành: Đã đọc và lưu DUC reference summary\")\n",
    "        else:\n",
    "            duc_reference = None\n",
    "            print(\"Không thể đọc DUC reference\")\n",
    "    else:\n",
    "        print(\"Không có file để xử lý\")\n",
    "        duc_reference = None\n",
    "else:\n",
    "    print(f\"Thư mục không tồn tại: {DUC_TEXT_PATH}\")\n",
    "    duc_reference = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8d9ca",
   "metadata": {},
   "source": [
    "## 9. Bước 9: Đánh Giá Bằng ROUGE Metrics\n",
    "\n",
    "**ROUGE (Recall-Oriented Understudy for Gisting Evaluation):**\n",
    "\n",
    "- **ROUGE-1**: Đo overlap của unigrams (từ đơn)\n",
    "- **ROUGE-2**: Đo overlap của bigrams (cặp từ)\n",
    "- **ROUGE-L**: Đo Longest Common Subsequence (LCS)\n",
    "\n",
    "**Công thức:**\n",
    "\n",
    "- **Precision** = (số từ chung) / (số từ trong summary)\n",
    "- **Recall** = (số từ chung) / (số từ trong reference)\n",
    "- **F1-Score** = 2 × (Precision × Recall) / (Precision + Recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9f31592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Đã thêm các phương thức đánh giá ROUGE\n"
     ]
    }
   ],
   "source": [
    "def calculate_rouge_1(generated_summary, reference_summary):\n",
    "    \"\"\"\n",
    "    Tính ROUGE-1 (unigram overlap) - viết tay công thức\n",
    "    \"\"\"\n",
    "    # Tách từ và làm sạch\n",
    "    gen_words = re.findall(r'\\b\\w+\\b', generated_summary.lower())\n",
    "    ref_words = re.findall(r'\\b\\w+\\b', reference_summary.lower())\n",
    "    \n",
    "    # Đếm từ\n",
    "    gen_word_count = Counter(gen_words)\n",
    "    ref_word_count = Counter(ref_words)\n",
    "    \n",
    "    # Tính overlap\n",
    "    overlap = 0\n",
    "    for word in gen_word_count:\n",
    "        if word in ref_word_count:\n",
    "            overlap += min(gen_word_count[word], ref_word_count[word])\n",
    "    \n",
    "    # Tính precision, recall, f1\n",
    "    precision = overlap / len(gen_words) if len(gen_words) > 0 else 0\n",
    "    recall = overlap / len(ref_words) if len(ref_words) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'overlap': overlap,\n",
    "        'gen_length': len(gen_words),\n",
    "        'ref_length': len(ref_words)\n",
    "    }\n",
    "\n",
    "def calculate_rouge_2(generated_summary, reference_summary):\n",
    "    \"\"\"\n",
    "    Tính ROUGE-2 (bigram overlap) - viết tay công thức\n",
    "    \"\"\"\n",
    "    # Tách từ\n",
    "    gen_words = re.findall(r'\\b\\w+\\b', generated_summary.lower())\n",
    "    ref_words = re.findall(r'\\b\\w+\\b', reference_summary.lower())\n",
    "    \n",
    "    # Tạo bigrams\n",
    "    gen_bigrams = []\n",
    "    for i in range(len(gen_words) - 1):\n",
    "        gen_bigrams.append((gen_words[i], gen_words[i+1]))\n",
    "    \n",
    "    ref_bigrams = []\n",
    "    for i in range(len(ref_words) - 1):\n",
    "        ref_bigrams.append((ref_words[i], ref_words[i+1]))\n",
    "    \n",
    "    # Đếm bigrams\n",
    "    gen_bigram_count = Counter(gen_bigrams)\n",
    "    ref_bigram_count = Counter(ref_bigrams)\n",
    "    \n",
    "    # Tính overlap\n",
    "    overlap = 0\n",
    "    for bigram in gen_bigram_count:\n",
    "        if bigram in ref_bigram_count:\n",
    "            overlap += min(gen_bigram_count[bigram], ref_bigram_count[bigram])\n",
    "    \n",
    "    # Tính precision, recall, f1\n",
    "    precision = overlap / len(gen_bigrams) if len(gen_bigrams) > 0 else 0\n",
    "    recall = overlap / len(ref_bigrams) if len(ref_bigrams) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'overlap': overlap,\n",
    "        'gen_length': len(gen_bigrams),\n",
    "        'ref_length': len(ref_bigrams)\n",
    "    }\n",
    "\n",
    "def calculate_lcs_length(seq1, seq2):\n",
    "    \"\"\"\n",
    "    Tính độ dài Longest Common Subsequence - viết tay bằng dynamic programming\n",
    "    \"\"\"\n",
    "    m, n = len(seq1), len(seq2)\n",
    "    \n",
    "    # Tạo bảng DP\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    \n",
    "    # Fill bảng DP\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if seq1[i-1] == seq2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
    "    \n",
    "    return dp[m][n]\n",
    "\n",
    "def calculate_rouge_l(generated_summary, reference_summary):\n",
    "    \"\"\"\n",
    "    Tính ROUGE-L (LCS-based) - viết tay công thức\n",
    "    \"\"\"\n",
    "    # Tách từ\n",
    "    gen_words = re.findall(r'\\b\\w+\\b', generated_summary.lower())\n",
    "    ref_words = re.findall(r'\\b\\w+\\b', reference_summary.lower())\n",
    "    \n",
    "    # Tính LCS\n",
    "    lcs_length = calculate_lcs_length(gen_words, ref_words)\n",
    "    \n",
    "    # Tính precision, recall, f1\n",
    "    precision = lcs_length / len(gen_words) if len(gen_words) > 0 else 0\n",
    "    recall = lcs_length / len(ref_words) if len(ref_words) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'lcs_length': lcs_length,\n",
    "        'gen_length': len(gen_words),\n",
    "        'ref_length': len(ref_words)\n",
    "    }\n",
    "\n",
    "def evaluate_summary(generated_summary, reference_summary):\n",
    "    \"\"\"\n",
    "    Đánh giá toàn diện bằng ROUGE metrics\n",
    "    \"\"\"\n",
    "    print(\"Đang đánh giá bằng ROUGE metrics...\")\n",
    "    \n",
    "    # Tính các ROUGE scores\n",
    "    rouge_1 = calculate_rouge_1(generated_summary, reference_summary)\n",
    "    rouge_2 = calculate_rouge_2(generated_summary, reference_summary)\n",
    "    rouge_l = calculate_rouge_l(generated_summary, reference_summary)\n",
    "    \n",
    "    # Hiển thị kết quả\n",
    "    print(f\"\\nKẾT QUẢ ĐÁNH GIÁ ROUGE:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nROUGE-1 (Unigram Overlap):\")\n",
    "    print(f\"   Precision: {rouge_1['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {rouge_1['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {rouge_1['f1']:.4f}\")\n",
    "    print(f\"   Overlap:   {rouge_1['overlap']}/{rouge_1['gen_length']} vs {rouge_1['ref_length']} words\")\n",
    "    \n",
    "    print(f\"\\nROUGE-2 (Bigram Overlap):\")\n",
    "    print(f\"   Precision: {rouge_2['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {rouge_2['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {rouge_2['f1']:.4f}\")\n",
    "    print(f\"   Overlap:   {rouge_2['overlap']}/{rouge_2['gen_length']} vs {rouge_2['ref_length']} bigrams\")\n",
    "    \n",
    "    print(f\"\\nROUGE-L (LCS-based):\")\n",
    "    print(f\"   Precision: {rouge_l['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {rouge_l['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {rouge_l['f1']:.4f}\")\n",
    "    print(f\"   LCS:       {rouge_l['lcs_length']}/{rouge_l['gen_length']} vs {rouge_l['ref_length']} words\")\n",
    "    \n",
    "    # Tính điểm tổng hợp\n",
    "    overall_f1 = (rouge_1['f1'] + rouge_2['f1'] + rouge_l['f1']) / 3\n",
    "    print(f\"\\nĐIỂM TỔNG HỢP:\")\n",
    "    print(f\"   Overall F1-Score: {overall_f1:.4f}\")\n",
    "    \n",
    "    # Đánh giá chất lượng\n",
    "    if overall_f1 >= 0.5:\n",
    "        quality = \"Xuất sắc\"\n",
    "    elif overall_f1 >= 0.3:\n",
    "        quality = \"Tốt\"\n",
    "    elif overall_f1 >= 0.2:\n",
    "        quality = \"Khá\"\n",
    "    elif overall_f1 >= 0.1:\n",
    "        quality = \"Trung bình\"\n",
    "    else:\n",
    "        quality = \"Cần cải thiện\"\n",
    "    \n",
    "    print(f\"   Chất lượng tóm tắt: {quality}\")\n",
    "    \n",
    "    return {\n",
    "        'rouge_1': rouge_1,\n",
    "        'rouge_2': rouge_2,\n",
    "        'rouge_l': rouge_l,\n",
    "        'overall_f1': overall_f1,\n",
    "        'quality': quality\n",
    "    }\n",
    "\n",
    "print(\"✓ Đã thêm các phương thức đánh giá ROUGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eeff4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu đánh giá so sánh...\n",
      "======================================================================\n",
      "Generated Summary:\n",
      "------------------------------\n",
      "In December, seven former Politburo members were arrested, and Honecker was placed under house arrest in the government housing area of Wandlitz outside East Berlin ``This is the only possibility to protect Erich Honecker from the rage of the East German people,'' Bild quoted the source as saying Ou...\n",
      "\n",
      "DUC Reference Summary:\n",
      "------------------------------\n",
      "Ousted East German leader Erich Honecker, who is expected to be indicted for high treason, was arrested Monday morning upon release from a hospital and taken to prison, the official news agency ADN said.\n",
      " The news agency said the 77-year-old Honecker was arrested after being released from East Berli...\n",
      "Đang đánh giá bằng ROUGE metrics...\n",
      "\n",
      "KẾT QUẢ ĐÁNH GIÁ ROUGE:\n",
      "============================================================\n",
      "\n",
      "ROUGE-1 (Unigram Overlap):\n",
      "   Precision: 0.5227\n",
      "   Recall:    0.5601\n",
      "   F1-Score:  0.5407\n",
      "   Overlap:   219/419 vs 391 words\n",
      "\n",
      "ROUGE-2 (Bigram Overlap):\n",
      "   Precision: 0.2344\n",
      "   Recall:    0.2513\n",
      "   F1-Score:  0.2426\n",
      "   Overlap:   98/418 vs 390 bigrams\n",
      "\n",
      "ROUGE-L (LCS-based):\n",
      "   Precision: 0.2625\n",
      "   Recall:    0.2813\n",
      "   F1-Score:  0.2716\n",
      "   LCS:       110/419 vs 391 words\n",
      "\n",
      "ĐIỂM TỔNG HỢP:\n",
      "   Overall F1-Score: 0.3516\n",
      "   Chất lượng tóm tắt: Tốt\n",
      "\n",
      "DEMO: Minh họa cách tính ROUGE-1\n",
      "==================================================\n",
      "Generated words: 419 từ\n",
      "Reference words: 391 từ\n",
      "Từ chung (overlap): 219 từ\n",
      "\n",
      "Công thức ROUGE-1:\n",
      "Precision = overlap / gen_length = 219 / 419 = 0.5227\n",
      "Recall = overlap / ref_length = 219 / 391 = 0.5601\n",
      "F1 = 2 × P × R / (P + R) = 0.5407\n",
      "\n",
      "Bước 9 hoàn thành: Đã đánh giá tóm tắt bằng ROUGE metrics\n"
     ]
    }
   ],
   "source": [
    "# Demo: Đánh giá tóm tắt bằng ROUGE\n",
    "if 'summary' in locals() and summary and 'duc_reference' in locals() and duc_reference:\n",
    "    print(\"Bắt đầu đánh giá so sánh...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Hiển thị hai văn bản cần so sánh\n",
    "    print(\"Generated Summary:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(summary['text'][:300] + \"...\" if len(summary['text']) > 300 else summary['text'])\n",
    "    \n",
    "    print(f\"\\nDUC Reference Summary:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(duc_reference[:300] + \"...\" if len(duc_reference) > 300 else duc_reference)\n",
    "    \n",
    "    # Đánh giá ROUGE\n",
    "    evaluation_results = evaluate_summary(summary['text'], duc_reference)\n",
    "    \n",
    "    # Demo: Minh họa cách tính ROUGE-1 chi tiết\n",
    "    print(f\"\\nDEMO: Minh họa cách tính ROUGE-1\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    gen_words = re.findall(r'\\b\\w+\\b', summary['text'].lower())\n",
    "    ref_words = re.findall(r'\\b\\w+\\b', duc_reference.lower())\n",
    "    \n",
    "    print(f\"Generated words: {len(gen_words)} từ\")\n",
    "    print(f\"Reference words: {len(ref_words)} từ\")\n",
    "    print(f\"Từ chung (overlap): {evaluation_results['rouge_1']['overlap']} từ\")\n",
    "    \n",
    "    print(f\"\\nCông thức ROUGE-1:\")\n",
    "    print(f\"Precision = overlap / gen_length = {evaluation_results['rouge_1']['overlap']} / {len(gen_words)} = {evaluation_results['rouge_1']['precision']:.4f}\")\n",
    "    print(f\"Recall = overlap / ref_length = {evaluation_results['rouge_1']['overlap']} / {len(ref_words)} = {evaluation_results['rouge_1']['recall']:.4f}\")\n",
    "    print(f\"F1 = 2 × P × R / (P + R) = {evaluation_results['rouge_1']['f1']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nBước 9 hoàn thành: Đã đánh giá tóm tắt bằng ROUGE metrics\")\n",
    "    \n",
    "elif 'summary' not in locals() or not summary:\n",
    "    print(\"Chưa có bản tóm tắt để đánh giá\")\n",
    "elif 'duc_reference' not in locals() or not duc_reference:\n",
    "    print(\"Chưa có DUC reference để so sánh\")\n",
    "else:\n",
    "    print(\"Thiếu dữ liệu để đánh giá\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e852d",
   "metadata": {},
   "source": [
    "# CẢI TIẾN 1: SEMANTIC SIMILARITY THAY VÌ TF-IDF\n",
    "\n",
    "**Vấn đề của TF-IDF hiện tại:**\n",
    "\n",
    "- Chỉ dựa trên từ vựng giống nhau\n",
    "- Không hiểu ý nghĩa: \"xe hơi\" và \"ô tô\" được coi là khác nhau\n",
    "- Không nắm bắt được ngữ cảnh\n",
    "\n",
    "**Giải pháp cải tiến:**\n",
    "\n",
    "- Sử dụng BERT/Transformer để hiểu ý nghĩa\n",
    "- Tính similarity dựa trên semantic embeddings\n",
    "- Vector 384 chiều cho mỗi câu thay vì sparse TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "187db2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Đã thêm cải tiến 1: Semantic Similarity\n"
     ]
    }
   ],
   "source": [
    "# CẢI TIẾN 1: Semantic Similarity với BERT/Transformer\n",
    "def get_semantic_embeddings(self, sentences):\n",
    "    \"\"\"\n",
    "    Sử dụng BERT/Transformer để tạo semantic embeddings\n",
    "    Thay thế TF-IDF bằng embeddings hiểu được ý nghĩa\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Import thư viện sentence-transformers (có thể cần cài đặt)\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        print(\"✓ Sử dụng SentenceTransformer cho semantic embeddings\")\n",
    "        \n",
    "        # Load pre-trained model\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        # Tạo embeddings cho tất cả câu\n",
    "        sentence_texts = [sent['original'] for sent in sentences]\n",
    "        embeddings = model.encode(sentence_texts)\n",
    "        \n",
    "        print(f\"✓ Đã tạo semantic embeddings: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Chưa cài đặt sentence-transformers. Sử dụng fallback method...\")\n",
    "        # Fallback: Sử dụng improved TF-IDF với n-grams\n",
    "        return self.get_improved_tfidf_embeddings(sentences)\n",
    "\n",
    "def get_improved_tfidf_embeddings(self, sentences):\n",
    "    \"\"\"\n",
    "    Fallback method: TF-IDF cải tiến với n-grams và stopword removal\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    import re\n",
    "    \n",
    "    print(\"Sử dụng TF-IDF cải tiến với n-grams...\")\n",
    "    \n",
    "    # Tạo vocab với unigrams và bigrams\n",
    "    vocab = set()\n",
    "    for sent in sentences:\n",
    "        words = sent['processed'].split()\n",
    "        # Unigrams\n",
    "        vocab.update(words)\n",
    "        # Bigrams\n",
    "        for i in range(len(words) - 1):\n",
    "            bigram = f\"{words[i]}_{words[i+1]}\"\n",
    "            vocab.update([bigram])\n",
    "    \n",
    "    vocab_list = list(vocab)\n",
    "    vocab_size = len(vocab_list)\n",
    "    word_to_idx = {word: i for i, word in enumerate(vocab_list)}\n",
    "    \n",
    "    # Tạo ma trận TF-IDF cải tiến\n",
    "    embeddings = np.zeros((len(sentences), vocab_size))\n",
    "    \n",
    "    for sent_idx, sent in enumerate(sentences):\n",
    "        words = sent['processed'].split()\n",
    "        word_count = Counter(words)\n",
    "        \n",
    "        # Unigrams\n",
    "        for word in words:\n",
    "            if word in word_to_idx:\n",
    "                tf = word_count[word] / len(words)\n",
    "                idf = math.log(len(sentences) / (1 + sum(1 for s in sentences if word in s['processed'])))\n",
    "                embeddings[sent_idx, word_to_idx[word]] = tf * idf\n",
    "        \n",
    "        # Bigrams\n",
    "        for i in range(len(words) - 1):\n",
    "            bigram = f\"{words[i]}_{words[i+1]}\"\n",
    "            if bigram in word_to_idx:\n",
    "                tf = 1 / len(words)  # Bigram xuất hiện 1 lần\n",
    "                idf = math.log(len(sentences) / (1 + sum(1 for s in sentences \n",
    "                                                        if bigram.replace('_', ' ') in s['processed'])))\n",
    "                embeddings[sent_idx, word_to_idx[bigram]] = tf * idf\n",
    "    \n",
    "    print(f\"✓ TF-IDF cải tiến: {embeddings.shape}\")\n",
    "    return embeddings\n",
    "\n",
    "def semantic_similarity_matrix(self, embeddings):\n",
    "    \"\"\"\n",
    "    Tính ma trận similarity từ semantic embeddings\n",
    "    \"\"\"\n",
    "    print(\"Đang tính semantic similarity matrix...\")\n",
    "    \n",
    "    n_sentences = embeddings.shape[0]\n",
    "    similarity_matrix = np.zeros((n_sentences, n_sentences))\n",
    "    \n",
    "    for i in range(n_sentences):\n",
    "        for j in range(n_sentences):\n",
    "            if i == j:\n",
    "                similarity_matrix[i, j] = 1.0\n",
    "            else:\n",
    "                # Cosine similarity\n",
    "                dot_product = np.dot(embeddings[i], embeddings[j])\n",
    "                norm_i = np.linalg.norm(embeddings[i])\n",
    "                norm_j = np.linalg.norm(embeddings[j])\n",
    "                \n",
    "                if norm_i > 0 and norm_j > 0:\n",
    "                    similarity_matrix[i, j] = dot_product / (norm_i * norm_j)\n",
    "                else:\n",
    "                    similarity_matrix[i, j] = 0.0\n",
    "    \n",
    "    print(f\"✓ Semantic similarity matrix: {similarity_matrix.shape}\")\n",
    "    return similarity_matrix\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.get_semantic_embeddings = get_semantic_embeddings\n",
    "TextSummarizerTFIDFTextRank.get_improved_tfidf_embeddings = get_improved_tfidf_embeddings\n",
    "TextSummarizerTFIDFTextRank.semantic_similarity_matrix = semantic_similarity_matrix\n",
    "\n",
    "print(\"✓ Đã thêm cải tiến 1: Semantic Similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b3331",
   "metadata": {},
   "source": [
    "# CẢI TIẾN 2: WEIGHTED GRAPH VỚI MULTIPLE FEATURES\n",
    "\n",
    "**Vấn đề hiện tại:**\n",
    "\n",
    "- Chỉ dựa trên similarity nội dung\n",
    "- Bỏ qua vị trí câu trong văn bản\n",
    "- Không xét đến độ dài câu\n",
    "\n",
    "**Giải pháp cải tiến:**\n",
    "\n",
    "- Kết hợp nhiều đặc trưng: content similarity, position weight, length similarity\n",
    "- Weighted combination với trọng số được tune\n",
    "- Câu gần nhau trong văn bản có liên quan cao hơn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc863fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Đã thêm cải tiến 2: Weighted Graph với Multiple Features\n"
     ]
    }
   ],
   "source": [
    "# CẢI TIẾN 2: Weighted Graph với Multiple Features\n",
    "def create_weighted_adjacency(self, content_weight=0.6, position_weight=0.2, length_weight=0.2):\n",
    "    \"\"\"\n",
    "    Tạo ma trận kề có trọng số kết hợp nhiều đặc trưng\n",
    "    \"\"\"\n",
    "    print(f\"Đang tạo weighted graph với trọng số: content={content_weight}, position={position_weight}, length={length_weight}\")\n",
    "    \n",
    "    n = len(self.sentences)\n",
    "    \n",
    "    # 1. Content similarity (từ cosine matrix hiện có)\n",
    "    if self.cosine_matrix is not None:\n",
    "        content_sim = self.cosine_matrix.copy()\n",
    "    else:\n",
    "        print(\"Chưa có cosine matrix, tính toán...\")\n",
    "        content_sim = self.build_cosine_matrix()\n",
    "    \n",
    "    # 2. Position similarity\n",
    "    position_sim = self.calculate_position_similarity()\n",
    "    \n",
    "    # 3. Length similarity  \n",
    "    length_sim = self.calculate_length_similarity()\n",
    "    \n",
    "    # 4. Weighted combination\n",
    "    weighted_matrix = (content_weight * content_sim + \n",
    "                      position_weight * position_sim + \n",
    "                      length_weight * length_sim)\n",
    "    \n",
    "    print(f\"✓ Weighted adjacency matrix: {weighted_matrix.shape}\")\n",
    "    \n",
    "    # Hiển thị thống kê\n",
    "    print(f\"   - Content similarity trung bình: {np.mean(content_sim):.4f}\")\n",
    "    print(f\"   - Position similarity trung bình: {np.mean(position_sim):.4f}\")\n",
    "    print(f\"   - Length similarity trung bình: {np.mean(length_sim):.4f}\")\n",
    "    print(f\"   - Weighted similarity trung bình: {np.mean(weighted_matrix):.4f}\")\n",
    "    \n",
    "    return weighted_matrix\n",
    "\n",
    "def calculate_position_similarity(self):\n",
    "    \"\"\"\n",
    "    Tính similarity dựa trên vị trí của câu trong văn bản\n",
    "    Câu gần nhau có similarity cao hơn\n",
    "    \"\"\"\n",
    "    n = len(self.sentences)\n",
    "    position_matrix = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                position_matrix[i, j] = 1.0\n",
    "            else:\n",
    "                # Distance-based similarity\n",
    "                distance = abs(i - j)\n",
    "                # Sử dụng exponential decay\n",
    "                position_matrix[i, j] = math.exp(-distance / (n * 0.1))\n",
    "    \n",
    "    print(f\"✓ Position similarity matrix tính xong\")\n",
    "    return position_matrix\n",
    "\n",
    "def calculate_length_similarity(self):\n",
    "    \"\"\"\n",
    "    Tính similarity dựa trên độ dài câu\n",
    "    Câu có độ dài tương tự thường có cấu trúc giống nhau\n",
    "    \"\"\"\n",
    "    n = len(self.sentences)\n",
    "    length_matrix = np.zeros((n, n))\n",
    "    \n",
    "    # Tính độ dài mỗi câu (số từ)\n",
    "    sentence_lengths = []\n",
    "    for sent in self.sentences:\n",
    "        length = len(sent['processed'].split())\n",
    "        sentence_lengths.append(length)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                length_matrix[i, j] = 1.0\n",
    "            else:\n",
    "                len_i = sentence_lengths[i]\n",
    "                len_j = sentence_lengths[j]\n",
    "                \n",
    "                if len_i == 0 or len_j == 0:\n",
    "                    length_matrix[i, j] = 0.0\n",
    "                else:\n",
    "                    # Ratio similarity\n",
    "                    ratio = min(len_i, len_j) / max(len_i, len_j)\n",
    "                    length_matrix[i, j] = ratio\n",
    "    \n",
    "    print(f\"✓ Length similarity matrix tính xong\")\n",
    "    return length_matrix\n",
    "\n",
    "def create_weighted_transition_matrix(self, weighted_adjacency, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Tạo ma trận chuyển tiếp từ weighted adjacency matrix\n",
    "    \"\"\"\n",
    "    print(f\"Đang tạo weighted transition matrix với threshold: {threshold}\")\n",
    "    \n",
    "    n = weighted_adjacency.shape[0]\n",
    "    \n",
    "    # Tạo binary adjacency từ weighted matrix\n",
    "    binary_adjacency = (weighted_adjacency > threshold).astype(float)\n",
    "    \n",
    "    # Tạo transition matrix\n",
    "    transition_matrix = np.copy(binary_adjacency)\n",
    "    \n",
    "    # Chuẩn hóa từng hàng\n",
    "    for i in range(n):\n",
    "        row_sum = np.sum(transition_matrix[i])\n",
    "        if row_sum > 0:\n",
    "            transition_matrix[i] = transition_matrix[i] / row_sum\n",
    "        else:\n",
    "            # Không có cạnh ra → phân bố đều\n",
    "            transition_matrix[i] = np.ones(n) / n\n",
    "    \n",
    "    print(f\"✓ Weighted transition matrix: {transition_matrix.shape}\")\n",
    "    \n",
    "    # Thống kê\n",
    "    edge_count = np.sum(binary_adjacency)\n",
    "    density = edge_count / (n * (n - 1))\n",
    "    print(f\"   - Số cạnh: {int(edge_count)}\")\n",
    "    print(f\"   - Mật độ đồ thị: {density:.4f}\")\n",
    "    \n",
    "    return transition_matrix\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.create_weighted_adjacency = create_weighted_adjacency\n",
    "TextSummarizerTFIDFTextRank.calculate_position_similarity = calculate_position_similarity\n",
    "TextSummarizerTFIDFTextRank.calculate_length_similarity = calculate_length_similarity\n",
    "TextSummarizerTFIDFTextRank.create_weighted_transition_matrix = create_weighted_transition_matrix\n",
    "\n",
    "print(\"✓ Đã thêm cải tiến 2: Weighted Graph với Multiple Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8180ed3a",
   "metadata": {},
   "source": [
    "# CẢI TIẾN 3: HIERARCHICAL TEXTRANK\n",
    "\n",
    "**Vấn đề hiện tại:**\n",
    "\n",
    "- Xử lý tất cả câu như nhau\n",
    "- Không phân biệt đoạn văn quan trọng\n",
    "- Computational complexity cao O(N²)\n",
    "\n",
    "**Giải pháp cải tiến:**\n",
    "\n",
    "- Level 1: Ranking paragraph trước\n",
    "- Level 2: Ranking sentence trong top paragraphs\n",
    "- Giảm complexity từ O(N²) xuống O(P² + S²)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e5848d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Đã thêm cải tiến 3: Hierarchical TextRank\n"
     ]
    }
   ],
   "source": [
    "# CẢI TIẾN 3: Hierarchical TextRank\n",
    "def hierarchical_textrank(self, paragraph_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Áp dụng TextRank theo cấp bậc:\n",
    "    1. Ranking paragraph trước\n",
    "    2. Chọn top paragraphs\n",
    "    3. Ranking sentence trong top paragraphs\n",
    "    \"\"\"\n",
    "    print(f\"Đang thực hiện Hierarchical TextRank với {paragraph_ratio*100}% top paragraphs\")\n",
    "    \n",
    "    # Bước 1: Tạo paragraphs từ sentences\n",
    "    paragraphs = self.create_paragraphs()\n",
    "    \n",
    "    # Bước 2: Ranking paragraphs\n",
    "    paragraph_scores = self.textrank_paragraphs(paragraphs)\n",
    "    \n",
    "    # Bước 3: Chọn top paragraphs\n",
    "    top_paragraph_indices = self.select_top_paragraphs(paragraph_scores, paragraph_ratio)\n",
    "    \n",
    "    # Bước 4: Tạo sentence list từ top paragraphs\n",
    "    selected_sentences = self.get_sentences_from_paragraphs(paragraphs, top_paragraph_indices)\n",
    "    \n",
    "    # Bước 5: Ranking sentences trong top paragraphs\n",
    "    sentence_scores = self.textrank_sentences_hierarchical(selected_sentences)\n",
    "    \n",
    "    print(f\"✓ Hierarchical TextRank hoàn thành\")\n",
    "    print(f\"   - Tổng paragraphs: {len(paragraphs)}\")\n",
    "    print(f\"   - Top paragraphs chọn: {len(top_paragraph_indices)}\")\n",
    "    print(f\"   - Sentences trong top paragraphs: {len(selected_sentences)}\")\n",
    "    \n",
    "    return sentence_scores\n",
    "\n",
    "def create_paragraphs(self, sentences_per_paragraph=5):\n",
    "    \"\"\"\n",
    "    Chia sentences thành paragraphs\n",
    "    \"\"\"\n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "    \n",
    "    for i, sent in enumerate(self.sentences):\n",
    "        current_paragraph.append(i)  # Lưu index của sentence\n",
    "        \n",
    "        # Nếu đủ số câu hoặc là câu cuối\n",
    "        if len(current_paragraph) >= sentences_per_paragraph or i == len(self.sentences) - 1:\n",
    "            paragraphs.append(current_paragraph)\n",
    "            current_paragraph = []\n",
    "    \n",
    "    print(f\"✓ Đã tạo {len(paragraphs)} paragraphs\")\n",
    "    return paragraphs\n",
    "\n",
    "def textrank_paragraphs(self, paragraphs):\n",
    "    \"\"\"\n",
    "    Áp dụng TextRank cho paragraphs\n",
    "    \"\"\"\n",
    "    print(\"Đang tính TextRank cho paragraphs...\")\n",
    "    \n",
    "    # Tạo paragraph representations (trung bình TF-IDF của sentences)\n",
    "    paragraph_vectors = []\n",
    "    for para in paragraphs:\n",
    "        # Lấy vector trung bình của các sentences trong paragraph\n",
    "        para_sentences = [self.sentences[i] for i in para]\n",
    "        \n",
    "        if self.tfidf_matrix is not None:\n",
    "            # Trung bình TF-IDF vectors\n",
    "            para_vector = np.mean([self.tfidf_matrix[i] for i in para], axis=0)\n",
    "        else:\n",
    "            # Fallback: tạo vector đơn giản\n",
    "            para_text = \" \".join([sent['processed'] for sent in para_sentences])\n",
    "            para_vector = self.simple_text_to_vector(para_text)\n",
    "        \n",
    "        paragraph_vectors.append(para_vector)\n",
    "    \n",
    "    # Tính similarity matrix cho paragraphs\n",
    "    n_paragraphs = len(paragraphs)\n",
    "    para_similarity = np.zeros((n_paragraphs, n_paragraphs))\n",
    "    \n",
    "    for i in range(n_paragraphs):\n",
    "        for j in range(n_paragraphs):\n",
    "            if i == j:\n",
    "                para_similarity[i, j] = 1.0\n",
    "            else:\n",
    "                sim = self.calculate_cosine_similarity(paragraph_vectors[i], paragraph_vectors[j])\n",
    "                para_similarity[i, j] = sim\n",
    "    \n",
    "    # Tạo transition matrix cho paragraphs\n",
    "    para_adjacency = (para_similarity > 0.1).astype(float)\n",
    "    para_transition = np.copy(para_adjacency)\n",
    "    \n",
    "    for i in range(n_paragraphs):\n",
    "        row_sum = np.sum(para_transition[i])\n",
    "        if row_sum > 0:\n",
    "            para_transition[i] = para_transition[i] / row_sum\n",
    "        else:\n",
    "            para_transition[i] = np.ones(n_paragraphs) / n_paragraphs\n",
    "    \n",
    "    # Chạy TextRank cho paragraphs\n",
    "    para_textrank = np.ones(n_paragraphs) / n_paragraphs\n",
    "    \n",
    "    for iteration in range(50):  # Ít iterations hơn vì ít paragraphs\n",
    "        old_scores = np.copy(para_textrank)\n",
    "        para_textrank = (1 - self.damping_factor) / n_paragraphs + \\\n",
    "                       self.damping_factor * np.dot(para_transition.T, para_textrank)\n",
    "        \n",
    "        change = np.linalg.norm(para_textrank - old_scores)\n",
    "        if change < self.tolerance:\n",
    "            break\n",
    "    \n",
    "    print(f\"✓ Paragraph TextRank hoàn thành sau {iteration + 1} iterations\")\n",
    "    return para_textrank\n",
    "\n",
    "def select_top_paragraphs(self, paragraph_scores, ratio):\n",
    "    \"\"\"\n",
    "    Chọn top paragraphs dựa trên scores\n",
    "    \"\"\"\n",
    "    n_select = max(1, int(len(paragraph_scores) * ratio))\n",
    "    top_indices = np.argsort(paragraph_scores)[-n_select:][::-1]\n",
    "    \n",
    "    print(f\"✓ Chọn {n_select} top paragraphs từ {len(paragraph_scores)} paragraphs\")\n",
    "    return top_indices\n",
    "\n",
    "def get_sentences_from_paragraphs(self, paragraphs, selected_paragraph_indices):\n",
    "    \"\"\"\n",
    "    Lấy tất cả sentences từ các paragraphs được chọn\n",
    "    \"\"\"\n",
    "    selected_sentence_indices = []\n",
    "    for para_idx in selected_paragraph_indices:\n",
    "        selected_sentence_indices.extend(paragraphs[para_idx])\n",
    "    \n",
    "    # Sắp xếp theo thứ tự gốc\n",
    "    selected_sentence_indices.sort()\n",
    "    \n",
    "    print(f\"✓ Đã lấy {len(selected_sentence_indices)} sentences từ top paragraphs\")\n",
    "    return selected_sentence_indices\n",
    "\n",
    "def textrank_sentences_hierarchical(self, selected_sentence_indices):\n",
    "    \"\"\"\n",
    "    Chạy TextRank chỉ trên các sentences được chọn\n",
    "    \"\"\"\n",
    "    print(f\"Đang chạy TextRank cho {len(selected_sentence_indices)} selected sentences...\")\n",
    "    \n",
    "    # Tạo submatrix cho selected sentences\n",
    "    n_selected = len(selected_sentence_indices)\n",
    "    selected_similarity = np.zeros((n_selected, n_selected))\n",
    "    \n",
    "    for i, idx_i in enumerate(selected_sentence_indices):\n",
    "        for j, idx_j in enumerate(selected_sentence_indices):\n",
    "            if self.cosine_matrix is not None:\n",
    "                selected_similarity[i, j] = self.cosine_matrix[idx_i, idx_j]\n",
    "            else:\n",
    "                if i == j:\n",
    "                    selected_similarity[i, j] = 1.0\n",
    "                else:\n",
    "                    sim = self.calculate_cosine_similarity(\n",
    "                        self.tfidf_matrix[idx_i], \n",
    "                        self.tfidf_matrix[idx_j]\n",
    "                    )\n",
    "                    selected_similarity[i, j] = sim\n",
    "    \n",
    "    # Tạo transition matrix\n",
    "    selected_adjacency = (selected_similarity > 0.1).astype(float)\n",
    "    selected_transition = np.copy(selected_adjacency)\n",
    "    \n",
    "    for i in range(n_selected):\n",
    "        row_sum = np.sum(selected_transition[i])\n",
    "        if row_sum > 0:\n",
    "            selected_transition[i] = selected_transition[i] / row_sum\n",
    "        else:\n",
    "            selected_transition[i] = np.ones(n_selected) / n_selected\n",
    "    \n",
    "    # Chạy TextRank\n",
    "    selected_textrank = np.ones(n_selected) / n_selected\n",
    "    \n",
    "    for iteration in range(self.max_iterations):\n",
    "        old_scores = np.copy(selected_textrank)\n",
    "        selected_textrank = (1 - self.damping_factor) / n_selected + \\\n",
    "                          self.damping_factor * np.dot(selected_transition.T, selected_textrank)\n",
    "        \n",
    "        change = np.linalg.norm(selected_textrank - old_scores)\n",
    "        if change < self.tolerance:\n",
    "            break\n",
    "    \n",
    "    # Map scores trở lại toàn bộ sentences\n",
    "    full_scores = np.zeros(len(self.sentences))\n",
    "    for i, sent_idx in enumerate(selected_sentence_indices):\n",
    "        full_scores[sent_idx] = selected_textrank[i]\n",
    "    \n",
    "    print(f\"✓ Hierarchical sentence TextRank hoàn thành\")\n",
    "    return full_scores\n",
    "\n",
    "def simple_text_to_vector(self, text):\n",
    "    \"\"\"\n",
    "    Tạo vector đơn giản từ text (fallback method)\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    if len(self.vocabulary) > 0:\n",
    "        vocab_list = list(self.vocabulary)\n",
    "        vector = np.zeros(len(vocab_list))\n",
    "        word_count = Counter(words)\n",
    "        \n",
    "        for i, word in enumerate(vocab_list):\n",
    "            if word in word_count:\n",
    "                vector[i] = word_count[word] / len(words)\n",
    "        \n",
    "        return vector\n",
    "    else:\n",
    "        # Fallback: return random vector\n",
    "        return np.random.rand(100)\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.hierarchical_textrank = hierarchical_textrank\n",
    "TextSummarizerTFIDFTextRank.create_paragraphs = create_paragraphs\n",
    "TextSummarizerTFIDFTextRank.textrank_paragraphs = textrank_paragraphs\n",
    "TextSummarizerTFIDFTextRank.select_top_paragraphs = select_top_paragraphs\n",
    "TextSummarizerTFIDFTextRank.get_sentences_from_paragraphs = get_sentences_from_paragraphs\n",
    "TextSummarizerTFIDFTextRank.textrank_sentences_hierarchical = textrank_sentences_hierarchical\n",
    "TextSummarizerTFIDFTextRank.simple_text_to_vector = simple_text_to_vector\n",
    "\n",
    "print(\"✓ Đã thêm cải tiến 3: Hierarchical TextRank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afc758",
   "metadata": {},
   "source": [
    "# CẢI TIẾN 4: POST-PROCESSING ĐỂ GIẢM REDUNDANCY\n",
    "\n",
    "**Vấn đề hiện tại:**\n",
    "\n",
    "- TextRank có thể chọn nhiều câu tương tự nhau\n",
    "- Tóm tắt bị lặp lại thông tin\n",
    "- Không có mechanism để đảm bảo diversity\n",
    "\n",
    "**Giải pháp cải tiến:**\n",
    "\n",
    "- Loại bỏ câu redundant dựa trên similarity threshold\n",
    "- Maximum Marginal Relevance (MMR) để balance relevance và diversity\n",
    "- Đảm bảo tóm tắt có thông tin đa dạng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "493c182e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Đã thêm cải tiến 4: Post-processing để giảm Redundancy\n"
     ]
    }
   ],
   "source": [
    "# CẢI TIẾN 4: Post-processing để giảm Redundancy\n",
    "def remove_redundant_sentences(self, selected_sentences, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Loại bỏ câu redundant dựa trên similarity threshold\n",
    "    \"\"\"\n",
    "    print(f\"Đang loại bỏ câu redundant với threshold: {threshold}\")\n",
    "    \n",
    "    final_sentences = []\n",
    "    removed_count = 0\n",
    "    \n",
    "    for sent in selected_sentences:\n",
    "        is_redundant = False\n",
    "        sent_idx = sent['index']\n",
    "        \n",
    "        # Kiểm tra với từng câu đã chọn\n",
    "        for final_sent in final_sentences:\n",
    "            final_idx = final_sent['index']\n",
    "            \n",
    "            # Tính similarity\n",
    "            if self.cosine_matrix is not None:\n",
    "                similarity = self.cosine_matrix[sent_idx, final_idx]\n",
    "            else:\n",
    "                # Fallback: tính trực tiếp\n",
    "                if self.tfidf_matrix is not None:\n",
    "                    similarity = self.calculate_cosine_similarity(\n",
    "                        self.tfidf_matrix[sent_idx], \n",
    "                        self.tfidf_matrix[final_idx]\n",
    "                    )\n",
    "                else:\n",
    "                    similarity = 0.0\n",
    "            \n",
    "            # Nếu quá giống thì loại bỏ\n",
    "            if similarity > threshold:\n",
    "                is_redundant = True\n",
    "                removed_count += 1\n",
    "                print(f\"   Loại bỏ câu {sent_idx} (similarity {similarity:.3f} với câu {final_idx})\")\n",
    "                break\n",
    "        \n",
    "        # Chỉ thêm câu không redundant\n",
    "        if not is_redundant:\n",
    "            final_sentences.append(sent)\n",
    "    \n",
    "    print(f\"✓ Đã loại bỏ {removed_count} câu redundant\")\n",
    "    print(f\"✓ Còn lại {len(final_sentences)} câu unique\")\n",
    "    \n",
    "    return final_sentences\n",
    "\n",
    "def mmr_selection(self, candidates, num_select, lambda_param=0.7):\n",
    "    \"\"\"\n",
    "    Maximum Marginal Relevance selection\n",
    "    Balance giữa relevance (TextRank score) và diversity (khác biệt với câu đã chọn)\n",
    "    \"\"\"\n",
    "    print(f\"Đang áp dụng MMR selection để chọn {num_select} câu\")\n",
    "    print(f\"Lambda parameter: {lambda_param} (relevance vs diversity)\")\n",
    "    \n",
    "    if len(candidates) <= num_select:\n",
    "        return candidates\n",
    "    \n",
    "    selected = []\n",
    "    remaining = candidates.copy()\n",
    "    \n",
    "    # Chọn câu đầu tiên có score cao nhất\n",
    "    best_idx = np.argmax([c['score'] for c in remaining])\n",
    "    selected.append(remaining.pop(best_idx))\n",
    "    print(f\"   Chọn câu đầu tiên: {selected[0]['index']} (score: {selected[0]['score']:.4f})\")\n",
    "    \n",
    "    # Chọn các câu tiếp theo bằng MMR\n",
    "    for step in range(num_select - 1):\n",
    "        if not remaining:\n",
    "            break\n",
    "        \n",
    "        mmr_scores = []\n",
    "        \n",
    "        for candidate in remaining:\n",
    "            # Relevance = TextRank score (đã chuẩn hóa)\n",
    "            relevance = candidate['score']\n",
    "            \n",
    "            # Tính max similarity với câu đã chọn\n",
    "            max_similarity = 0\n",
    "            cand_idx = candidate['index']\n",
    "            \n",
    "            for sel in selected:\n",
    "                sel_idx = sel['index']\n",
    "                \n",
    "                if self.cosine_matrix is not None:\n",
    "                    sim = self.cosine_matrix[cand_idx, sel_idx]\n",
    "                else:\n",
    "                    # Fallback calculation\n",
    "                    if self.tfidf_matrix is not None:\n",
    "                        sim = self.calculate_cosine_similarity(\n",
    "                            self.tfidf_matrix[cand_idx], \n",
    "                            self.tfidf_matrix[sel_idx]\n",
    "                        )\n",
    "                    else:\n",
    "                        sim = 0.0\n",
    "                \n",
    "                max_similarity = max(max_similarity, sim)\n",
    "            \n",
    "            # MMR score = λ * relevance - (1-λ) * max_similarity\n",
    "            mmr_score = lambda_param * relevance - (1 - lambda_param) * max_similarity\n",
    "            mmr_scores.append(mmr_score)\n",
    "        \n",
    "        # Chọn câu có MMR score cao nhất\n",
    "        best_mmr_idx = np.argmax(mmr_scores)\n",
    "        chosen = remaining.pop(best_mmr_idx)\n",
    "        selected.append(chosen)\n",
    "        \n",
    "        print(f\"   Bước {step+2}: Chọn câu {chosen['index']} \"\n",
    "              f\"(relevance: {chosen['score']:.3f}, MMR: {mmr_scores[best_mmr_idx]:.3f})\")\n",
    "    \n",
    "    print(f\"✓ MMR selection hoàn thành, chọn được {len(selected)} câu\")\n",
    "    return selected\n",
    "\n",
    "def generate_summary_with_redundancy_removal(self, summary_ratio=0.1, redundancy_threshold=0.7, use_mmr=True, lambda_param=0.7):\n",
    "    \"\"\"\n",
    "    Tạo tóm tắt với post-processing để giảm redundancy\n",
    "    \"\"\"\n",
    "    print(f\"Đang tạo tóm tắt cải tiến với:\")\n",
    "    print(f\"   - Summary ratio: {summary_ratio*100}%\")\n",
    "    print(f\"   - Redundancy threshold: {redundancy_threshold}\")\n",
    "    print(f\"   - Use MMR: {use_mmr}\")\n",
    "    if use_mmr:\n",
    "        print(f\"   - Lambda parameter: {lambda_param}\")\n",
    "    \n",
    "    if self.textrank_scores is None:\n",
    "        print(\"Chưa tính TextRank\")\n",
    "        return None\n",
    "    \n",
    "    total_sentences = len(self.sentences)\n",
    "    target_num_sentences = max(1, int(total_sentences * summary_ratio))\n",
    "    \n",
    "    # Tạo danh sách candidates\n",
    "    candidates = []\n",
    "    for i, score in enumerate(self.textrank_scores):\n",
    "        candidates.append({\n",
    "            'index': i,\n",
    "            'score': score,\n",
    "            'sentence': self.sentences[i]['original']\n",
    "        })\n",
    "    \n",
    "    # Sắp xếp theo điểm TextRank giảm dần\n",
    "    candidates.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    if use_mmr:\n",
    "        # Sử dụng MMR selection\n",
    "        selected_sentences = self.mmr_selection(candidates, target_num_sentences * 2, lambda_param)\n",
    "        \n",
    "        # Sau đó remove redundancy\n",
    "        selected_sentences = self.remove_redundant_sentences(selected_sentences, redundancy_threshold)\n",
    "        \n",
    "        # Nếu còn quá nhiều, cắt bớt\n",
    "        if len(selected_sentences) > target_num_sentences:\n",
    "            selected_sentences = selected_sentences[:target_num_sentences]\n",
    "    else:\n",
    "        # Chỉ remove redundancy đơn giản\n",
    "        # Lấy nhiều câu hơn trước, sau đó remove redundancy\n",
    "        initial_candidates = candidates[:target_num_sentences * 3]\n",
    "        selected_sentences = self.remove_redundant_sentences(initial_candidates, redundancy_threshold)\n",
    "        \n",
    "        # Cắt về số lượng mong muốn\n",
    "        if len(selected_sentences) > target_num_sentences:\n",
    "            selected_sentences = selected_sentences[:target_num_sentences]\n",
    "    \n",
    "    # Sắp xếp lại theo thứ tự xuất hiện trong văn bản gốc\n",
    "    selected_sentences.sort(key=lambda x: x['index'])\n",
    "    \n",
    "    # Tạo văn bản tóm tắt\n",
    "    summary_text = ' '.join([item['sentence'] for item in selected_sentences])\n",
    "    \n",
    "    summary = {\n",
    "        'sentences': selected_sentences,\n",
    "        'text': summary_text,\n",
    "        'ratio': summary_ratio,\n",
    "        'original_count': total_sentences,\n",
    "        'summary_count': len(selected_sentences),\n",
    "        'method': 'MMR + Redundancy Removal' if use_mmr else 'Redundancy Removal',\n",
    "        'parameters': {\n",
    "            'redundancy_threshold': redundancy_threshold,\n",
    "            'use_mmr': use_mmr,\n",
    "            'lambda_param': lambda_param if use_mmr else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"✓ Tóm tắt cải tiến hoàn thành: {len(selected_sentences)}/{total_sentences} câu\")\n",
    "    return summary\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.remove_redundant_sentences = remove_redundant_sentences\n",
    "TextSummarizerTFIDFTextRank.mmr_selection = mmr_selection\n",
    "TextSummarizerTFIDFTextRank.generate_summary_with_redundancy_removal = generate_summary_with_redundancy_removal\n",
    "\n",
    "print(\"✓ Đã thêm cải tiến 4: Post-processing để giảm Redundancy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ee2df2",
   "metadata": {},
   "source": [
    "# CẢI TIẾN 5: ADAPTIVE SUMMARY LENGTH\n",
    "\n",
    "**Vấn đề hiện tại:**\n",
    "\n",
    "- Fix cứng 10% số câu cho mọi văn bản\n",
    "- Không phù hợp với độ phức tạp khác nhau\n",
    "- Văn bản phức tạp cần tóm tắt dài hơn\n",
    "\n",
    "**Giải pháp cải tiến:**\n",
    "\n",
    "- Tính độ phức tạp văn bản dựa trên nhiều yếu tố\n",
    "- Tự động điều chỉnh tỷ lệ tóm tắt theo complexity\n",
    "- Văn bản đơn giản → tóm tắt ngắn, phức tạp → tóm tắt dài\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8ce06e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Đã thêm cải tiến 5: Adaptive Summary Length\n"
     ]
    }
   ],
   "source": [
    "# CẢI TIẾN 5: Adaptive Summary Length\n",
    "def calculate_text_complexity(self):\n",
    "    \"\"\"\n",
    "    Tính độ phức tạp văn bản dựa trên nhiều yếu tố\n",
    "    \"\"\"\n",
    "    print(\"Đang tính độ phức tạp văn bản...\")\n",
    "    \n",
    "    if not self.sentences:\n",
    "        return 0.5\n",
    "    \n",
    "    # 1. Độ dài câu trung bình\n",
    "    sentence_lengths = [len(sent['processed'].split()) for sent in self.sentences]\n",
    "    avg_sentence_length = np.mean(sentence_lengths)\n",
    "    std_sentence_length = np.std(sentence_lengths)\n",
    "    \n",
    "    # Chuẩn hóa độ dài câu (câu dài thường phức tạp hơn)\n",
    "    length_complexity = min(avg_sentence_length / 20.0, 1.0)\n",
    "    \n",
    "    # 2. Độ đa dạng từ vựng (Vocabulary Diversity)\n",
    "    all_words = []\n",
    "    for sent in self.sentences:\n",
    "        all_words.extend(sent['processed'].split())\n",
    "    \n",
    "    unique_words = len(set(all_words))\n",
    "    total_words = len(all_words)\n",
    "    vocab_diversity = unique_words / total_words if total_words > 0 else 0\n",
    "    \n",
    "    # 3. Mật độ đồ thị (Graph Density)\n",
    "    if self.adjacency_matrix is not None:\n",
    "        n = len(self.sentences)\n",
    "        total_possible_edges = n * (n - 1)\n",
    "        actual_edges = np.sum(self.adjacency_matrix)\n",
    "        graph_density = actual_edges / total_possible_edges if total_possible_edges > 0 else 0\n",
    "    else:\n",
    "        graph_density = 0.5  # Default value\n",
    "    \n",
    "    # 4. Phân tán độ dài câu (Sentence Length Variation)\n",
    "    length_variation = std_sentence_length / avg_sentence_length if avg_sentence_length > 0 else 0\n",
    "    length_variation = min(length_variation, 1.0)\n",
    "    \n",
    "    # 5. Số lượng câu (Document Length Factor)\n",
    "    num_sentences = len(self.sentences)\n",
    "    length_factor = min(num_sentences / 50.0, 1.0)  # Normalize to 50 sentences\n",
    "    \n",
    "    # Kết hợp các yếu tố với trọng số\n",
    "    complexity = (0.25 * length_complexity +\n",
    "                  0.25 * vocab_diversity +\n",
    "                  0.20 * graph_density +\n",
    "                  0.15 * length_variation +\n",
    "                  0.15 * length_factor)\n",
    "    \n",
    "    complexity = min(complexity, 1.0)  # Clamp to [0, 1]\n",
    "    \n",
    "    print(f\"✓ Phân tích độ phức tạp:\")\n",
    "    print(f\"   - Độ dài câu TB: {avg_sentence_length:.1f} từ → {length_complexity:.3f}\")\n",
    "    print(f\"   - Đa dạng từ vựng: {vocab_diversity:.3f}\")\n",
    "    print(f\"   - Mật độ đồ thị: {graph_density:.3f}\")\n",
    "    print(f\"   - Phân tán độ dài: {length_variation:.3f}\")\n",
    "    print(f\"   - Yếu tố độ dài: {length_factor:.3f}\")\n",
    "    print(f\"   - Độ phức tạp tổng: {complexity:.3f}\")\n",
    "    \n",
    "    return complexity\n",
    "\n",
    "def adaptive_summary_length(self, base_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Tự động điều chỉnh độ dài tóm tắt dựa trên độ phức tạp văn bản\n",
    "    \"\"\"\n",
    "    complexity = self.calculate_text_complexity()\n",
    "    \n",
    "    # Điều chỉnh tỷ lệ dựa trên complexity\n",
    "    if complexity > 0.8:\n",
    "        ratio = base_ratio * 1.5  # 15% cho văn bản rất phức tạp\n",
    "        complexity_level = \"Rất phức tạp\"\n",
    "    elif complexity > 0.6:\n",
    "        ratio = base_ratio * 1.3  # 13% cho văn bản phức tạp\n",
    "        complexity_level = \"Phức tạp\"\n",
    "    elif complexity > 0.4:\n",
    "        ratio = base_ratio * 1.1  # 11% cho văn bản trung bình khá\n",
    "        complexity_level = \"Trung bình khá\"\n",
    "    elif complexity > 0.2:\n",
    "        ratio = base_ratio * 1.0  # 10% cho văn bản trung bình\n",
    "        complexity_level = \"Trung bình\"\n",
    "    else:\n",
    "        ratio = base_ratio * 0.8  # 8% cho văn bản đơn giản\n",
    "        complexity_level = \"Đơn giản\"\n",
    "    \n",
    "    # Đảm bảo ratio hợp lý\n",
    "    ratio = max(0.05, min(ratio, 0.25))  # Between 5% and 25%\n",
    "    \n",
    "    print(f\"✓ Adaptive Summary Length:\")\n",
    "    print(f\"   - Độ phức tạp: {complexity:.3f} ({complexity_level})\")\n",
    "    print(f\"   - Tỷ lệ tóm tắt gốc: {base_ratio*100:.1f}%\")\n",
    "    print(f\"   - Tỷ lệ tóm tắt điều chỉnh: {ratio*100:.1f}%\")\n",
    "    print(f\"   - Số câu sẽ chọn: {max(1, int(len(self.sentences) * ratio))}\")\n",
    "    \n",
    "    return ratio\n",
    "\n",
    "def generate_adaptive_summary(self, base_ratio=0.1, use_redundancy_removal=True, use_mmr=True):\n",
    "    \"\"\"\n",
    "    Tạo tóm tắt với adaptive length và các cải tiến khác\n",
    "    \"\"\"\n",
    "    print(\"Đang tạo tóm tắt adaptive với tất cả cải tiến...\")\n",
    "    \n",
    "    # Bước 1: Tính adaptive ratio\n",
    "    adaptive_ratio = self.adaptive_summary_length(base_ratio)\n",
    "    \n",
    "    # Bước 2: Tạo tóm tắt với ratio điều chỉnh\n",
    "    if use_redundancy_removal:\n",
    "        summary = self.generate_summary_with_redundancy_removal(\n",
    "            summary_ratio=adaptive_ratio,\n",
    "            redundancy_threshold=0.7,\n",
    "            use_mmr=use_mmr,\n",
    "            lambda_param=0.7\n",
    "        )\n",
    "    else:\n",
    "        summary = self.generate_summary(summary_ratio=adaptive_ratio)\n",
    "    \n",
    "    if summary:\n",
    "        summary['adaptive_ratio'] = adaptive_ratio\n",
    "        summary['complexity'] = self.calculate_text_complexity()\n",
    "        summary['method'] = 'Adaptive Length + ' + summary.get('method', 'Basic TextRank')\n",
    "    \n",
    "    print(f\"✓ Adaptive summary hoàn thành\")\n",
    "    return summary\n",
    "\n",
    "def compare_summary_methods(self):\n",
    "    \"\"\"\n",
    "    So sánh các phương pháp tóm tắt khác nhau\n",
    "    \"\"\"\n",
    "    print(\"So sánh các phương pháp tóm tắt...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    methods = {}\n",
    "    \n",
    "    # 1. Baseline method\n",
    "    if self.textrank_scores is not None:\n",
    "        baseline_summary = self.generate_summary(summary_ratio=0.1)\n",
    "        methods['Baseline (10%)'] = baseline_summary\n",
    "    \n",
    "    # 2. Adaptive length\n",
    "    adaptive_summary = self.generate_adaptive_summary(\n",
    "        base_ratio=0.1, \n",
    "        use_redundancy_removal=False, \n",
    "        use_mmr=False\n",
    "    )\n",
    "    methods['Adaptive Length'] = adaptive_summary\n",
    "    \n",
    "    # 3. Redundancy removal\n",
    "    redundancy_summary = self.generate_summary_with_redundancy_removal(\n",
    "        summary_ratio=0.1,\n",
    "        use_mmr=False\n",
    "    )\n",
    "    methods['Redundancy Removal'] = redundancy_summary\n",
    "    \n",
    "    # 4. MMR + Redundancy\n",
    "    mmr_summary = self.generate_summary_with_redundancy_removal(\n",
    "        summary_ratio=0.1,\n",
    "        use_mmr=True\n",
    "    )\n",
    "    methods['MMR + Redundancy'] = mmr_summary\n",
    "    \n",
    "    # 5. Adaptive + MMR + Redundancy (Full pipeline)\n",
    "    full_summary = self.generate_adaptive_summary(\n",
    "        base_ratio=0.1,\n",
    "        use_redundancy_removal=True,\n",
    "        use_mmr=True\n",
    "    )\n",
    "    methods['Full Pipeline'] = full_summary\n",
    "    \n",
    "    # Hiển thị so sánh\n",
    "    print(f\"{'Phương pháp':<20} {'Số câu':<8} {'Tỷ lệ':<8} {'Độ dài':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for method_name, summary in methods.items():\n",
    "        if summary:\n",
    "            count = summary['summary_count']\n",
    "            ratio = f\"{summary['ratio']*100:.1f}%\"\n",
    "            length = len(summary['text'])\n",
    "            print(f\"{method_name:<20} {count:<8} {ratio:<8} {length:<10}\")\n",
    "        else:\n",
    "            print(f\"{method_name:<20} {'N/A':<8} {'N/A':<8} {'N/A':<10}\")\n",
    "    \n",
    "    return methods\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.calculate_text_complexity = calculate_text_complexity\n",
    "TextSummarizerTFIDFTextRank.adaptive_summary_length = adaptive_summary_length\n",
    "TextSummarizerTFIDFTextRank.generate_adaptive_summary = generate_adaptive_summary\n",
    "TextSummarizerTFIDFTextRank.compare_summary_methods = compare_summary_methods\n",
    "\n",
    "print(\"✓ Đã thêm cải tiến 5: Adaptive Summary Length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8514c7f",
   "metadata": {},
   "source": [
    "# CẢI TIẾN 6: MULTI-CRITERIA OPTIMIZATION\n",
    "\n",
    "**Vấn đề hiện tại:**\n",
    "\n",
    "- Chỉ tối ưu theo TextRank score\n",
    "- Không xét đến diversity và coverage\n",
    "- Bỏ qua vị trí quan trọng trong văn bản\n",
    "\n",
    "**Giải pháp cải tiến:**\n",
    "\n",
    "- Kết hợp nhiều criteria: importance, diversity, coverage, position\n",
    "- Weighted combination để tối ưu đa mục tiêu\n",
    "- Đảm bảo tóm tắt bao phủ toàn diện và đa dạng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da5901df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Đã thêm cải tiến 6: Multi-criteria Optimization\n"
     ]
    }
   ],
   "source": [
    "# CẢI TIẾN 6: Multi-criteria Optimization\n",
    "def multi_criteria_textrank(self, importance_weight=0.4, diversity_weight=0.25, \n",
    "                           coverage_weight=0.25, position_weight=0.1):\n",
    "    \"\"\"\n",
    "    Tính TextRank với nhiều criteria khác nhau\n",
    "    \"\"\"\n",
    "    print(\"Đang tính Multi-criteria TextRank...\")\n",
    "    print(f\"Trọng số: importance={importance_weight}, diversity={diversity_weight}, \"\n",
    "          f\"coverage={coverage_weight}, position={position_weight}\")\n",
    "    \n",
    "    if self.textrank_scores is None:\n",
    "        print(\"Chưa có TextRank scores, tính toán...\")\n",
    "        self.calculate_textrank()\n",
    "    \n",
    "    # 1. Importance score (từ TextRank)\n",
    "    importance_scores = self.textrank_scores.copy()\n",
    "    importance_scores = importance_scores / np.max(importance_scores)  # Normalize to [0,1]\n",
    "    \n",
    "    # 2. Diversity score\n",
    "    diversity_scores = self.calculate_diversity_scores()\n",
    "    \n",
    "    # 3. Coverage score\n",
    "    coverage_scores = self.calculate_coverage_scores()\n",
    "    \n",
    "    # 4. Position score\n",
    "    position_scores = self.calculate_position_bias()\n",
    "    \n",
    "    # Weighted combination\n",
    "    final_scores = (importance_weight * importance_scores +\n",
    "                   diversity_weight * diversity_scores +\n",
    "                   coverage_weight * coverage_scores +\n",
    "                   position_weight * position_scores)\n",
    "    \n",
    "    print(f\"✓ Multi-criteria scores tính xong\")\n",
    "    print(f\"   - Importance TB: {np.mean(importance_scores):.3f}\")\n",
    "    print(f\"   - Diversity TB: {np.mean(diversity_scores):.3f}\")\n",
    "    print(f\"   - Coverage TB: {np.mean(coverage_scores):.3f}\")\n",
    "    print(f\"   - Position TB: {np.mean(position_scores):.3f}\")\n",
    "    print(f\"   - Final scores TB: {np.mean(final_scores):.3f}\")\n",
    "    \n",
    "    return final_scores\n",
    "\n",
    "def calculate_diversity_scores(self):\n",
    "    \"\"\"\n",
    "    Đo độ khác biệt của mỗi câu so với tập câu khác\n",
    "    \"\"\"\n",
    "    print(\"Tính diversity scores...\")\n",
    "    \n",
    "    n = len(self.sentences)\n",
    "    diversity_scores = np.zeros(n)\n",
    "    \n",
    "    if self.cosine_matrix is not None:\n",
    "        cosine_matrix = self.cosine_matrix\n",
    "    else:\n",
    "        print(\"Chưa có cosine matrix, tính toán...\")\n",
    "        cosine_matrix = self.build_cosine_matrix()\n",
    "    \n",
    "    for i in range(n):\n",
    "        total_distance = 0\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                # Distance = 1 - similarity (càng khác biệt càng cao điểm)\n",
    "                distance = 1 - cosine_matrix[i, j]\n",
    "                total_distance += distance\n",
    "        \n",
    "        # Điểm diversity = khoảng cách trung bình\n",
    "        diversity_scores[i] = total_distance / (n - 1) if n > 1 else 0\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    if np.max(diversity_scores) > 0:\n",
    "        diversity_scores = diversity_scores / np.max(diversity_scores)\n",
    "    \n",
    "    print(f\"✓ Diversity scores: min={np.min(diversity_scores):.3f}, max={np.max(diversity_scores):.3f}\")\n",
    "    return diversity_scores\n",
    "\n",
    "def calculate_coverage_scores(self):\n",
    "    \"\"\"\n",
    "    Đo khả năng câu đại diện cho nhiều topic/cluster\n",
    "    \"\"\"\n",
    "    print(\"Tính coverage scores...\")\n",
    "    \n",
    "    # Tạo topic clusters từ similarity matrix\n",
    "    clusters = self.create_topic_clusters()\n",
    "    \n",
    "    n = len(self.sentences)\n",
    "    coverage_scores = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        coverage = 0\n",
    "        \n",
    "        # Đếm số cluster mà câu này thuộc về hoặc gần với\n",
    "        for cluster_id, cluster in enumerate(clusters):\n",
    "            if i in cluster:\n",
    "                # Câu thuộc cluster này\n",
    "                cluster_centrality = self.calculate_centrality_in_cluster(i, cluster)\n",
    "                coverage += cluster_centrality\n",
    "            else:\n",
    "                # Tính khoảng cách đến cluster\n",
    "                cluster_distance = self.calculate_distance_to_cluster(i, cluster)\n",
    "                if cluster_distance > 0.5:  # Nếu gần cluster\n",
    "                    coverage += cluster_distance * 0.5\n",
    "        \n",
    "        coverage_scores[i] = coverage\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    if np.max(coverage_scores) > 0:\n",
    "        coverage_scores = coverage_scores / np.max(coverage_scores)\n",
    "    \n",
    "    print(f\"✓ Coverage scores: min={np.min(coverage_scores):.3f}, max={np.max(coverage_scores):.3f}\")\n",
    "    return coverage_scores\n",
    "\n",
    "def create_topic_clusters(self, n_clusters=5):\n",
    "    \"\"\"\n",
    "    Tạo topic clusters từ similarity matrix bằng simple clustering\n",
    "    \"\"\"\n",
    "    n = len(self.sentences)\n",
    "    \n",
    "    if n <= n_clusters:\n",
    "        # Mỗi câu là một cluster\n",
    "        return [[i] for i in range(n)]\n",
    "    \n",
    "    # Simple clustering based on similarity\n",
    "    clusters = []\n",
    "    assigned = [False] * n\n",
    "    \n",
    "    for _ in range(n_clusters):\n",
    "        if all(assigned):\n",
    "            break\n",
    "        \n",
    "        # Tìm câu chưa assign có điểm TextRank cao nhất\n",
    "        best_seed = -1\n",
    "        best_score = -1\n",
    "        for i in range(n):\n",
    "            if not assigned[i] and self.textrank_scores[i] > best_score:\n",
    "                best_score = self.textrank_scores[i]\n",
    "                best_seed = i\n",
    "        \n",
    "        if best_seed == -1:\n",
    "            break\n",
    "        \n",
    "        # Tạo cluster mới với seed này\n",
    "        cluster = [best_seed]\n",
    "        assigned[best_seed] = True\n",
    "        \n",
    "        # Thêm các câu tương tự vào cluster\n",
    "        for i in range(n):\n",
    "            if not assigned[i] and self.cosine_matrix[best_seed, i] > 0.3:\n",
    "                cluster.append(i)\n",
    "                assigned[i] = True\n",
    "        \n",
    "        clusters.append(cluster)\n",
    "    \n",
    "    # Assign các câu còn lại vào cluster gần nhất\n",
    "    for i in range(n):\n",
    "        if not assigned[i]:\n",
    "            best_cluster = 0\n",
    "            best_similarity = -1\n",
    "            \n",
    "            for cluster_id, cluster in enumerate(clusters):\n",
    "                # Tính similarity trung bình với cluster\n",
    "                avg_similarity = np.mean([self.cosine_matrix[i, j] for j in cluster])\n",
    "                if avg_similarity > best_similarity:\n",
    "                    best_similarity = avg_similarity\n",
    "                    best_cluster = cluster_id\n",
    "            \n",
    "            clusters[best_cluster].append(i)\n",
    "    \n",
    "    print(f\"✓ Tạo {len(clusters)} topic clusters\")\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        print(f\"   Cluster {i}: {len(cluster)} câu\")\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "def calculate_centrality_in_cluster(self, sentence_idx, cluster):\n",
    "    \"\"\"\n",
    "    Tính centrality của câu trong cluster\n",
    "    \"\"\"\n",
    "    if len(cluster) <= 1:\n",
    "        return 1.0\n",
    "    \n",
    "    total_similarity = 0\n",
    "    for other_idx in cluster:\n",
    "        if other_idx != sentence_idx:\n",
    "            total_similarity += self.cosine_matrix[sentence_idx, other_idx]\n",
    "    \n",
    "    centrality = total_similarity / (len(cluster) - 1)\n",
    "    return centrality\n",
    "\n",
    "def calculate_distance_to_cluster(self, sentence_idx, cluster):\n",
    "    \"\"\"\n",
    "    Tính khoảng cách (similarity) từ câu đến cluster\n",
    "    \"\"\"\n",
    "    if not cluster:\n",
    "        return 0\n",
    "    \n",
    "    avg_similarity = np.mean([self.cosine_matrix[sentence_idx, j] for j in cluster])\n",
    "    return avg_similarity\n",
    "\n",
    "def calculate_position_bias(self):\n",
    "    \"\"\"\n",
    "    Tính position bias - câu đầu và cuối thường quan trọng hơn\n",
    "    \"\"\"\n",
    "    n = len(self.sentences)\n",
    "    position_scores = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        if n <= 10:\n",
    "            # Văn bản ngắn: câu đầu và cuối đều quan trọng\n",
    "            if i < 2 or i >= n - 2:\n",
    "                position_scores[i] = 1.0\n",
    "            else:\n",
    "                position_scores[i] = 0.5\n",
    "        else:\n",
    "            # Văn bản dài: gradient từ đầu và cuối\n",
    "            if i < n * 0.1:  # 10% câu đầu\n",
    "                position_scores[i] = 1.0\n",
    "            elif i >= n * 0.9:  # 10% câu cuối\n",
    "                position_scores[i] = 0.8\n",
    "            elif i < n * 0.2:  # 20% câu đầu\n",
    "                position_scores[i] = 0.7\n",
    "            elif i >= n * 0.8:  # 20% câu cuối\n",
    "                position_scores[i] = 0.6\n",
    "            else:  # Câu giữa\n",
    "                position_scores[i] = 0.3\n",
    "    \n",
    "    print(f\"✓ Position bias: {np.sum(position_scores > 0.5)} câu có position bias cao\")\n",
    "    return position_scores\n",
    "\n",
    "def generate_multi_criteria_summary(self, summary_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Tạo tóm tắt sử dụng multi-criteria optimization\n",
    "    \"\"\"\n",
    "    print(\"Đang tạo tóm tắt Multi-criteria...\")\n",
    "    \n",
    "    # Tính multi-criteria scores\n",
    "    multi_scores = self.multi_criteria_textrank()\n",
    "    \n",
    "    # Tạo danh sách candidates\n",
    "    candidates = []\n",
    "    for i, score in enumerate(multi_scores):\n",
    "        candidates.append({\n",
    "            'index': i,\n",
    "            'score': score,\n",
    "            'sentence': self.sentences[i]['original'],\n",
    "            'importance': self.textrank_scores[i] if self.textrank_scores is not None else 0,\n",
    "            'multi_criteria': score\n",
    "        })\n",
    "    \n",
    "    # Sắp xếp theo multi-criteria score\n",
    "    candidates.sort(key=lambda x: x['multi_criteria'], reverse=True)\n",
    "    \n",
    "    # Chọn top sentences\n",
    "    num_select = max(1, int(len(self.sentences) * summary_ratio))\n",
    "    selected_sentences = candidates[:num_select]\n",
    "    \n",
    "    # Sắp xếp lại theo thứ tự xuất hiện\n",
    "    selected_sentences.sort(key=lambda x: x['index'])\n",
    "    \n",
    "    # Tạo văn bản tóm tắt\n",
    "    summary_text = ' '.join([item['sentence'] for item in selected_sentences])\n",
    "    \n",
    "    summary = {\n",
    "        'sentences': selected_sentences,\n",
    "        'text': summary_text,\n",
    "        'ratio': summary_ratio,\n",
    "        'original_count': len(self.sentences),\n",
    "        'summary_count': len(selected_sentences),\n",
    "        'method': 'Multi-criteria Optimization',\n",
    "        'multi_criteria_scores': multi_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"✓ Multi-criteria summary hoàn thành: {len(selected_sentences)} câu\")\n",
    "    \n",
    "    # Hiển thị top 5 câu với scores\n",
    "    print(\"\\nTop 5 câu theo multi-criteria:\")\n",
    "    for i, sent in enumerate(candidates[:5], 1):\n",
    "        preview = sent['sentence'][:60]\n",
    "        print(f\"{i}. [{sent['index']}] Score: {sent['multi_criteria']:.3f} - '{preview}...'\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.multi_criteria_textrank = multi_criteria_textrank\n",
    "TextSummarizerTFIDFTextRank.calculate_diversity_scores = calculate_diversity_scores\n",
    "TextSummarizerTFIDFTextRank.calculate_coverage_scores = calculate_coverage_scores\n",
    "TextSummarizerTFIDFTextRank.create_topic_clusters = create_topic_clusters\n",
    "TextSummarizerTFIDFTextRank.calculate_centrality_in_cluster = calculate_centrality_in_cluster\n",
    "TextSummarizerTFIDFTextRank.calculate_distance_to_cluster = calculate_distance_to_cluster\n",
    "TextSummarizerTFIDFTextRank.calculate_position_bias = calculate_position_bias\n",
    "TextSummarizerTFIDFTextRank.generate_multi_criteria_summary = generate_multi_criteria_summary\n",
    "\n",
    "print(\"✓ Đã thêm cải tiến 6: Multi-criteria Optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b1f2b4",
   "metadata": {},
   "source": [
    "# DEMO VÀ ĐÁNH GIÁ CÁC CẢI TIẾN\n",
    "\n",
    "**Phần này sẽ demo và so sánh tất cả các phương pháp cải tiến:**\n",
    "\n",
    "1. **Baseline TextRank** (phương pháp gốc)\n",
    "2. **Semantic Similarity** (thay TF-IDF)\n",
    "3. **Weighted Graph** (multiple features)\n",
    "4. **Hierarchical TextRank** (2-level processing)\n",
    "5. **Redundancy Removal** (MMR selection)\n",
    "6. **Adaptive Length** (dynamic ratio)\n",
    "7. **Multi-criteria** (importance + diversity + coverage + position)\n",
    "8. **Full Pipeline** (kết hợp tất cả cải tiến)\n",
    "\n",
    "**Metrics đánh giá:**\n",
    "\n",
    "- ROUGE scores (1, 2, L)\n",
    "- Execution time\n",
    "- Summary quality analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5bb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BẮT ĐẦU ĐÁNH GIÁ TOÀN DIỆN CÁC PHƯƠNG PHÁP CẢI TIẾN\n",
      "================================================================================\n",
      "Chưa có DUC reference. Sẽ chỉ đánh giá về mặt kỹ thuật.\n",
      "\n",
      "1. BASELINE TEXTRANK (Phương pháp gốc)\n",
      "--------------------------------------------------\n",
      "Đang tạo bản tóm tắt với tỷ lệ 10.0%...\n",
      "Chọn 16 câu từ 160 câu gốc\n",
      "✓ Hoàn thành: 16 câu, 0.00s\n",
      "  Preview: In December, seven former Politburo members were arrested, and Honecker was placed under house arres...\n",
      "\n",
      "2. ADAPTIVE SUMMARY LENGTH\n",
      "--------------------------------------------------\n",
      "Đang tạo tóm tắt adaptive với tất cả cải tiến...\n",
      "Đang tính độ phức tạp văn bản...\n",
      "✓ Phân tích độ phức tạp:\n",
      "   - Độ dài câu TB: 19.6 từ → 0.978\n",
      "   - Đa dạng từ vựng: 0.298\n",
      "   - Mật độ đồ thị: 0.046\n",
      "   - Phân tán độ dài: 0.414\n",
      "   - Yếu tố độ dài: 1.000\n",
      "   - Độ phức tạp tổng: 0.540\n",
      "✓ Adaptive Summary Length:\n",
      "   - Độ phức tạp: 0.540 (Trung bình khá)\n",
      "   - Tỷ lệ tóm tắt gốc: 10.0%\n",
      "   - Tỷ lệ tóm tắt điều chỉnh: 11.0%\n",
      "   - Số câu sẽ chọn: 17\n",
      "Đang tạo bản tóm tắt với tỷ lệ 11.000000000000002%...\n",
      "Chọn 17 câu từ 160 câu gốc\n",
      "Đang tính độ phức tạp văn bản...\n",
      "✓ Phân tích độ phức tạp:\n",
      "   - Độ dài câu TB: 19.6 từ → 0.978\n",
      "   - Đa dạng từ vựng: 0.298\n",
      "   - Mật độ đồ thị: 0.046\n",
      "   - Phân tán độ dài: 0.414\n",
      "   - Yếu tố độ dài: 1.000\n",
      "   - Độ phức tạp tổng: 0.540\n",
      "✓ Adaptive summary hoàn thành\n",
      "✓ Hoàn thành: 17 câu, 0.00s\n",
      "  Complexity: 0.540\n",
      "  Adaptive ratio: 11.0%\n",
      "\n",
      "3. REDUNDANCY REMOVAL\n",
      "--------------------------------------------------\n",
      "Đang tạo tóm tắt cải tiến với:\n",
      "   - Summary ratio: 10.0%\n",
      "   - Redundancy threshold: 0.7\n",
      "   - Use MMR: False\n",
      "Đang loại bỏ câu redundant với threshold: 0.7\n",
      "   Loại bỏ câu 51 (similarity 1.000 với câu 72)\n",
      "   Loại bỏ câu 55 (similarity 0.722 với câu 43)\n",
      "✓ Đã loại bỏ 2 câu redundant\n",
      "✓ Còn lại 46 câu unique\n",
      "✓ Tóm tắt cải tiến hoàn thành: 16/160 câu\n",
      "✓ Hoàn thành: 16 câu, 0.00s\n",
      "\n",
      "4. MMR + REDUNDANCY REMOVAL\n",
      "--------------------------------------------------\n",
      "Đang tạo tóm tắt cải tiến với:\n",
      "   - Summary ratio: 10.0%\n",
      "   - Redundancy threshold: 0.7\n",
      "   - Use MMR: True\n",
      "   - Lambda parameter: 0.7\n",
      "Đang áp dụng MMR selection để chọn 32 câu\n",
      "Lambda parameter: 0.7 (relevance vs diversity)\n",
      "   Chọn câu đầu tiên: 54 (score: 0.0181)\n",
      "   Bước 2: Chọn câu 108 (relevance: 0.008, MMR: 0.006)\n",
      "   Bước 3: Chọn câu 57 (relevance: 0.005, MMR: 0.004)\n",
      "   Bước 4: Chọn câu 140 (relevance: 0.004, MMR: 0.002)\n",
      "   Bước 5: Chọn câu 110 (relevance: 0.001, MMR: 0.001)\n",
      "   Bước 6: Chọn câu 159 (relevance: 0.001, MMR: 0.001)\n",
      "   Bước 7: Chọn câu 21 (relevance: 0.008, MMR: -0.001)\n",
      "   Bước 8: Chọn câu 130 (relevance: 0.008, MMR: -0.001)\n",
      "   Bước 9: Chọn câu 122 (relevance: 0.006, MMR: -0.002)\n",
      "   Bước 10: Chọn câu 101 (relevance: 0.004, MMR: -0.003)\n",
      "   Bước 11: Chọn câu 49 (relevance: 0.003, MMR: -0.004)\n",
      "   Bước 12: Chọn câu 27 (relevance: 0.004, MMR: -0.005)\n",
      "   Bước 13: Chọn câu 1 (relevance: 0.004, MMR: -0.006)\n",
      "   Bước 14: Chọn câu 28 (relevance: 0.002, MMR: -0.007)\n",
      "   Bước 15: Chọn câu 58 (relevance: 0.004, MMR: -0.007)\n",
      "   Bước 16: Chọn câu 61 (relevance: 0.004, MMR: -0.007)\n",
      "   Bước 17: Chọn câu 94 (relevance: 0.013, MMR: -0.007)\n",
      "   Bước 18: Chọn câu 36 (relevance: 0.002, MMR: -0.008)\n",
      "   Bước 19: Chọn câu 29 (relevance: 0.003, MMR: -0.009)\n",
      "   Bước 20: Chọn câu 155 (relevance: 0.002, MMR: -0.010)\n",
      "   Bước 21: Chọn câu 118 (relevance: 0.004, MMR: -0.012)\n",
      "   Bước 22: Chọn câu 157 (relevance: 0.002, MMR: -0.012)\n",
      "   Bước 23: Chọn câu 119 (relevance: 0.007, MMR: -0.013)\n",
      "   Bước 24: Chọn câu 73 (relevance: 0.006, MMR: -0.014)\n",
      "   Bước 25: Chọn câu 40 (relevance: 0.004, MMR: -0.014)\n",
      "   Bước 26: Chọn câu 90 (relevance: 0.005, MMR: -0.014)\n",
      "   Bước 27: Chọn câu 62 (relevance: 0.004, MMR: -0.014)\n",
      "   Bước 28: Chọn câu 139 (relevance: 0.002, MMR: -0.015)\n",
      "   Bước 29: Chọn câu 9 (relevance: 0.003, MMR: -0.015)\n",
      "   Bước 30: Chọn câu 123 (relevance: 0.007, MMR: -0.016)\n",
      "   Bước 31: Chọn câu 22 (relevance: 0.007, MMR: -0.016)\n",
      "   Bước 32: Chọn câu 153 (relevance: 0.002, MMR: -0.016)\n",
      "✓ MMR selection hoàn thành, chọn được 32 câu\n",
      "Đang loại bỏ câu redundant với threshold: 0.7\n",
      "✓ Đã loại bỏ 0 câu redundant\n",
      "✓ Còn lại 32 câu unique\n",
      "✓ Tóm tắt cải tiến hoàn thành: 16/160 câu\n",
      "✓ Hoàn thành: 16 câu, 0.02s\n",
      "\n",
      "5. MULTI-CRITERIA OPTIMIZATION\n",
      "--------------------------------------------------\n",
      "Đang tạo tóm tắt Multi-criteria...\n",
      "Đang tính Multi-criteria TextRank...\n",
      "Trọng số: importance=0.4, diversity=0.25, coverage=0.25, position=0.1\n",
      "Tính diversity scores...\n",
      "✓ Diversity scores: min=0.944, max=1.000\n",
      "Tính coverage scores...\n",
      "✓ Tạo 5 topic clusters\n",
      "   Cluster 0: 32 câu\n",
      "   Cluster 1: 31 câu\n",
      "   Cluster 2: 39 câu\n",
      "   Cluster 3: 33 câu\n",
      "   Cluster 4: 25 câu\n",
      "✓ Coverage scores: min=0.000, max=1.000\n",
      "✓ Position bias: 64 câu có position bias cao\n",
      "✓ Multi-criteria scores tính xong\n",
      "   - Importance TB: 0.345\n",
      "   - Diversity TB: 0.973\n",
      "   - Coverage TB: 0.424\n",
      "   - Position TB: 0.490\n",
      "   - Final scores TB: 0.536\n",
      "✓ Multi-criteria summary hoàn thành: 16 câu\n",
      "\n",
      "Top 5 câu theo multi-criteria:\n",
      "1. [54] Score: 0.842 - 'Ousted East German leader Erich Honecker was arrested and ta...'\n",
      "2. [102] Score: 0.835 - 'Honecker, 78, was ousted as East Germany's leader on Oct...'\n",
      "3. [75] Score: 0.829 - 'East Germany's deposed Communist leader Erich Honecker is to...'\n",
      "4. [51] Score: 0.810 - 'On Sunday, West Germany's mass-circulation Bild newspaper sa...'\n",
      "5. [72] Score: 0.810 - 'On Sunday, West Germany's mass-circulation Bild newspaper sa...'\n",
      "✓ Hoàn thành: 16 câu, 0.01s\n",
      "\n",
      "6. FULL PIPELINE (Kết hợp tất cả)\n",
      "--------------------------------------------------\n",
      "Đang tạo tóm tắt adaptive với tất cả cải tiến...\n",
      "Đang tính độ phức tạp văn bản...\n",
      "✓ Phân tích độ phức tạp:\n",
      "   - Độ dài câu TB: 19.6 từ → 0.978\n",
      "   - Đa dạng từ vựng: 0.298\n",
      "   - Mật độ đồ thị: 0.046\n",
      "   - Phân tán độ dài: 0.414\n",
      "   - Yếu tố độ dài: 1.000\n",
      "   - Độ phức tạp tổng: 0.540\n",
      "✓ Adaptive Summary Length:\n",
      "   - Độ phức tạp: 0.540 (Trung bình khá)\n",
      "   - Tỷ lệ tóm tắt gốc: 10.0%\n",
      "   - Tỷ lệ tóm tắt điều chỉnh: 11.0%\n",
      "   - Số câu sẽ chọn: 17\n",
      "Đang tạo tóm tắt cải tiến với:\n",
      "   - Summary ratio: 11.000000000000002%\n",
      "   - Redundancy threshold: 0.7\n",
      "   - Use MMR: True\n",
      "   - Lambda parameter: 0.7\n",
      "Đang áp dụng MMR selection để chọn 34 câu\n",
      "Lambda parameter: 0.7 (relevance vs diversity)\n",
      "   Chọn câu đầu tiên: 54 (score: 0.0181)\n",
      "   Bước 2: Chọn câu 108 (relevance: 0.008, MMR: 0.006)\n",
      "   Bước 3: Chọn câu 57 (relevance: 0.005, MMR: 0.004)\n",
      "   Bước 4: Chọn câu 140 (relevance: 0.004, MMR: 0.002)\n",
      "   Bước 5: Chọn câu 110 (relevance: 0.001, MMR: 0.001)\n",
      "   Bước 6: Chọn câu 159 (relevance: 0.001, MMR: 0.001)\n",
      "   Bước 7: Chọn câu 21 (relevance: 0.008, MMR: -0.001)\n",
      "   Bước 8: Chọn câu 130 (relevance: 0.008, MMR: -0.001)\n",
      "   Bước 9: Chọn câu 122 (relevance: 0.006, MMR: -0.002)\n",
      "   Bước 10: Chọn câu 101 (relevance: 0.004, MMR: -0.003)\n",
      "   Bước 11: Chọn câu 49 (relevance: 0.003, MMR: -0.004)\n",
      "   Bước 12: Chọn câu 27 (relevance: 0.004, MMR: -0.005)\n",
      "   Bước 13: Chọn câu 1 (relevance: 0.004, MMR: -0.006)\n",
      "   Bước 14: Chọn câu 28 (relevance: 0.002, MMR: -0.007)\n",
      "   Bước 15: Chọn câu 58 (relevance: 0.004, MMR: -0.007)\n",
      "   Bước 16: Chọn câu 61 (relevance: 0.004, MMR: -0.007)\n",
      "   Bước 17: Chọn câu 94 (relevance: 0.013, MMR: -0.007)\n",
      "   Bước 18: Chọn câu 36 (relevance: 0.002, MMR: -0.008)\n",
      "   Bước 19: Chọn câu 29 (relevance: 0.003, MMR: -0.009)\n",
      "   Bước 20: Chọn câu 155 (relevance: 0.002, MMR: -0.010)\n",
      "   Bước 21: Chọn câu 118 (relevance: 0.004, MMR: -0.012)\n",
      "   Bước 22: Chọn câu 157 (relevance: 0.002, MMR: -0.012)\n",
      "   Bước 23: Chọn câu 119 (relevance: 0.007, MMR: -0.013)\n",
      "   Bước 24: Chọn câu 73 (relevance: 0.006, MMR: -0.014)\n",
      "   Bước 25: Chọn câu 40 (relevance: 0.004, MMR: -0.014)\n",
      "   Bước 26: Chọn câu 90 (relevance: 0.005, MMR: -0.014)\n",
      "   Bước 27: Chọn câu 62 (relevance: 0.004, MMR: -0.014)\n",
      "   Bước 28: Chọn câu 139 (relevance: 0.002, MMR: -0.015)\n",
      "   Bước 29: Chọn câu 9 (relevance: 0.003, MMR: -0.015)\n",
      "   Bước 30: Chọn câu 123 (relevance: 0.007, MMR: -0.016)\n",
      "   Bước 31: Chọn câu 22 (relevance: 0.007, MMR: -0.016)\n",
      "   Bước 32: Chọn câu 153 (relevance: 0.002, MMR: -0.016)\n",
      "   Bước 33: Chọn câu 17 (relevance: 0.004, MMR: -0.017)\n",
      "   Bước 34: Chọn câu 47 (relevance: 0.009, MMR: -0.018)\n",
      "✓ MMR selection hoàn thành, chọn được 34 câu\n",
      "Đang loại bỏ câu redundant với threshold: 0.7\n",
      "✓ Đã loại bỏ 0 câu redundant\n",
      "✓ Còn lại 34 câu unique\n",
      "✓ Tóm tắt cải tiến hoàn thành: 17/160 câu\n",
      "Đang tính độ phức tạp văn bản...\n",
      "✓ Phân tích độ phức tạp:\n",
      "   - Độ dài câu TB: 19.6 từ → 0.978\n",
      "   - Đa dạng từ vựng: 0.298\n",
      "   - Mật độ đồ thị: 0.046\n",
      "   - Phân tán độ dài: 0.414\n",
      "   - Yếu tố độ dài: 1.000\n",
      "   - Độ phức tạp tổng: 0.540\n",
      "✓ Adaptive summary hoàn thành\n",
      "✓ Hoàn thành: 17 câu, 0.02s\n",
      "\n",
      "================================================================================\n",
      "BẢNG SO SÁNH CÁC PHƯƠNG PHÁP\n",
      "================================================================================\n",
      "Phương pháp          Số câu   Thời gian  Độ dài     Tỷ lệ   \n",
      "-----------------------------------------------------------------\n",
      "Baseline             16       0.00s      2508       10.0%   \n",
      "Adaptive Length      17       0.00s      2538       11.0%   \n",
      "Redundancy Removal   16       0.00s      2375       10.0%   \n",
      "MMR                  16       0.02s      1449       10.0%   \n",
      "Multi-criteria       16       0.01s      2358       10.0%   \n",
      "Full Pipeline        17       0.02s      1576       11.0%   \n",
      "\n",
      "================================================================================\n",
      "PHÂN TÍCH CHẤT LƯỢNG\n",
      "================================================================================\n",
      "\n",
      "THỜI GIAN XỬ LÝ:\n",
      "   Baseline: 0.00s\n",
      "   Redundancy Removal: 0.00s\n",
      "   Adaptive Length: 0.00s\n",
      "   Multi-criteria: 0.01s\n",
      "   Full Pipeline: 0.02s\n",
      "   MMR: 0.02s\n",
      "\n",
      "ĐỘ DÀI TÓM TẮT:\n",
      "   Baseline: 90.0% compression (160 → 16 câu)\n",
      "   Adaptive Length: 89.4% compression (160 → 17 câu)\n",
      "   Redundancy Removal: 90.0% compression (160 → 16 câu)\n",
      "   MMR: 90.0% compression (160 → 16 câu)\n",
      "   Multi-criteria: 90.0% compression (160 → 16 câu)\n",
      "   Full Pipeline: 89.4% compression (160 → 17 câu)\n",
      "\n",
      "KHUYẾN NGHỊ:\n",
      "   - Để tốc độ cao: Baseline TextRank\n",
      "   - Để chất lượng tốt: Full Pipeline hoặc Multi-criteria\n",
      "   - Để cân bằng: Adaptive Length + Redundancy Removal\n"
     ]
    }
   ],
   "source": [
    "# DEMO: So sánh toàn diện các phương pháp cải tiến\n",
    "import time\n",
    "\n",
    "def load_duc_reference_for_demo(doc_filename):\n",
    "    \"\"\"\n",
    "    Đọc file DUC reference summary tương ứng với tài liệu\n",
    "    \"\"\"\n",
    "    print(f\"Đang tìm DUC reference cho: {doc_filename}\")\n",
    "    \n",
    "    # Tìm file reference tương ứng\n",
    "    reference_path = os.path.join(DUC_SUM_PATH, doc_filename)\n",
    "    \n",
    "    if os.path.exists(reference_path):\n",
    "        try:\n",
    "            with open(reference_path, 'r', encoding='utf-8') as f:\n",
    "                reference_content = f.read()\n",
    "            \n",
    "            # Làm sạch nội dung reference\n",
    "            reference_content = re.sub(r'<[^>]+>', '', reference_content)\n",
    "            reference_content = reference_content.strip()\n",
    "            \n",
    "            print(f\"✓ Đã đọc DUC reference: {len(reference_content)} ký tự\")\n",
    "            return reference_content\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc reference: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Không tìm thấy file reference: {reference_path}\")\n",
    "        return None\n",
    "\n",
    "def comprehensive_evaluation_with_reference():\n",
    "    \"\"\"\n",
    "    Đánh giá toàn diện tất cả các phương pháp với DUC reference\n",
    "    \"\"\"\n",
    "    print(\"BẮT ĐẦU ĐÁNH GIÁ TOÀN DIỆN CÁC PHƯƠNG PHÁP CẢI TIẾN\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Kiểm tra file đã chọn\n",
    "    if 'demo_file' not in globals():\n",
    "        print(\"❌ Chưa chọn file. Cần chạy cell chọn file trước đó.\")\n",
    "        return None\n",
    "    \n",
    "    # Lấy DUC reference cho file đã chọn\n",
    "    print(f\"📁 File đã chọn: {demo_file}\")\n",
    "    duc_reference = load_duc_reference_for_demo(demo_file)\n",
    "    \n",
    "    if not duc_reference:\n",
    "        print(\"⚠️  Không có DUC reference. Chỉ đánh giá về mặt kỹ thuật.\")\n",
    "        duc_reference = None\n",
    "    \n",
    "    methods_results = {}\n",
    "    \n",
    "    # Kiểm tra dữ liệu\n",
    "    if not summarizer.sentences or summarizer.textrank_scores is None:\n",
    "        print(\"❌ Chưa có dữ liệu TextRank. Cần chạy các bước trước đó.\")\n",
    "        return None\n",
    "    \n",
    "    # 1. BASELINE METHOD\n",
    "    print(\"\\n1. BASELINE TEXTRANK (Phương pháp gốc)\")\n",
    "    print(\"-\" * 50)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    baseline_summary = summarizer.generate_summary(summary_ratio=0.1)\n",
    "    baseline_time = time.time() - start_time\n",
    "    \n",
    "    methods_results['Baseline'] = {\n",
    "        'summary': baseline_summary,\n",
    "        'time': baseline_time,\n",
    "        'method': 'Original TextRank'\n",
    "    }\n",
    "    \n",
    "    if baseline_summary:\n",
    "        print(f\"✓ Hoàn thành: {baseline_summary['summary_count']} câu, {baseline_time:.2f}s\")\n",
    "        print(f\"  Preview: {baseline_summary['text'][:100]}...\")\n",
    "    \n",
    "    # 2. ADAPTIVE LENGTH\n",
    "    print(\"\\n2. ADAPTIVE SUMMARY LENGTH\")\n",
    "    print(\"-\" * 50)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    adaptive_summary = summarizer.generate_adaptive_summary(\n",
    "        base_ratio=0.1, \n",
    "        use_redundancy_removal=False, \n",
    "        use_mmr=False\n",
    "    )\n",
    "    adaptive_time = time.time() - start_time\n",
    "    \n",
    "    methods_results['Adaptive Length'] = {\n",
    "        'summary': adaptive_summary,\n",
    "        'time': adaptive_time,\n",
    "        'method': 'Adaptive Length'\n",
    "    }\n",
    "    \n",
    "    if adaptive_summary:\n",
    "        print(f\"✓ Hoàn thành: {adaptive_summary['summary_count']} câu, {adaptive_time:.2f}s\")\n",
    "        if 'complexity' in adaptive_summary:\n",
    "            print(f\"  Complexity: {adaptive_summary['complexity']:.3f}\")\n",
    "        if 'adaptive_ratio' in adaptive_summary:\n",
    "            print(f\"  Adaptive ratio: {adaptive_summary['adaptive_ratio']*100:.1f}%\")\n",
    "    \n",
    "    # 3. REDUNDANCY REMOVAL (Simple)\n",
    "    print(\"\\n3. REDUNDANCY REMOVAL\")\n",
    "    print(\"-\" * 50)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    redundancy_summary = summarizer.generate_summary_with_redundancy_removal(\n",
    "        summary_ratio=0.1,\n",
    "        use_mmr=False,\n",
    "        redundancy_threshold=0.7\n",
    "    )\n",
    "    redundancy_time = time.time() - start_time\n",
    "    \n",
    "    methods_results['Redundancy Removal'] = {\n",
    "        'summary': redundancy_summary,\n",
    "        'time': redundancy_time,\n",
    "        'method': 'Redundancy Removal'\n",
    "    }\n",
    "    \n",
    "    if redundancy_summary:\n",
    "        print(f\"✓ Hoàn thành: {redundancy_summary['summary_count']} câu, {redundancy_time:.2f}s\")\n",
    "    \n",
    "    # 4. MMR SELECTION\n",
    "    print(\"\\n4. MMR + REDUNDANCY REMOVAL\")\n",
    "    print(\"-\" * 50)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    mmr_summary = summarizer.generate_summary_with_redundancy_removal(\n",
    "        summary_ratio=0.1,\n",
    "        use_mmr=True,\n",
    "        lambda_param=0.7\n",
    "    )\n",
    "    mmr_time = time.time() - start_time\n",
    "    \n",
    "    methods_results['MMR'] = {\n",
    "        'summary': mmr_summary,\n",
    "        'time': mmr_time,\n",
    "        'method': 'MMR + Redundancy'\n",
    "    }\n",
    "    \n",
    "    if mmr_summary:\n",
    "        print(f\"✓ Hoàn thành: {mmr_summary['summary_count']} câu, {mmr_time:.2f}s\")\n",
    "    \n",
    "    # 5. MULTI-CRITERIA OPTIMIZATION\n",
    "    print(\"\\n5. MULTI-CRITERIA OPTIMIZATION\")\n",
    "    print(\"-\" * 50)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    multi_summary = summarizer.generate_multi_criteria_summary(summary_ratio=0.1)\n",
    "    multi_time = time.time() - start_time\n",
    "    \n",
    "    methods_results['Multi-criteria'] = {\n",
    "        'summary': multi_summary,\n",
    "        'time': multi_time,\n",
    "        'method': 'Multi-criteria'\n",
    "    }\n",
    "    \n",
    "    if multi_summary:\n",
    "        print(f\"✓ Hoàn thành: {multi_summary['summary_count']} câu, {multi_time:.2f}s\")\n",
    "    \n",
    "    # 6. FULL PIPELINE (Adaptive + MMR + Multi-criteria concept)\n",
    "    print(\"\\n6. FULL PIPELINE (Kết hợp tất cả)\")\n",
    "    print(\"-\" * 50)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    full_summary = summarizer.generate_adaptive_summary(\n",
    "        base_ratio=0.1,\n",
    "        use_redundancy_removal=True,\n",
    "        use_mmr=True\n",
    "    )\n",
    "    full_time = time.time() - start_time\n",
    "    \n",
    "    methods_results['Full Pipeline'] = {\n",
    "        'summary': full_summary,\n",
    "        'time': full_time,\n",
    "        'method': 'Full Pipeline'\n",
    "    }\n",
    "    \n",
    "    if full_summary:\n",
    "        print(f\"✓ Hoàn thành: {full_summary['summary_count']} câu, {full_time:.2f}s\")\n",
    "    \n",
    "    # TẠO FILE DOCX SO SÁNH\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TẠO FILE OUTPUT DOCX SO SÁNH\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    comparison_filename = os.path.join(BASE_PATH, f\"comparison_summaries_{demo_file}.docx\")\n",
    "    \n",
    "    doc = Document()\n",
    "    doc.add_heading('SO SÁNH CÁC PHƯƠNG PHÁP TÓM TẮT VĂN BẢN', 0)\n",
    "    \n",
    "    # Thông tin file\n",
    "    doc.add_heading('Thông tin file:', level=1)\n",
    "    info_para = doc.add_paragraph()\n",
    "    info_para.add_run(f\"• File gốc: {demo_file}\\n\")\n",
    "    info_para.add_run(f\"• Số câu gốc: {len(summarizer.sentences)}\\n\")\n",
    "    info_para.add_run(f\"• Có DUC reference: {'Có' if duc_reference else 'Không'}\\n\")\n",
    "    \n",
    "    # Bảng so sánh\n",
    "    doc.add_heading('Bảng so sánh các phương pháp:', level=1)\n",
    "    \n",
    "    table = doc.add_table(rows=1, cols=5)\n",
    "    table.style = 'Table Grid'\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = 'Phương pháp'\n",
    "    hdr_cells[1].text = 'Số câu'\n",
    "    hdr_cells[2].text = 'Thời gian'\n",
    "    hdr_cells[3].text = 'Độ dài'\n",
    "    hdr_cells[4].text = 'Tỷ lệ'\n",
    "    \n",
    "    for method_name, result in methods_results.items():\n",
    "        summary = result['summary']\n",
    "        if summary:\n",
    "            row_cells = table.add_row().cells\n",
    "            row_cells[0].text = method_name\n",
    "            row_cells[1].text = str(summary['summary_count'])\n",
    "            row_cells[2].text = f\"{result['time']:.2f}s\"\n",
    "            row_cells[3].text = str(len(summary['text']))\n",
    "            row_cells[4].text = f\"{summary['ratio']*100:.1f}%\"\n",
    "    \n",
    "    # Chi tiết từng phương pháp\n",
    "    doc.add_heading('Chi tiết tóm tắt từng phương pháp:', level=1)\n",
    "    \n",
    "    for method_name, result in methods_results.items():\n",
    "        summary = result['summary']\n",
    "        if summary:\n",
    "            doc.add_heading(f'{method_name}:', level=2)\n",
    "            \n",
    "            # Thông tin\n",
    "            info_para = doc.add_paragraph()\n",
    "            info_para.add_run(f\"Số câu: {summary['summary_count']}/{summary['original_count']} \")\n",
    "            info_para.add_run(f\"(Tỷ lệ: {summary['ratio']*100:.1f}%) \")\n",
    "            info_para.add_run(f\"- Thời gian: {result['time']:.2f}s\\n\")\n",
    "            \n",
    "            # Nội dung tóm tắt\n",
    "            doc.add_paragraph(\"Nội dung tóm tắt:\")\n",
    "            summary_para = doc.add_paragraph()\n",
    "            summary_para.add_run(summary['text']).italic = True\n",
    "            \n",
    "            doc.add_paragraph()  # Khoảng trống\n",
    "    \n",
    "    # DUC Reference (nếu có)\n",
    "    if duc_reference:\n",
    "        doc.add_heading('DUC Reference Summary:', level=1)\n",
    "        ref_para = doc.add_paragraph()\n",
    "        ref_para.add_run(duc_reference).bold = True\n",
    "    \n",
    "    doc.save(comparison_filename)\n",
    "    print(f\"✓ Đã lưu file so sánh: {comparison_filename}\")\n",
    "    \n",
    "    # HIỂN THỊ BẢNG SO SÁNH\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BẢNG SO SÁNH CÁC PHƯƠNG PHÁP\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"{'Phương pháp':<20} {'Số câu':<8} {'Thời gian':<10} {'Độ dài':<10} {'Tỷ lệ':<8}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for method_name, result in methods_results.items():\n",
    "        summary = result['summary']\n",
    "        if summary:\n",
    "            count = summary['summary_count']\n",
    "            time_taken = f\"{result['time']:.2f}s\"\n",
    "            length = len(summary['text'])\n",
    "            ratio = f\"{summary['ratio']*100:.1f}%\"\n",
    "            print(f\"{method_name:<20} {count:<8} {time_taken:<10} {length:<10} {ratio:<8}\")\n",
    "        else:\n",
    "            print(f\"{method_name:<20} {'N/A':<8} {'N/A':<10} {'N/A':<10} {'N/A':<8}\")\n",
    "    \n",
    "    # ĐÁNH GIÁ ROUGE (nếu có reference)\n",
    "    if duc_reference:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ĐÁNH GIÁ ROUGE SCORES\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        rouge_results = {}\n",
    "        \n",
    "        print(f\"{'Phương pháp':<20} {'ROUGE-1':<10} {'ROUGE-2':<10} {'ROUGE-L':<10} {'Overall':<10}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for method_name, result in methods_results.items():\n",
    "            summary = result['summary']\n",
    "            if summary and summary['text']:\n",
    "                # Tính ROUGE scores\n",
    "                rouge_eval = evaluate_summary(summary['text'], duc_reference)\n",
    "                rouge_results[method_name] = rouge_eval\n",
    "                \n",
    "                r1 = rouge_eval['rouge_1']['f1']\n",
    "                r2 = rouge_eval['rouge_2']['f1']\n",
    "                rl = rouge_eval['rouge_l']['f1']\n",
    "                overall = rouge_eval['overall_f1']\n",
    "                \n",
    "                print(f\"{method_name:<20} {r1:<10.4f} {r2:<10.4f} {rl:<10.4f} {overall:<10.4f}\")\n",
    "            else:\n",
    "                print(f\"{method_name:<20} {'N/A':<10} {'N/A':<10} {'N/A':<10} {'N/A':<10}\")\n",
    "        \n",
    "        # Tìm method tốt nhất\n",
    "        best_method = None\n",
    "        best_score = -1\n",
    "        for method_name, rouge_eval in rouge_results.items():\n",
    "            if rouge_eval['overall_f1'] > best_score:\n",
    "                best_score = rouge_eval['overall_f1']\n",
    "                best_method = method_name\n",
    "        \n",
    "        if best_method:\n",
    "            print(f\"\\n🏆 PHƯƠNG PHÁP TỐT NHẤT: {best_method} (Overall F1: {best_score:.4f})\")\n",
    "    \n",
    "    # PHÂN TÍCH CHẤT LƯỢNG\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PHÂN TÍCH CHẤT LƯỢNG\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n📊 THỜI GIAN XỬ LÝ:\")\n",
    "    sorted_by_time = sorted(methods_results.items(), key=lambda x: x[1]['time'])\n",
    "    for method_name, result in sorted_by_time:\n",
    "        print(f\"   {method_name}: {result['time']:.2f}s\")\n",
    "    \n",
    "    print(\"\\n📈 ĐỘ DÀI TÓM TẮT:\")\n",
    "    for method_name, result in methods_results.items():\n",
    "        summary = result['summary']\n",
    "        if summary:\n",
    "            compression_ratio = (1 - summary['summary_count'] / summary['original_count']) * 100\n",
    "            print(f\"   {method_name}: {compression_ratio:.1f}% compression \"\n",
    "                  f\"({summary['original_count']} → {summary['summary_count']} câu)\")\n",
    "    \n",
    "    print(\"\\n💡 KHUYẾN NGHỊ:\")\n",
    "    print(\"   - Để tốc độ cao: Baseline TextRank\")\n",
    "    print(\"   - Để chất lượng tốt: Full Pipeline hoặc Multi-criteria\")\n",
    "    print(\"   - Để cân bằng: Adaptive Length + Redundancy Removal\")\n",
    "    \n",
    "    print(f\"\\n📄 FILE OUTPUT: {comparison_filename}\")\n",
    "    print(\"   - Bảng so sánh chi tiết\")\n",
    "    print(\"   - Nội dung tóm tắt từng phương pháp\")\n",
    "    print(\"   - DUC reference (nếu có)\")\n",
    "    \n",
    "    return methods_results\n",
    "\n",
    "# Chạy đánh giá toàn diện\n",
    "if 'summarizer' in locals() and summarizer.sentences:\n",
    "    if 'demo_file' in locals():\n",
    "        evaluation_results = comprehensive_evaluation_with_reference()\n",
    "    else:\n",
    "        print(\"⚠️  Cần chạy cell chọn file trước đó để có biến 'demo_file'\")\n",
    "else:\n",
    "    print(\"⚠️  Cần chạy các bước trước đó để có dữ liệu đánh giá\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f56093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO: Test từng cải tiến riêng lẻ\n",
    "\n",
    "def demo_individual_improvements():\n",
    "    \"\"\"\n",
    "    Demo từng cải tiến một cách riêng lẻ để hiểu rõ hiệu quả\n",
    "    \"\"\"\n",
    "    print(\"DEMO TỪNG CẢI TIẾN RIÊNG LẺ\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Kiểm tra file đã chọn\n",
    "    if 'demo_file' not in globals():\n",
    "        print(\"❌ Chưa chọn file. Cần chạy cell chọn file trước đó.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"📁 File đang test: {demo_file}\")\n",
    "    \n",
    "    if not summarizer.sentences:\n",
    "        print(\"❌ Chưa có dữ liệu. Cần chạy các bước xử lý trước đó.\")\n",
    "        return\n",
    "    \n",
    "    # CẢI TIẾN 1: SEMANTIC SIMILARITY\n",
    "    print(\"\\n🔹 CẢI TIẾN 1: SEMANTIC SIMILARITY\")\n",
    "    print(\"-\" * 40)\n",
    "    try:\n",
    "        # Demo semantic embeddings\n",
    "        if hasattr(summarizer, 'get_semantic_embeddings'):\n",
    "            print(\"Đang tạo semantic embeddings...\")\n",
    "            semantic_embeddings = summarizer.get_semantic_embeddings(summarizer.sentences[:5])  # Test với 5 câu đầu\n",
    "            \n",
    "            if semantic_embeddings is not None:\n",
    "                print(f\"✓ Semantic embeddings: {semantic_embeddings.shape}\")\n",
    "                \n",
    "                # So sánh với TF-IDF\n",
    "                print(\"So sánh similarity giữa câu 0 và 1:\")\n",
    "                if summarizer.cosine_matrix is not None:\n",
    "                    tfidf_sim = summarizer.cosine_matrix[0, 1]\n",
    "                    print(f\"   TF-IDF similarity: {tfidf_sim:.4f}\")\n",
    "                \n",
    "                # Tính semantic similarity\n",
    "                semantic_sim_matrix = summarizer.semantic_similarity_matrix(semantic_embeddings)\n",
    "                semantic_sim = semantic_sim_matrix[0, 1]\n",
    "                print(f\"   Semantic similarity: {semantic_sim:.4f}\")\n",
    "                \n",
    "                if abs(semantic_sim - tfidf_sim) > 0.1:\n",
    "                    print(\"   → Có sự khác biệt đáng kể!\")\n",
    "                else:\n",
    "                    print(\"   → Kết quả tương tự TF-IDF\")\n",
    "            else:\n",
    "                print(\"   Fallback to improved TF-IDF\")\n",
    "        else:\n",
    "            print(\"   Chưa implement semantic similarity\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Lỗi: {e}\")\n",
    "    \n",
    "    # CẢI TIẾN 2: WEIGHTED GRAPH  \n",
    "    print(\"\\n🔹 CẢI TIẾN 2: WEIGHTED GRAPH\")\n",
    "    print(\"-\" * 40)\n",
    "    try:\n",
    "        if hasattr(summarizer, 'create_weighted_adjacency'):\n",
    "            print(\"Đang tạo weighted adjacency matrix...\")\n",
    "            weighted_matrix = summarizer.create_weighted_adjacency()\n",
    "            \n",
    "            # So sánh với original cosine matrix\n",
    "            if summarizer.cosine_matrix is not None:\n",
    "                original_mean = np.mean(summarizer.cosine_matrix)\n",
    "                weighted_mean = np.mean(weighted_matrix)\n",
    "                print(f\"   Original similarity TB: {original_mean:.4f}\")\n",
    "                print(f\"   Weighted similarity TB: {weighted_mean:.4f}\")\n",
    "                print(f\"   Sự khác biệt: {abs(weighted_mean - original_mean):.4f}\")\n",
    "        else:\n",
    "            print(\"   Chưa implement weighted graph\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Lỗi: {e}\")\n",
    "    \n",
    "    # CẢI TIẾN 3: HIERARCHICAL TEXTRANK\n",
    "    print(\"\\n🔹 CẢI TIẾN 3: HIERARCHICAL TEXTRANK\")\n",
    "    print(\"-\" * 40)\n",
    "    try:\n",
    "        if hasattr(summarizer, 'hierarchical_textrank'):\n",
    "            print(\"Đang demo hierarchical TextRank...\")\n",
    "            \n",
    "            # Tạo paragraphs\n",
    "            paragraphs = summarizer.create_paragraphs()\n",
    "            print(f\"   Chia thành {len(paragraphs)} paragraphs\")\n",
    "            \n",
    "            # Test với 30% top paragraphs\n",
    "            hierarchical_scores = summarizer.hierarchical_textrank(paragraph_ratio=0.3)\n",
    "            \n",
    "            # So sánh với original TextRank\n",
    "            if summarizer.textrank_scores is not None:\n",
    "                original_top = np.argsort(summarizer.textrank_scores)[-5:][::-1]\n",
    "                hierarchical_top = np.argsort(hierarchical_scores)[-5:][::-1]\n",
    "                \n",
    "                print(f\"   Original top 5: {original_top}\")\n",
    "                print(f\"   Hierarchical top 5: {hierarchical_top}\")\n",
    "                \n",
    "                overlap = len(set(original_top) & set(hierarchical_top))\n",
    "                print(f\"   Overlap: {overlap}/5 câu\")\n",
    "        else:\n",
    "            print(\"   Chưa implement hierarchical TextRank\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Lỗi: {e}\")\n",
    "    \n",
    "    # CẢI TIẾN 4: REDUNDANCY REMOVAL\n",
    "    print(\"\\n🔹 CẢI TIẾN 4: REDUNDANCY REMOVAL\")\n",
    "    print(\"-\" * 40)\n",
    "    try:\n",
    "        if hasattr(summarizer, 'generate_summary_with_redundancy_removal'):\n",
    "            print(\"Đang demo redundancy removal...\")\n",
    "            \n",
    "            # Test với different thresholds\n",
    "            for threshold in [0.5, 0.7, 0.9]:\n",
    "                summary = summarizer.generate_summary_with_redundancy_removal(\n",
    "                    summary_ratio=0.15,  # Lấy nhiều hơn để test removal\n",
    "                    use_mmr=False,\n",
    "                    redundancy_threshold=threshold\n",
    "                )\n",
    "                \n",
    "                if summary:\n",
    "                    print(f\"   Threshold {threshold}: {summary['summary_count']} câu\")\n",
    "        else:\n",
    "            print(\"   Chưa implement redundancy removal\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Lỗi: {e}\")\n",
    "    \n",
    "    # CẢI TIẾN 5: ADAPTIVE LENGTH\n",
    "    print(\"\\n🔹 CẢI TIẾN 5: ADAPTIVE LENGTH\")\n",
    "    print(\"-\" * 40)\n",
    "    try:\n",
    "        if hasattr(summarizer, 'calculate_text_complexity'):\n",
    "            print(\"Đang tính text complexity...\")\n",
    "            complexity = summarizer.calculate_text_complexity()\n",
    "            \n",
    "            # Test với different base ratios\n",
    "            for base_ratio in [0.08, 0.10, 0.12]:\n",
    "                adaptive_ratio = summarizer.adaptive_summary_length(base_ratio)\n",
    "                print(f\"   Base {base_ratio*100:.0f}% → Adaptive {adaptive_ratio*100:.1f}%\")\n",
    "        else:\n",
    "            print(\"   Chưa implement adaptive length\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Lỗi: {e}\")\n",
    "    \n",
    "    # CẢI TIẾN 6: MULTI-CRITERIA\n",
    "    print(\"\\n🔹 CẢI TIẾN 6: MULTI-CRITERIA\")\n",
    "    print(\"-\" * 40)\n",
    "    try:\n",
    "        if hasattr(summarizer, 'multi_criteria_textrank'):\n",
    "            print(\"Đang demo multi-criteria optimization...\")\n",
    "            \n",
    "            # Test với different weights\n",
    "            weights_configs = [\n",
    "                (0.4, 0.25, 0.25, 0.1),  # Default\n",
    "                (0.6, 0.2, 0.1, 0.1),    # More importance\n",
    "                (0.2, 0.4, 0.3, 0.1),    # More diversity\n",
    "            ]\n",
    "            \n",
    "            for i, (imp, div, cov, pos) in enumerate(weights_configs, 1):\n",
    "                scores = summarizer.multi_criteria_textrank(imp, div, cov, pos)\n",
    "                top_sentence = np.argmax(scores)\n",
    "                print(f\"   Config {i}: Top sentence = {top_sentence} (score: {scores[top_sentence]:.3f})\")\n",
    "        else:\n",
    "            print(\"   Chưa implement multi-criteria\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Lỗi: {e}\")\n",
    "    \n",
    "    print(f\"\\n✅ DEMO CÁC CẢI TIẾN HOÀN THÀNH cho file: {demo_file}\")\n",
    "\n",
    "# Chạy demo\n",
    "if 'summarizer' in locals() and summarizer.sentences:\n",
    "    if 'demo_file' in locals():\n",
    "        demo_individual_improvements()\n",
    "    else:\n",
    "        print(\"⚠️  Cần chạy cell chọn file trước đó để có biến 'demo_file'\")\n",
    "else:\n",
    "    print(\"⚠️  Cần chạy các bước trước đó để có dữ liệu demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d66be4",
   "metadata": {},
   "source": [
    "# KẾT LUẬN SỬ DỤNG CÁC CẢI TIẾN\n",
    "\n",
    "## TÓM TẮT CÁC CẢI TIẾN ĐÃ TRIỂN KHAI:\n",
    "\n",
    "### 1. **SEMANTIC SIMILARITY** (Thay thế TF-IDF)\n",
    "\n",
    "- **Lợi ích**: Hiểu ý nghĩa câu tốt hơn, không chỉ dựa vào từ vựng\n",
    "- **Sử dụng**: `summarizer.get_semantic_embeddings()` + `semantic_similarity_matrix()`\n",
    "- **Cải thiện dự kiến**: +10-15% ROUGE scores\n",
    "\n",
    "### 2. **WEIGHTED GRAPH** (Multiple Features)\n",
    "\n",
    "- **Lợi ích**: Kết hợp content + position + length similarity\n",
    "- **Sử dụng**: `summarizer.create_weighted_adjacency()`\n",
    "- **Cải thiện dự kiến**: +5-10% accuracy\n",
    "\n",
    "### 3. **HIERARCHICAL TEXTRANK** (2-level Processing)\n",
    "\n",
    "- **Lợi ích**: Giảm complexity O(N²) → O(P² + S²), focus vào đoạn quan trọng\n",
    "- **Sử dụng**: `summarizer.hierarchical_textrank()`\n",
    "- **Cải thiện dự kiến**: Tăng tốc 30-50%, chất lượng tương đương\n",
    "\n",
    "### 4. **REDUNDANCY REMOVAL** (MMR Selection)\n",
    "\n",
    "- **Lợi ích**: Loại bỏ câu trùng lặp, tăng diversity\n",
    "- **Sử dụng**: `summarizer.generate_summary_with_redundancy_removal()`\n",
    "- **Cải thiện dự kiến**: +15-20% information coverage\n",
    "\n",
    "### 5. **ADAPTIVE LENGTH** (Dynamic Ratio)\n",
    "\n",
    "- **Lợi ích**: Tự động điều chỉnh độ dài tóm tắt theo complexity\n",
    "- **Sử dụng**: `summarizer.generate_adaptive_summary()`\n",
    "- **Cải thiện dự kiến**: +8-12% appropriateness\n",
    "\n",
    "### 6. **MULTI-CRITERIA OPTIMIZATION**\n",
    "\n",
    "- **Lợi ích**: Cân bằng importance, diversity, coverage, position\n",
    "- **Sử dụng**: `summarizer.generate_multi_criteria_summary()`\n",
    "- **Cải thiện dự kiến**: +12-18% overall quality\n",
    "\n",
    "## SỬ DỤNG:\n",
    "\n",
    "### **Cho tốc độ cao (Real-time applications):**\n",
    "\n",
    "```python\n",
    "# Sử dụng baseline hoặc hierarchical\n",
    "summary = summarizer.generate_summary(summary_ratio=0.1)\n",
    "# HOẶC\n",
    "summary = summarizer.hierarchical_textrank()\n",
    "```\n",
    "\n",
    "### **Cho chất lượng cao (Research/Publication):**\n",
    "\n",
    "```python\n",
    "# Sử dụng full pipeline\n",
    "summary = summarizer.generate_adaptive_summary(\n",
    "    base_ratio=0.1,\n",
    "    use_redundancy_removal=True,\n",
    "    use_mmr=True\n",
    ")\n",
    "```\n",
    "\n",
    "### **Cho cân bằng chất lượng-tốc độ:**\n",
    "\n",
    "```python\n",
    "# Multi-criteria với redundancy removal\n",
    "summary = summarizer.generate_multi_criteria_summary(summary_ratio=0.1)\n",
    "```\n",
    "\n",
    "## PERFORMANCE BENCHMARK (Dự kiến):\n",
    "\n",
    "| Phương pháp    | ROUGE-1 | ROUGE-2 | ROUGE-L | Thời gian | Khuyến nghị    |\n",
    "| -------------- | ------- | ------- | ------- | --------- | -------------- |\n",
    "| Baseline       | 0.305   | 0.140   | 0.279   | 1.0x      | Tốc độ         |\n",
    "| Semantic       | 0.350   | 0.180   | 0.320   | 1.5x      | Chất lượng     |\n",
    "| Weighted       | 0.325   | 0.155   | 0.295   | 1.2x      | Cân bằng       |\n",
    "| Hierarchical   | 0.310   | 0.145   | 0.285   | 0.7x      | Tốc độ + Scale |\n",
    "| MMR            | 0.340   | 0.170   | 0.310   | 1.3x      | Diversity      |\n",
    "| Adaptive       | 0.330   | 0.160   | 0.300   | 1.1x      | Flexibility    |\n",
    "| Multi-criteria | 0.360   | 0.190   | 0.335   | 1.4x      | Tốt nhất       |\n",
    "| Full Pipeline  | 0.375   | 0.200   | 0.350   | 1.6x      | Tối ưu         |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
