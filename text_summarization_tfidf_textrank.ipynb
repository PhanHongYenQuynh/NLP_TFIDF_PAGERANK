{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37205065",
   "metadata": {},
   "source": [
    "# TÓM TẮT VĂN BẢN BẰNG TF-IDF VÀ TEXTRANK\n",
    "\n",
    "Notebook này thực hiện tóm tắt văn bản sử dụng thuật toán TextRank dựa trên TF-IDF và đánh giá kết quả bằng ROUGE metrics.\n",
    "\n",
    "## Các bước thực hiện:\n",
    "\n",
    "1. Đọc file XML và lưu vào Word (input.docx)\n",
    "2. Biểu diễn các câu bằng vector TF-IDF\n",
    "3. Tính độ tương đồng cosine giữa các câu\n",
    "4. Mô hình hóa văn bản dưới dạng đồ thị\n",
    "5. Áp dụng thuật toán TextRank\n",
    "6. Lấy 10% câu có điểm cao nhất\n",
    "7. Lưu bản tóm tắt vào Word (output_summary.docx)\n",
    "8. Đọc DUC_SUM reference và lưu vào Word (Test_DUC_SUM.docx)\n",
    "9. So sánh và đánh giá bằng ROUGE\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d9712",
   "metadata": {},
   "source": [
    "## 1. Setup và Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d366a313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ python-docx đã được cài đặt\n",
      "✓ numpy đã sẵn sàng\n",
      "✓ Tất cả thư viện đã được import thành công!\n",
      "✓ Notebook sẵn sàng để chạy tóm tắt văn bản\n"
     ]
    }
   ],
   "source": [
    "# Import các thư viện cơ bản\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import xml.etree.ElementTree as ET\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import thư viện cho Word processing\n",
    "try:\n",
    "    from docx import Document\n",
    "    from docx.shared import Inches\n",
    "    print(\"✓ python-docx đã được cài đặt\")\n",
    "except ImportError:\n",
    "    print(\"Cần cài đặt python-docx: pip install python-docx\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"python-docx\"])\n",
    "    from docx import Document\n",
    "\n",
    "# Cài đặt các thư viện cần thiết nếu chưa có\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"✓ numpy đã sẵn sàng\")\n",
    "except ImportError:\n",
    "    print(\"Cần cài đặt numpy: pip install numpy\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"numpy\"])\n",
    "    import numpy as np\n",
    "\n",
    "print(\"✓ Tất cả thư viện đã được import thành công!\")\n",
    "print(\"✓ Notebook sẵn sàng để chạy tóm tắt văn bản\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9c3f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TextSummarizerTFIDFTextRank đã được khởi tạo\n",
      "  - Damping factor: 0.85\n",
      "  - Max iterations: 100\n",
      "  - Tolerance: 1e-06\n",
      "✓ Đường dẫn dữ liệu: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/MY/DUC_TEXT/train\n",
      "✓ Đường dẫn reference: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/MY/DUC_SUM\n"
     ]
    }
   ],
   "source": [
    "class TextSummarizerTFIDFTextRank:\n",
    "    \"\"\"\n",
    "    Lớp tóm tắt văn bản sử dụng TF-IDF và TextRank\n",
    "    Viết tay các công thức toán học để minh họa cách tính\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, damping_factor=0.85, max_iterations=100, tolerance=1e-6):\n",
    "        self.damping_factor = damping_factor\n",
    "        self.max_iterations = max_iterations\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "        # Dữ liệu câu\n",
    "        self.sentences = []\n",
    "        self.sentence_vectors = []\n",
    "        self.vocabulary = set()\n",
    "        self.word_doc_count = defaultdict(int)\n",
    "        \n",
    "        # Ma trận\n",
    "        self.tfidf_matrix = None\n",
    "        self.cosine_matrix = None\n",
    "        self.adjacency_matrix = None\n",
    "        self.transition_matrix = None\n",
    "        self.textrank_scores = None\n",
    "        \n",
    "        print(\"✓ TextSummarizerTFIDFTextRank đã được khởi tạo\")\n",
    "        print(f\"  - Damping factor: {damping_factor}\")\n",
    "        print(f\"  - Max iterations: {max_iterations}\")\n",
    "        print(f\"  - Tolerance: {tolerance}\")\n",
    "\n",
    "# Khởi tạo summarizer\n",
    "summarizer = TextSummarizerTFIDFTextRank()\n",
    "\n",
    "# Cấu hình đường dẫn\n",
    "BASE_PATH = \"/Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/MY\"\n",
    "DUC_TEXT_PATH = os.path.join(BASE_PATH, \"DUC_TEXT\", \"train\")\n",
    "DUC_SUM_PATH = os.path.join(BASE_PATH, \"DUC_SUM\")\n",
    "\n",
    "print(f\"✓ Đường dẫn dữ liệu: {DUC_TEXT_PATH}\")\n",
    "print(f\"✓ Đường dẫn reference: {DUC_SUM_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72666e8f",
   "metadata": {},
   "source": [
    "## 2. Bước 1: Đọc File XML và Xử Lý Văn Bản\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7153afde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Đã thêm các phương thức xử lý văn bản\n"
     ]
    }
   ],
   "source": [
    "def load_xml_document(self, file_path):\n",
    "    \"\"\"\n",
    "    Đọc và xử lý file XML từ DUC dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def preprocess_text(self, text):\n",
    "    \"\"\"\n",
    "    Tiền xử lý văn bản:\n",
    "    - Loại bỏ thẻ XML/HTML\n",
    "    - Tách câu dựa trên dấu câu\n",
    "    - Làm sạch văn bản\n",
    "    \"\"\"\n",
    "    # Loại bỏ thẻ XML/HTML\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Tách câu dựa trên dấu chấm, chấm than, chấm hỏi\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    \n",
    "    # Làm sạch từng câu\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Loại bỏ khoảng trắng thừa\n",
    "        sentence = sentence.strip()\n",
    "        if len(sentence) > 10:  # Chỉ giữ câu có ít nhất 10 ký tự\n",
    "            # Chuyển về chữ thường cho việc xử lý\n",
    "            sentence_clean = sentence.lower()\n",
    "            # Loại bỏ ký tự đặc biệt nhưng giữ nguyên câu gốc để hiển thị\n",
    "            cleaned_sentences.append({\n",
    "                'original': sentence,\n",
    "                'processed': re.sub(r'[^a-zA-Z0-9\\s]', '', sentence_clean)\n",
    "            })\n",
    "    \n",
    "    return cleaned_sentences\n",
    "\n",
    "def save_to_word(self, content, filename):\n",
    "    \"\"\"\n",
    "    Lưu nội dung vào file Word\n",
    "    \"\"\"\n",
    "    doc = Document()\n",
    "    doc.add_heading('Document Content', 0)\n",
    "    \n",
    "    if isinstance(content, list):\n",
    "        for i, item in enumerate(content, 1):\n",
    "            if isinstance(item, dict):\n",
    "                doc.add_paragraph(f\"{i}. {item['original']}\")\n",
    "            else:\n",
    "                doc.add_paragraph(f\"{i}. {item}\")\n",
    "    else:\n",
    "        doc.add_paragraph(content)\n",
    "    \n",
    "    doc.save(filename)\n",
    "    print(f\"✓ Đã lưu vào file: {filename}\")\n",
    "\n",
    "# Thêm các phương thức vào class\n",
    "TextSummarizerTFIDFTextRank.load_xml_document = load_xml_document\n",
    "TextSummarizerTFIDFTextRank.preprocess_text = preprocess_text\n",
    "TextSummarizerTFIDFTextRank.save_to_word = save_to_word\n",
    "\n",
    "print(\"✓ Đã thêm các phương thức xử lý văn bản\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c8c8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DANH SÁCH FILE CÓ SẴN TRONG DUC_TEXT:\n",
      "==================================================\n",
      "Tổng cộng: 50 file\n",
      "\n",
      "Các file có sẵn:\n",
      "d061j      d062j      d063j      d064j      d065j      \n",
      "d066j      d067f      d068f      d069f      d070f      \n",
      "d071f      d072f      d073b      d074b      d075b      \n",
      "d076b      d077b      d078b      d079a      d080a      \n",
      "d081a      d082a      d083a      d084a      d085d      \n",
      "d086d      d087d      d089d      d090d      d091c      \n",
      "d092c      d093c      d094c      d095c      d096c      \n",
      "d097e      d098e      d099e      d100e      d101e      \n",
      "d102e      d103g      d104g      d105g      d106g      \n",
      "d107g      d108g      d109h      d110h      d111h      \n",
      "\n",
      "Bạn có thể chọn bất kỳ file nào từ danh sách trên.\n",
      "Ví dụ: d061j, d062j, d063j, ...\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị danh sách tất cả file có sẵn\n",
    "print(\"DANH SÁCH FILE CÓ SẴN TRONG DUC_TEXT:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if os.path.exists(DUC_TEXT_PATH):\n",
    "    all_files = [f for f in os.listdir(DUC_TEXT_PATH) if not f.startswith('.')]\n",
    "    all_files.sort()\n",
    "    \n",
    "    print(f\"Tổng cộng: {len(all_files)} file\")\n",
    "    print(\"\\nCác file có sẵn:\")\n",
    "    \n",
    "    # Hiển thị file theo dạng cột\n",
    "    for i, filename in enumerate(all_files):\n",
    "        if i % 5 == 0 and i > 0:\n",
    "            print()\n",
    "        print(f\"{filename:<10}\", end=\" \")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Bạn có thể chọn bất kỳ file nào từ danh sách trên.\")\n",
    "    print(\"Ví dụ: d061j, d062j, d063j, ...\")\n",
    "else:\n",
    "    print(f\"Thư mục không tồn tại: {DUC_TEXT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85ee3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Có 50 file có sẵn trong DUC_TEXT:\n",
      "Một số file mẫu: ['d061j', 'd062j', 'd063j', 'd064j', 'd065j', 'd066j', 'd067f', 'd068f', 'd069f', 'd070f']\n",
      "Đã chọn file: d061j\n",
      "Đang đọc file: d061j\n",
      "✓ Đã đọc 32448 ký tự\n",
      "Đã tách thành 201 câu\n",
      "\n",
      "3 câu đầu tiên sau khi xử lý:\n",
      "1. Hurricane Gilbert swept toward the Dominican Republic Sunday, and the Civil Defense alerted its heavily populated south coast to prepare for high winds, heavy rains and high seas\n",
      "2. The storm was approaching from the southeast with sustained winds of 75 mph gusting to 92 mph\n",
      "3. ``There is no need for alarm,'' Civil Defense Director Eugenio Cabral said in a television alert shortly before midnight Saturday\n",
      "✓ Đã lưu vào file: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/MY/input.docx\n",
      "\n",
      "Bước 1 hoàn thành: Đã xử lý 201 câu và lưu vào input.docx\n",
      "Đã chọn file: d061j\n",
      "Đang đọc file: d061j\n",
      "✓ Đã đọc 32448 ký tự\n",
      "Đã tách thành 201 câu\n",
      "\n",
      "3 câu đầu tiên sau khi xử lý:\n",
      "1. Hurricane Gilbert swept toward the Dominican Republic Sunday, and the Civil Defense alerted its heavily populated south coast to prepare for high winds, heavy rains and high seas\n",
      "2. The storm was approaching from the southeast with sustained winds of 75 mph gusting to 92 mph\n",
      "3. ``There is no need for alarm,'' Civil Defense Director Eugenio Cabral said in a television alert shortly before midnight Saturday\n",
      "✓ Đã lưu vào file: /Users/yoliephan/Library/CloudStorage/OneDrive-Personal/Tài liệu/MASTER 2025/Đợt 1/Xử lý Ngôn Ngữ Tự Nhiên/MY/input.docx\n",
      "\n",
      "Bước 1 hoàn thành: Đã xử lý 201 câu và lưu vào input.docx\n"
     ]
    }
   ],
   "source": [
    "# Demo: Đọc file XML với tùy chọn chọn file\n",
    "if os.path.exists(DUC_TEXT_PATH):\n",
    "    files = [f for f in os.listdir(DUC_TEXT_PATH) if not f.startswith('.')]\n",
    "    files.sort()  # Sắp xếp để dễ tìm\n",
    "    \n",
    "    if files:\n",
    "        print(f\"Có {len(files)} file có sẵn trong DUC_TEXT:\")\n",
    "        print(\"Một số file mẫu:\", files[:10])  # Hiển thị 10 file đầu\n",
    "        \n",
    "        # Tùy chọn chọn file\n",
    "        demo_file_input = input(\"\\nNhập tên file muốn xử lý (ví dụ: d061j) hoặc nhấn Enter để dùng file đầu tiên: \").strip()\n",
    "        \n",
    "        if demo_file_input and demo_file_input in files:\n",
    "            demo_file = demo_file_input\n",
    "            print(f\"Đã chọn file: {demo_file}\")\n",
    "        elif demo_file_input and demo_file_input not in files:\n",
    "            print(f\"File '{demo_file_input}' không tồn tại. Sử dụng file đầu tiên: {files[0]}\")\n",
    "            demo_file = files[0]\n",
    "        else:\n",
    "            demo_file = files[0]\n",
    "            print(f\"Sử dụng file mặc định: {demo_file}\")\n",
    "        \n",
    "        file_path = os.path.join(DUC_TEXT_PATH, demo_file)\n",
    "        \n",
    "        print(f\"Đang đọc file: {demo_file}\")\n",
    "        \n",
    "        # Đọc nội dung\n",
    "        content = summarizer.load_xml_document(file_path)\n",
    "        print(f\"✓ Đã đọc {len(content)} ký tự\")\n",
    "        \n",
    "        # Tiền xử lý và tách câu\n",
    "        sentences = summarizer.preprocess_text(content)\n",
    "        print(f\"Đã tách thành {len(sentences)} câu\")\n",
    "        \n",
    "        # Lưu câu gốc vào summarizer\n",
    "        summarizer.sentences = sentences\n",
    "        \n",
    "        # Hiển thị 3 câu đầu tiên\n",
    "        print(\"\\n3 câu đầu tiên sau khi xử lý:\")\n",
    "        for i, sent in enumerate(sentences[:3], 1):\n",
    "            print(f\"{i}. {sent['original']}\")\n",
    "        \n",
    "        # Lưu vào file Word (input.docx)\n",
    "        input_filename = os.path.join(BASE_PATH, \"input.docx\")\n",
    "        summarizer.save_to_word(sentences, input_filename)\n",
    "        \n",
    "        print(f\"\\nBước 1 hoàn thành: Đã xử lý {len(sentences)} câu và lưu vào input.docx\")\n",
    "    else:\n",
    "        print(\"Không tìm thấy file nào trong thư mục DUC_TEXT\")\n",
    "else:\n",
    "    print(f\"Thư mục không tồn tại: {DUC_TEXT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053817f",
   "metadata": {},
   "source": [
    "## 3. Bước 2: Biểu Diễn Câu Bằng Vector TF-IDF\n",
    "\n",
    "**Công thức TF-IDF:**\n",
    "\n",
    "- **TF (Term Frequency)** = (số lần xuất hiện của từ trong câu) / (tổng số từ trong câu)\n",
    "- **IDF (Inverse Document Frequency)** = log(tổng số câu / số câu chứa từ đó)\n",
    "- **TF-IDF** = TF × IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c21dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã thêm các phương thức tính TF-IDF\n"
     ]
    }
   ],
   "source": [
    "def build_vocabulary(self):\n",
    "    \"\"\"\n",
    "    Xây dựng từ vựng từ tất cả các câu\n",
    "    \"\"\"\n",
    "    print(\"Đang xây dựng từ vựng...\")\n",
    "    \n",
    "    # Tách từ từ tất cả các câu\n",
    "    all_words = []\n",
    "    for sentence in self.sentences:\n",
    "        words = sentence['processed'].split()\n",
    "        # Lọc từ có ít nhất 2 ký tự\n",
    "        words = [word for word in words if len(word) >= 2]\n",
    "        all_words.extend(words)\n",
    "        \n",
    "        # Cập nhật từ vựng unique\n",
    "        self.vocabulary.update(words)\n",
    "        \n",
    "        # Đếm số câu chứa mỗi từ\n",
    "        unique_words = set(words)\n",
    "        for word in unique_words:\n",
    "            self.word_doc_count[word] += 1\n",
    "    \n",
    "    print(f\"Tổng từ vựng: {len(self.vocabulary)} từ\")\n",
    "    print(f\"Tổng từ (có lặp): {len(all_words)} từ\")\n",
    "    \n",
    "    return list(self.vocabulary)\n",
    "\n",
    "def calculate_tf(self, word, sentence_words):\n",
    "    \"\"\"\n",
    "    Tính Term Frequency (TF) \n",
    "    TF = số lần xuất hiện của từ / tổng số từ trong câu\n",
    "    \"\"\"\n",
    "    word_count = sentence_words.count(word)\n",
    "    total_words = len(sentence_words)\n",
    "    tf = word_count / total_words if total_words > 0 else 0\n",
    "    return tf\n",
    "\n",
    "def calculate_idf(self, word):\n",
    "    \"\"\"\n",
    "    Tính Inverse Document Frequency (IDF) \n",
    "    IDF = log(tổng số câu / số câu chứa từ)\n",
    "    \"\"\"\n",
    "    total_sentences = len(self.sentences)\n",
    "    sentences_with_word = self.word_doc_count[word]\n",
    "    \n",
    "    if sentences_with_word == 0:\n",
    "        return 0\n",
    "    \n",
    "    idf = math.log(total_sentences / sentences_with_word)\n",
    "    return idf\n",
    "\n",
    "def calculate_tfidf(self, word, sentence_words):\n",
    "    \"\"\"\n",
    "    Tính TF-IDF - viết tay công thức\n",
    "    TF-IDF = TF × IDF\n",
    "    \"\"\"\n",
    "    tf = self.calculate_tf(word, sentence_words)\n",
    "    idf = self.calculate_idf(word)\n",
    "    tfidf = tf * idf\n",
    "    return tfidf\n",
    "\n",
    "def build_tfidf_matrix(self):\n",
    "    \"\"\"\n",
    "    Xây dựng ma trận TF-IDF cho tất cả các câu\n",
    "    \"\"\"\n",
    "    print(\"Đang xây dựng ma trận TF-IDF...\")\n",
    "    \n",
    "    # Xây dựng từ vựng\n",
    "    vocab_list = self.build_vocabulary()\n",
    "    vocab_size = len(vocab_list)\n",
    "    \n",
    "    # Khởi tạo ma trận TF-IDF\n",
    "    self.tfidf_matrix = np.zeros((len(self.sentences), vocab_size))\n",
    "    \n",
    "    # Tạo mapping từ word → index\n",
    "    word_to_index = {word: i for i, word in enumerate(vocab_list)}\n",
    "    \n",
    "    # Tính TF-IDF cho từng câu\n",
    "    for sent_idx, sentence in enumerate(self.sentences):\n",
    "        sentence_words = sentence['processed'].split()\n",
    "        sentence_words = [word for word in sentence_words if len(word) >= 2]\n",
    "        \n",
    "        # Tính TF-IDF cho mỗi từ trong câu\n",
    "        for word in set(sentence_words):  # Chỉ tính cho từ unique trong câu\n",
    "            if word in word_to_index:\n",
    "                word_idx = word_to_index[word]\n",
    "                self.tfidf_matrix[sent_idx, word_idx] = self.calculate_tfidf(word, sentence_words)\n",
    "    \n",
    "    print(f\"✓ Ma trận TF-IDF: {self.tfidf_matrix.shape} (câu × từ vựng)\")\n",
    "    return self.tfidf_matrix, vocab_list\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.build_vocabulary = build_vocabulary\n",
    "TextSummarizerTFIDFTextRank.calculate_tf = calculate_tf\n",
    "TextSummarizerTFIDFTextRank.calculate_idf = calculate_idf\n",
    "TextSummarizerTFIDFTextRank.calculate_tfidf = calculate_tfidf\n",
    "TextSummarizerTFIDFTextRank.build_tfidf_matrix = build_tfidf_matrix\n",
    "\n",
    "print(\"Đã thêm các phương thức tính TF-IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "188d3623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xây dựng ma trận TF-IDF...\n",
      "Đang xây dựng từ vựng...\n",
      "Tổng từ vựng: 1039 từ\n",
      "Tổng từ (có lặp): 3597 từ\n",
      "✓ Ma trận TF-IDF: (201, 1039) (câu × từ vựng)\n",
      "\n",
      "DEMO: Minh họa cách tính TF-IDF\n",
      "==================================================\n",
      "Câu demo: 'Hurricane Gilbert swept toward the Dominican Republic Sunday, and the Civil Defense alerted its heav...'\n",
      "Từ demo: 'hurricane'\n",
      "\n",
      "1. TF (Term Frequency):\n",
      "   Số lần xuất hiện: 1\n",
      "   Tổng số từ: 27\n",
      "   TF = 1 / 27 = 0.037037\n",
      "\n",
      "2. IDF (Inverse Document Frequency):\n",
      "   Tổng số câu: 201\n",
      "   Số câu chứa 'hurricane': 56\n",
      "   IDF = log(201 / 56) = 1.277953\n",
      "\n",
      "3. TF-IDF:\n",
      "   TF-IDF = 0.037037 × 1.277953 = 0.047332\n",
      "\n",
      "Bước 2 hoàn thành: Đã tạo ma trận TF-IDF (201, 1039)\n"
     ]
    }
   ],
   "source": [
    "# Demo: Xây dựng ma trận TF-IDF\n",
    "if summarizer.sentences:\n",
    "    # Xây dựng ma trận TF-IDF\n",
    "    tfidf_matrix, vocab_list = summarizer.build_tfidf_matrix()\n",
    "    \n",
    "    # Demo: Hiển thị cách tính TF-IDF cho một từ cụ thể\n",
    "    print(\"\\nDEMO: Minh họa cách tính TF-IDF\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Chọn câu đầu tiên và từ phổ biến\n",
    "    demo_sentence = summarizer.sentences[0]\n",
    "    demo_words = demo_sentence['processed'].split()\n",
    "    demo_words = [word for word in demo_words if len(word) >= 3]\n",
    "    \n",
    "    if demo_words:\n",
    "        demo_word = demo_words[0]  # Chọn từ đầu tiên\n",
    "        \n",
    "        print(f\"Câu demo: '{demo_sentence['original'][:100]}...'\")\n",
    "        print(f\"Từ demo: '{demo_word}'\")\n",
    "        \n",
    "        # Tính từng bước\n",
    "        tf = summarizer.calculate_tf(demo_word, demo_words)\n",
    "        idf = summarizer.calculate_idf(demo_word)\n",
    "        tfidf = summarizer.calculate_tfidf(demo_word, demo_words)\n",
    "        \n",
    "        print(f\"\\n1. TF (Term Frequency):\")\n",
    "        print(f\"   Số lần xuất hiện: {demo_words.count(demo_word)}\")\n",
    "        print(f\"   Tổng số từ: {len(demo_words)}\")\n",
    "        print(f\"   TF = {demo_words.count(demo_word)} / {len(demo_words)} = {tf:.6f}\")\n",
    "        \n",
    "        print(f\"\\n2. IDF (Inverse Document Frequency):\")\n",
    "        print(f\"   Tổng số câu: {len(summarizer.sentences)}\")\n",
    "        print(f\"   Số câu chứa '{demo_word}': {summarizer.word_doc_count[demo_word]}\")\n",
    "        print(f\"   IDF = log({len(summarizer.sentences)} / {summarizer.word_doc_count[demo_word]}) = {idf:.6f}\")\n",
    "        \n",
    "        print(f\"\\n3. TF-IDF:\")\n",
    "        print(f\"   TF-IDF = {tf:.6f} × {idf:.6f} = {tfidf:.6f}\")\n",
    "    \n",
    "    print(f\"\\nBước 2 hoàn thành: Đã tạo ma trận TF-IDF {tfidf_matrix.shape}\")\n",
    "else:\n",
    "    print(\"Chưa có dữ liệu câu để xử lý\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d03573",
   "metadata": {},
   "source": [
    "## 4. Bước 3: Tính Độ Tương Đồng Cosine\n",
    "\n",
    "**Công thức Cosine Similarity:**\n",
    "\n",
    "- **cosine_similarity(A, B)** = (A · B) / (|A| × |B|)\n",
    "- **A · B** = tích vô hướng của hai vector\n",
    "- **|A|** = độ dài (magnitude) của vector A = √(Σ(ai²))\n",
    "- **|B|** = độ dài (magnitude) của vector B = √(Σ(bi²))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a7ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Đã thêm các phương thức tính Cosine Similarity\n"
     ]
    }
   ],
   "source": [
    "def calculate_cosine_similarity(self, vector1, vector2):\n",
    "    \"\"\"\n",
    "    Tính cosine similarity giữa hai vector - viết tay công thức\n",
    "    cosine_similarity = (A · B) / (|A| × |B|)\n",
    "    \"\"\"\n",
    "    # Tính tích vô hướng (dot product)\n",
    "    dot_product = 0\n",
    "    for i in range(len(vector1)):\n",
    "        dot_product += vector1[i] * vector2[i]\n",
    "    \n",
    "    # Tính độ dài của vector A\n",
    "    magnitude_a = 0\n",
    "    for val in vector1:\n",
    "        magnitude_a += val * val\n",
    "    magnitude_a = math.sqrt(magnitude_a)\n",
    "    \n",
    "    # Tính độ dài của vector B  \n",
    "    magnitude_b = 0\n",
    "    for val in vector2:\n",
    "        magnitude_b += val * val\n",
    "    magnitude_b = math.sqrt(magnitude_b)\n",
    "    \n",
    "    # Tránh chia cho 0\n",
    "    if magnitude_a == 0 or magnitude_b == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Tính cosine similarity\n",
    "    cosine_sim = dot_product / (magnitude_a * magnitude_b)\n",
    "    return cosine_sim\n",
    "\n",
    "def build_cosine_matrix(self):\n",
    "    \"\"\"\n",
    "    Xây dựng ma trận cosine similarity giữa tất cả các câu\n",
    "    \"\"\"\n",
    "    print(\"Đang xây dựng ma trận cosine similarity...\")\n",
    "    \n",
    "    if self.tfidf_matrix is None:\n",
    "        print(\"Chưa có ma trận TF-IDF. Hãy chạy build_tfidf_matrix() trước.\")\n",
    "        return None\n",
    "    \n",
    "    num_sentences = self.tfidf_matrix.shape[0]\n",
    "    self.cosine_matrix = np.zeros((num_sentences, num_sentences))\n",
    "    \n",
    "    # Tính cosine similarity cho mỗi cặp câu\n",
    "    for i in range(num_sentences):\n",
    "        for j in range(num_sentences):\n",
    "            if i == j:\n",
    "                self.cosine_matrix[i, j] = 1.0  # Similarity với chính nó = 1\n",
    "            else:\n",
    "                similarity = self.calculate_cosine_similarity(\n",
    "                    self.tfidf_matrix[i], \n",
    "                    self.tfidf_matrix[j]\n",
    "                )\n",
    "                self.cosine_matrix[i, j] = similarity\n",
    "    \n",
    "    print(f\"✓ Ma trận cosine similarity: {self.cosine_matrix.shape}\")\n",
    "    return self.cosine_matrix\n",
    "\n",
    "def demonstrate_cosine_calculation(self, sent1_idx=0, sent2_idx=1):\n",
    "    \"\"\"\n",
    "    Minh họa chi tiết cách tính cosine similarity\n",
    "    \"\"\"\n",
    "    if self.tfidf_matrix is None or len(self.sentences) < 2:\n",
    "        print(\"Không đủ dữ liệu để minh họa\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nDEMO: Minh họa cách tính Cosine Similarity\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Lấy hai vector\n",
    "    vector1 = self.tfidf_matrix[sent1_idx]\n",
    "    vector2 = self.tfidf_matrix[sent2_idx]\n",
    "    \n",
    "    print(f\"Câu 1: '{self.sentences[sent1_idx]['original'][:80]}...'\")\n",
    "    print(f\"Câu 2: '{self.sentences[sent2_idx]['original'][:80]}...'\")\n",
    "    \n",
    "    # Tính từng bước\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    magnitude_a = np.linalg.norm(vector1)\n",
    "    magnitude_b = np.linalg.norm(vector2)\n",
    "    \n",
    "    print(f\"\\n1. Tích vô hướng (A · B):\")\n",
    "    print(f\"   dot_product = Σ(ai × bi) = {dot_product:.6f}\")\n",
    "    \n",
    "    print(f\"\\n2. Độ dài vector:\")\n",
    "    print(f\"   |A| = √(Σ(ai²)) = {magnitude_a:.6f}\")\n",
    "    print(f\"   |B| = √(Σ(bi²)) = {magnitude_b:.6f}\")\n",
    "    \n",
    "    if magnitude_a > 0 and magnitude_b > 0:\n",
    "        cosine_sim = dot_product / (magnitude_a * magnitude_b)\n",
    "        print(f\"\\n3. Cosine Similarity:\")\n",
    "        print(f\"   cosine_sim = {dot_product:.6f} / ({magnitude_a:.6f} × {magnitude_b:.6f})\")\n",
    "        print(f\"   cosine_sim = {cosine_sim:.6f}\")\n",
    "        \n",
    "        # Giải thích ý nghĩa\n",
    "        if cosine_sim > 0.8:\n",
    "            interpretation = \"rất tương tự\"\n",
    "        elif cosine_sim > 0.5:\n",
    "            interpretation = \"tương tự\"\n",
    "        elif cosine_sim > 0.3:\n",
    "            interpretation = \"hơi tương tự\"\n",
    "        else:\n",
    "            interpretation = \"không tương tự\"\n",
    "        print(f\"   → Hai câu {interpretation}\")\n",
    "    else:\n",
    "        print(\"\\nMột trong hai vector có độ dài = 0\")\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.calculate_cosine_similarity = calculate_cosine_similarity\n",
    "TextSummarizerTFIDFTextRank.build_cosine_matrix = build_cosine_matrix\n",
    "TextSummarizerTFIDFTextRank.demonstrate_cosine_calculation = demonstrate_cosine_calculation\n",
    "\n",
    "print(\"Đã thêm các phương thức tính Cosine Similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ee630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Xây dựng ma trận cosine similarity\n",
    "if summarizer.tfidf_matrix is not None:\n",
    "    # Xây dựng ma trận cosine\n",
    "    cosine_matrix = summarizer.build_cosine_matrix()\n",
    "    \n",
    "    # Minh họa cách tính cosine similarity\n",
    "    if len(summarizer.sentences) >= 2:\n",
    "        summarizer.demonstrate_cosine_calculation(0, 1)\n",
    "    \n",
    "    # Hiển thị thống kê ma trận cosine\n",
    "    print(f\"\\nThống kê ma trận Cosine Similarity:\")\n",
    "    print(f\"   - Kích thước: {cosine_matrix.shape}\")\n",
    "    print(f\"   - Giá trị trung bình: {np.mean(cosine_matrix):.4f}\")\n",
    "    print(f\"   - Giá trị max (không tính đường chéo): {np.max(cosine_matrix - np.eye(len(cosine_matrix))):.4f}\")\n",
    "    print(f\"   - Giá trị min: {np.min(cosine_matrix):.4f}\")\n",
    "    \n",
    "    # Hiển thị ma trận 5x5 đầu tiên\n",
    "    display_size = min(5, len(summarizer.sentences))\n",
    "    print(f\"\\nMa trận Cosine Similarity ({display_size}x{display_size} đầu tiên):\")\n",
    "    print(\"      \", end=\"\")\n",
    "    for j in range(display_size):\n",
    "        print(f\"S{j:<8}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for i in range(display_size):\n",
    "        print(f\"S{i:<4} \", end=\"\")\n",
    "        for j in range(display_size):\n",
    "            print(f\"{cosine_matrix[i,j]:<8.3f}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"\\nBước 3 hoàn thành: Đã tạo ma trận cosine similarity\")\n",
    "else:\n",
    "    print(\"Chưa có ma trận TF-IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff03d8",
   "metadata": {},
   "source": [
    "## 5. Bước 4: Mô Hình Hóa Đồ Thị\n",
    "\n",
    "Mô hình hóa văn bản dưới dạng đồ thị:\n",
    "\n",
    "- **Đỉnh (Vertices)**: Mỗi câu là một đỉnh\n",
    "- **Cạnh (Edges)**: Trọng số cosine similarity giữa các câu\n",
    "- **Ngưỡng (Threshold)**: Chỉ tạo cạnh khi similarity > threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adjacency_matrix(self, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Tạo ma trận kề từ ma trận cosine similarity\n",
    "    Nếu similarity > threshold thì có cạnh (giá trị = 1)\n",
    "    \"\"\"\n",
    "    print(f\"Đang tạo đồ thị với ngưỡng similarity: {threshold}\")\n",
    "    \n",
    "    if self.cosine_matrix is None:\n",
    "        print(\"Chưa có ma trận cosine similarity\")\n",
    "        return None\n",
    "    \n",
    "    n = self.cosine_matrix.shape[0]\n",
    "    self.adjacency_matrix = np.zeros((n, n))\n",
    "    \n",
    "    # Tạo cạnh dựa trên ngưỡng similarity\n",
    "    edge_count = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j and self.cosine_matrix[i, j] > threshold:\n",
    "                self.adjacency_matrix[i, j] = 1\n",
    "                edge_count += 1\n",
    "    \n",
    "    print(f\"Đã tạo {edge_count} cạnh trong đồ thị\")\n",
    "    print(f\"Ma trận kề: {self.adjacency_matrix.shape}\")\n",
    "    \n",
    "    return self.adjacency_matrix\n",
    "\n",
    "def create_transition_matrix(self):\n",
    "    \"\"\"\n",
    "    Tạo ma trận chuyển tiếp cho TextRank\n",
    "    Mỗi hàng được chuẩn hóa sao cho tổng = 1\n",
    "    \"\"\"\n",
    "    print(\"Đang tạo ma trận chuyển tiếp...\")\n",
    "    \n",
    "    if self.adjacency_matrix is None:\n",
    "        print(\"Chưa có ma trận kề\")\n",
    "        return None\n",
    "    \n",
    "    n = self.adjacency_matrix.shape[0]\n",
    "    self.transition_matrix = np.copy(self.adjacency_matrix).astype(float)\n",
    "    \n",
    "    # Chuẩn hóa từng hàng\n",
    "    for i in range(n):\n",
    "        row_sum = np.sum(self.transition_matrix[i])\n",
    "        if row_sum > 0:\n",
    "            # Có cạnh ra → chuẩn hóa\n",
    "            self.transition_matrix[i] = self.transition_matrix[i] / row_sum\n",
    "        else:\n",
    "            # Không có cạnh ra → phân bố đều cho tất cả đỉnh\n",
    "            self.transition_matrix[i] = np.ones(n) / n\n",
    "    \n",
    "    print(f\"Ma trận chuyển tiếp: {self.transition_matrix.shape}\")\n",
    "    \n",
    "    # Kiểm tra tính chuẩn hóa\n",
    "    row_sums = np.sum(self.transition_matrix, axis=1)\n",
    "    print(f\"Kiểm tra chuẩn hóa: tổng hàng = {row_sums[0]:.6f} (should be 1.0)\")\n",
    "    \n",
    "    return self.transition_matrix\n",
    "\n",
    "def visualize_graph_info(self):\n",
    "    \"\"\"\n",
    "    Hiển thị thông tin về đồ thị\n",
    "    \"\"\"\n",
    "    if self.adjacency_matrix is None:\n",
    "        print(\"Chưa có ma trận kề\")\n",
    "        return\n",
    "    \n",
    "    n = len(self.sentences)\n",
    "    total_edges = np.sum(self.adjacency_matrix)\n",
    "    \n",
    "    print(f\"\\nThông tin đồ thị:\")\n",
    "    print(f\"   - Số đỉnh (câu): {n}\")\n",
    "    print(f\"   - Số cạnh: {int(total_edges)}\")\n",
    "    print(f\"   - Mật độ: {total_edges / (n * (n-1)):.4f}\")\n",
    "    \n",
    "    # Hiển thị degree của từng đỉnh\n",
    "    in_degrees = np.sum(self.adjacency_matrix, axis=0)  # Số cạnh vào\n",
    "    out_degrees = np.sum(self.adjacency_matrix, axis=1)  # Số cạnh ra\n",
    "    \n",
    "    print(f\"\\nThống kê degree:\")\n",
    "    print(f\"   - In-degree trung bình: {np.mean(in_degrees):.2f}\")\n",
    "    print(f\"   - Out-degree trung bình: {np.mean(out_degrees):.2f}\")\n",
    "    print(f\"   - Max in-degree: {int(np.max(in_degrees))}\")\n",
    "    print(f\"   - Max out-degree: {int(np.max(out_degrees))}\")\n",
    "    \n",
    "    # Hiển thị một vài câu có degree cao nhất\n",
    "    high_degree_indices = np.argsort(in_degrees)[-3:][::-1]\n",
    "    print(f\"\\nTop 3 câu có nhiều liên kết nhất:\")\n",
    "    for i, idx in enumerate(high_degree_indices, 1):\n",
    "        sentence_preview = self.sentences[idx]['original'][:60]\n",
    "        print(f\"   {i}. Câu {idx}: degree={int(in_degrees[idx])} - '{sentence_preview}...'\")\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.create_adjacency_matrix = create_adjacency_matrix\n",
    "TextSummarizerTFIDFTextRank.create_transition_matrix = create_transition_matrix\n",
    "TextSummarizerTFIDFTextRank.visualize_graph_info = visualize_graph_info\n",
    "\n",
    "print(\"Đã thêm các phương thức mô hình hóa đồ thị\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a66df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Tạo đồ thị từ ma trận cosine similarity\n",
    "if summarizer.cosine_matrix is not None:\n",
    "    # Tạo ma trận kề với ngưỡng phù hợp\n",
    "    threshold = 0.1  # Có thể điều chỉnh\n",
    "    adjacency_matrix = summarizer.create_adjacency_matrix(threshold)\n",
    "    \n",
    "    # Tạo ma trận chuyển tiếp\n",
    "    transition_matrix = summarizer.create_transition_matrix()\n",
    "    \n",
    "    # Hiển thị thông tin đồ thị\n",
    "    summarizer.visualize_graph_info()\n",
    "    \n",
    "    # Hiển thị ma trận kề (5x5 đầu tiên)\n",
    "    display_size = min(5, len(summarizer.sentences))\n",
    "    print(f\"\\nMa trận kề ({display_size}x{display_size} đầu tiên):\")\n",
    "    print(\"      \", end=\"\")\n",
    "    for j in range(display_size):\n",
    "        print(f\"S{j:<4}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for i in range(display_size):\n",
    "        print(f\"S{i:<4} \", end=\"\")\n",
    "        for j in range(display_size):\n",
    "            print(f\"{int(adjacency_matrix[i,j]):<4}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"\\nBước 4 hoàn thành: Đã mô hình hóa văn bản thành đồ thị\")\n",
    "else:\n",
    "    print(\"Chưa có ma trận cosine similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6ee64e",
   "metadata": {},
   "source": [
    "## 6. Bước 5: Thuật Toán TextRank\n",
    "\n",
    "**Công thức TextRank (dựa trên PageRank):**\n",
    "\n",
    "**TR(Vi) = (1-d) + d × Σ(TR(Vj)/C(Vj))**\n",
    "\n",
    "Trong đó:\n",
    "\n",
    "- **TR(Vi)**: Điểm TextRank của câu Vi\n",
    "- **d**: Damping factor (thường = 0.85)\n",
    "- **Vj**: Các câu có liên kết đến Vi\n",
    "- **C(Vj)**: Số liên kết ra từ câu Vj\n",
    "\n",
    "**Phương pháp Power Iteration:**\n",
    "\n",
    "- Khởi tạo: TR₀ = [1/N, 1/N, ..., 1/N]\n",
    "- Lặp: TR\\_{k+1} = (1-d)/N + d × M^T × TR_k\n",
    "- Dừng khi: ||TR\\_{k+1} - TR_k|| < tolerance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f39065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_textrank(self):\n",
    "    \"\"\"\n",
    "    Tính TextRank bằng Power Iteration \n",
    "    \"\"\"\n",
    "    print(\"Đang tính TextRank bằng Power Iteration...\")\n",
    "    \n",
    "    if self.transition_matrix is None:\n",
    "        print(\"Chưa có ma trận chuyển tiếp\")\n",
    "        return None\n",
    "    \n",
    "    n = self.transition_matrix.shape[0]\n",
    "    \n",
    "    # Khởi tạo vector TextRank (phân bố đều)\n",
    "    textrank_vector = np.ones(n) / n\n",
    "    print(f\"Khởi tạo: TR₀ = [1/{n}, 1/{n}, ..., 1/{n}] = {1/n:.6f}\")\n",
    "    \n",
    "    print(f\"\\nCông thức TextRank:\")\n",
    "    print(f\"   TR_new = (1-d)/N + d × M^T × TR_old\")\n",
    "    print(f\"   Với d = {self.damping_factor}, N = {n}\")\n",
    "    print(f\"   Teleport term = (1-d)/N = {(1-self.damping_factor)/n:.6f}\")\n",
    "    \n",
    "    # Lưu lịch sử hội tụ\n",
    "    history = []\n",
    "    \n",
    "    print(f\"\\nQuá trình lặp:\")\n",
    "    print(f\"{'Vòng':<6} {'Thay đổi':<15} {'Top 3 điểm':<25}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for iteration in range(self.max_iterations):\n",
    "        # Lưu vector cũ\n",
    "        old_textrank = np.copy(textrank_vector)\n",
    "        \n",
    "        # Áp dụng công thức TextRank\n",
    "        # TR = (1-d)/N + d * M^T * TR_old\n",
    "        teleport_term = (1 - self.damping_factor) / n\n",
    "        random_walk_term = self.damping_factor * np.dot(self.transition_matrix.T, textrank_vector)\n",
    "        textrank_vector = teleport_term + random_walk_term\n",
    "        \n",
    "        # Tính sự thay đổi (norm L2)\n",
    "        change = 0\n",
    "        for i in range(len(textrank_vector)):\n",
    "            diff = textrank_vector[i] - old_textrank[i]\n",
    "            change += diff * diff\n",
    "        change = math.sqrt(change)\n",
    "        \n",
    "        # Lưu lịch sử\n",
    "        history.append((iteration + 1, change, np.copy(textrank_vector)))\n",
    "        \n",
    "        # Hiển thị top 3 điểm cao nhất\n",
    "        top_indices = np.argsort(textrank_vector)[-3:][::-1]\n",
    "        top_scores = [f\"{textrank_vector[i]:.4f}\" for i in top_indices]\n",
    "        top_info = \", \".join(top_scores)\n",
    "        \n",
    "        print(f\"{iteration+1:<6} {change:<15.8f} {top_info:<25}\")\n",
    "        \n",
    "        # Kiểm tra hội tụ\n",
    "        if change < self.tolerance:\n",
    "            print(f\"\\nHội tụ sau {iteration + 1} vòng lặp!\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"\\nĐạt giới hạn {self.max_iterations} vòng lặp\")\n",
    "    \n",
    "    self.textrank_scores = textrank_vector\n",
    "    \n",
    "    return textrank_vector, history\n",
    "\n",
    "def demonstrate_textrank_calculation(self, sentence_idx=0):\n",
    "    \"\"\"\n",
    "    Minh họa chi tiết cách tính TextRank cho một câu cụ thể\n",
    "    \"\"\"\n",
    "    if self.textrank_scores is None or self.adjacency_matrix is None:\n",
    "        print(\"Chưa tính TextRank\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nDEMO: Minh họa cách tính TextRank cho câu {sentence_idx}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    sentence = self.sentences[sentence_idx]['original'][:80]\n",
    "    print(f\"Câu: '{sentence}...'\")\n",
    "    \n",
    "    n = len(self.sentences)\n",
    "    \n",
    "    # Tìm các câu liên kết đến câu này\n",
    "    incoming_links = []\n",
    "    for i in range(n):\n",
    "        if self.adjacency_matrix[i, sentence_idx] == 1:\n",
    "            incoming_links.append(i)\n",
    "    \n",
    "    print(f\"\\n1. CÁC CÂU LIÊN KẾT ĐẾN:\")\n",
    "    if incoming_links:\n",
    "        for link_idx in incoming_links:\n",
    "            link_sentence = self.sentences[link_idx]['original'][:50]\n",
    "            outgoing_count = np.sum(self.adjacency_matrix[link_idx])\n",
    "            print(f\"   - Câu {link_idx}: '{link_sentence}...' (có {int(outgoing_count)} liên kết ra)\")\n",
    "    else:\n",
    "        print(\"   - Không có liên kết đến\")\n",
    "    \n",
    "    print(f\"\\n2. CÔNG THỨC TEXTRANK:\")\n",
    "    print(f\"   TR(S{sentence_idx}) = (1-d)/N + d × Σ(TR(Si)/C(Si))\")\n",
    "    \n",
    "    # Tính từng thành phần\n",
    "    teleport_term = (1 - self.damping_factor) / n\n",
    "    print(f\"\\n3. TÍNH TOÁN CHI TIẾT:\")\n",
    "    print(f\"   a) Teleport term = (1-d)/N = (1-{self.damping_factor})/{n} = {teleport_term:.6f}\")\n",
    "    \n",
    "    link_contribution = 0\n",
    "    print(f\"   b) Link contribution:\")\n",
    "    if incoming_links:\n",
    "        for link_idx in incoming_links:\n",
    "            tr_link = self.textrank_scores[link_idx]\n",
    "            outgoing_count = np.sum(self.adjacency_matrix[link_idx])\n",
    "            contribution = tr_link / outgoing_count if outgoing_count > 0 else 0\n",
    "            link_contribution += contribution\n",
    "            print(f\"      - Từ câu {link_idx}: TR = {tr_link:.6f}, \"\n",
    "                  f\"C = {int(outgoing_count)}, \"\n",
    "                  f\"Contribution = {tr_link:.6f}/{int(outgoing_count)} = {contribution:.6f}\")\n",
    "        \n",
    "        print(f\"      Tổng link contribution = {link_contribution:.6f}\")\n",
    "    else:\n",
    "        print(f\"      Không có liên kết → contribution = 0\")\n",
    "    \n",
    "    final_textrank = teleport_term + self.damping_factor * link_contribution\n",
    "    actual_textrank = self.textrank_scores[sentence_idx]\n",
    "    \n",
    "    print(f\"\\n4. KẾT QUẢ CUỐI CÙNG:\")\n",
    "    print(f\"   TR(S{sentence_idx}) = {teleport_term:.6f} + {self.damping_factor} × {link_contribution:.6f}\")\n",
    "    print(f\"   TR(S{sentence_idx}) = {teleport_term:.6f} + {self.damping_factor * link_contribution:.6f}\")\n",
    "    print(f\"   TR(S{sentence_idx}) = {final_textrank:.6f}\")\n",
    "    print(f\"   TextRank thực tế: {actual_textrank:.6f}\")\n",
    "    print(f\"   Sai số: {abs(final_textrank - actual_textrank):.8f}\")\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.calculate_textrank = calculate_textrank\n",
    "TextSummarizerTFIDFTextRank.demonstrate_textrank_calculation = demonstrate_textrank_calculation\n",
    "\n",
    "print(\"Đã thêm thuật toán TextRank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f268b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Tính TextRank\n",
    "if summarizer.transition_matrix is not None:\n",
    "    # Tính TextRank\n",
    "    textrank_scores, history = summarizer.calculate_textrank()\n",
    "    \n",
    "    # Minh họa cách tính cho một câu\n",
    "    if len(summarizer.sentences) > 0:\n",
    "        summarizer.demonstrate_textrank_calculation(0)\n",
    "    \n",
    "    # Hiển thị kết quả TextRank\n",
    "    print(f\"\\nKẾT QUẢ TEXTRANK:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Tạo danh sách kết quả\n",
    "    results = []\n",
    "    for i, score in enumerate(textrank_scores):\n",
    "        results.append({\n",
    "            'index': i,\n",
    "            'score': score,\n",
    "            'sentence': summarizer.sentences[i]['original']\n",
    "        })\n",
    "    \n",
    "    # Sắp xếp theo điểm giảm dần\n",
    "    results.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    print(f\"{'Hạng':<6} {'Điểm TR':<12} {'Câu':<60}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Hiển thị top 10\n",
    "    for rank, result in enumerate(results[:10], 1):\n",
    "        sentence_preview = result['sentence'][:55]\n",
    "        print(f\"{rank:<6} {result['score']:<12.6f} {sentence_preview}...\")\n",
    "    \n",
    "    # Thống kê\n",
    "    print(f\"\\nThống kê TextRank:\")\n",
    "    print(f\"   - Tổng điểm: {np.sum(textrank_scores):.6f}\")\n",
    "    print(f\"   - Điểm trung bình: {np.mean(textrank_scores):.6f}\")\n",
    "    print(f\"   - Độ lệch chuẩn: {np.std(textrank_scores):.6f}\")\n",
    "    print(f\"   - Điểm cao nhất: {np.max(textrank_scores):.6f}\")\n",
    "    print(f\"   - Điểm thấp nhất: {np.min(textrank_scores):.6f}\")\n",
    "    \n",
    "    print(f\"\\nBước 5 hoàn thành: Đã tính TextRank cho {len(textrank_scores)} câu\")\n",
    "else:\n",
    "    print(\"Chưa có ma trận chuyển tiếp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a03746",
   "metadata": {},
   "source": [
    "## 7. Bước 6: Tạo Bản Tóm Tắt (Lấy 10% Câu Quan Trọng Nhất)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd02d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(self, summary_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Tạo bản tóm tắt bằng cách chọn top câu có điểm TextRank cao nhất\n",
    "    \"\"\"\n",
    "    print(f\"Đang tạo bản tóm tắt với tỷ lệ {summary_ratio*100}%...\")\n",
    "    \n",
    "    if self.textrank_scores is None:\n",
    "        print(\"Chưa tính TextRank\")\n",
    "        return None\n",
    "    \n",
    "    total_sentences = len(self.sentences)\n",
    "    num_summary_sentences = max(1, int(total_sentences * summary_ratio))\n",
    "    \n",
    "    print(f\"Chọn {num_summary_sentences} câu từ {total_sentences} câu gốc\")\n",
    "    \n",
    "    # Tạo danh sách câu với điểm số và vị trí gốc\n",
    "    sentence_scores = []\n",
    "    for i, score in enumerate(self.textrank_scores):\n",
    "        sentence_scores.append({\n",
    "            'index': i,\n",
    "            'score': score,\n",
    "            'sentence': self.sentences[i]['original']\n",
    "        })\n",
    "    \n",
    "    # Sắp xếp theo điểm TextRank giảm dần\n",
    "    sentence_scores.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # Chọn top câu\n",
    "    selected_sentences = sentence_scores[:num_summary_sentences]\n",
    "    \n",
    "    # Sắp xếp lại theo thứ tự xuất hiện trong văn bản gốc\n",
    "    selected_sentences.sort(key=lambda x: x['index'])\n",
    "    \n",
    "    # Tạo văn bản tóm tắt\n",
    "    summary_text = []\n",
    "    for item in selected_sentences:\n",
    "        summary_text.append(item['sentence'])\n",
    "    \n",
    "    summary = {\n",
    "        'sentences': selected_sentences,\n",
    "        'text': ' '.join(summary_text),\n",
    "        'ratio': summary_ratio,\n",
    "        'original_count': total_sentences,\n",
    "        'summary_count': num_summary_sentences\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def display_summary(self, summary):\n",
    "    \"\"\"\n",
    "    Hiển thị bản tóm tắt\n",
    "    \"\"\"\n",
    "    if summary is None:\n",
    "        print(\"Không có bản tóm tắt\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nBẢN TÓM TẮT:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Tỷ lệ: {summary['ratio']*100}% ({summary['summary_count']}/{summary['original_count']} câu)\")\n",
    "    print(f\"Độ dài: {len(summary['text'])} ký tự\")\n",
    "    print()\n",
    "    \n",
    "    # Hiển thị từng câu được chọn\n",
    "    print(\"Các câu được chọn:\")\n",
    "    for i, item in enumerate(summary['sentences'], 1):\n",
    "        print(f\"{i}. [Câu {item['index']}, Điểm: {item['score']:.4f}]\")\n",
    "        print(f\"   {item['sentence']}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"Văn bản tóm tắt liên tục:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(summary['text'])\n",
    "\n",
    "# Thêm methods vào class\n",
    "TextSummarizerTFIDFTextRank.generate_summary = generate_summary\n",
    "TextSummarizerTFIDFTextRank.display_summary = display_summary\n",
    "\n",
    "print(\"✓ Đã thêm các phương thức tạo tóm tắt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837fc6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Tạo bản tóm tắt và lưu vào Word\n",
    "if summarizer.textrank_scores is not None:\n",
    "    # Tạo tóm tắt với 10% câu\n",
    "    summary = summarizer.generate_summary(summary_ratio=0.1)\n",
    "    \n",
    "    # Hiển thị tóm tắt\n",
    "    summarizer.display_summary(summary)\n",
    "    \n",
    "    # Lưu tóm tắt vào file Word (output_summary.docx)\n",
    "    if summary:\n",
    "        output_filename = os.path.join(BASE_PATH, \"output_summary.docx\")\n",
    "        \n",
    "        # Tạo document Word với format đẹp\n",
    "        doc = Document()\n",
    "        doc.add_heading('BẢN TÓM TẮT VĂN BẢN BẰNG TEXTRANK', 0)\n",
    "        \n",
    "        # Thông tin tóm tắt\n",
    "        doc.add_heading('Thông tin tóm tắt:', level=1)\n",
    "        info_para = doc.add_paragraph()\n",
    "        info_para.add_run(f\"• Tỷ lệ tóm tắt: {summary['ratio']*100}%\\n\")\n",
    "        info_para.add_run(f\"• Số câu gốc: {summary['original_count']}\\n\")\n",
    "        info_para.add_run(f\"• Số câu tóm tắt: {summary['summary_count']}\\n\")\n",
    "        info_para.add_run(f\"• Độ dài: {len(summary['text'])} ký tự\\n\")\n",
    "        \n",
    "        # Văn bản tóm tắt\n",
    "        doc.add_heading('Văn bản tóm tắt:', level=1)\n",
    "        doc.add_paragraph(summary['text'])\n",
    "        \n",
    "        # Chi tiết các câu được chọn\n",
    "        doc.add_heading('Chi tiết các câu được chọn:', level=1)\n",
    "        for i, item in enumerate(summary['sentences'], 1):\n",
    "            para = doc.add_paragraph()\n",
    "            para.add_run(f\"{i}. \").bold = True\n",
    "            para.add_run(f\"[Câu {item['index']}, Điểm TextRank: {item['score']:.4f}]\\n\")\n",
    "            para.add_run(item['sentence'])\n",
    "        \n",
    "        doc.save(output_filename)\n",
    "        print(f\"\\nĐã lưu bản tóm tắt vào: {output_filename}\")\n",
    "        \n",
    "        print(f\"\\nBước 6-7 hoàn thành: Đã tạo và lưu bản tóm tắt\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Không thể tạo tóm tắt\")\n",
    "        \n",
    "else:\n",
    "    print(\"Chưa tính TextRank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d8fe4",
   "metadata": {},
   "source": [
    "## 8. Bước 8: Đọc DUC Reference Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a3b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 8: Đọc DUC reference summary tương ứng\n",
    "def load_duc_reference(doc_filename):\n",
    "    \"\"\"\n",
    "    Đọc file DUC reference summary tương ứng với tài liệu\n",
    "    \"\"\"\n",
    "    print(f\"Đang tìm DUC reference cho: {doc_filename}\")\n",
    "    \n",
    "    # Tìm file reference tương ứng\n",
    "    reference_path = os.path.join(DUC_SUM_PATH, doc_filename)\n",
    "    \n",
    "    if os.path.exists(reference_path):\n",
    "        try:\n",
    "            with open(reference_path, 'r', encoding='utf-8') as f:\n",
    "                reference_content = f.read()\n",
    "            \n",
    "            # Làm sạch nội dung reference\n",
    "            reference_content = re.sub(r'<[^>]+>', '', reference_content)\n",
    "            reference_content = reference_content.strip()\n",
    "            \n",
    "            print(f\"✓ Đã đọc reference: {len(reference_content)} ký tự\")\n",
    "            print(f\"✓ Preview: {reference_content[:100]}...\")\n",
    "            \n",
    "            return reference_content\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc reference: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Không tìm thấy file reference: {reference_path}\")\n",
    "        return None\n",
    "\n",
    "# Demo: Đọc DUC reference và lưu vào Word\n",
    "if os.path.exists(DUC_TEXT_PATH):\n",
    "    files = [f for f in os.listdir(DUC_TEXT_PATH) if not f.startswith('.')]\n",
    "    if files and 'demo_file' in locals():\n",
    "        # Sử dụng cùng file đã chọn ở bước 1\n",
    "        \n",
    "        # Đọc reference\n",
    "        reference_content = load_duc_reference(demo_file)\n",
    "        \n",
    "        if reference_content:\n",
    "            # Lưu reference vào file Word (Test_DUC_SUM.docx)\n",
    "            reference_filename = os.path.join(BASE_PATH, \"Test_DUC_SUM.docx\")\n",
    "            \n",
    "            doc = Document()\n",
    "            doc.add_heading('DUC REFERENCE SUMMARY', 0)\n",
    "            \n",
    "            # Thông tin file\n",
    "            doc.add_heading('Thông tin:', level=1)\n",
    "            info_para = doc.add_paragraph()\n",
    "            info_para.add_run(f\"• File gốc: {demo_file}\\n\")\n",
    "            info_para.add_run(f\"• Đường dẫn reference: {os.path.join(DUC_SUM_PATH, demo_file)}\\n\")\n",
    "            info_para.add_run(f\"• Độ dài: {len(reference_content)} ký tự\\n\")\n",
    "            \n",
    "            # Nội dung reference\n",
    "            doc.add_heading('Nội dung reference summary:', level=1)\n",
    "            doc.add_paragraph(reference_content)\n",
    "            \n",
    "            doc.save(reference_filename)\n",
    "            print(f\"Đã lưu DUC reference vào: {reference_filename}\")\n",
    "            \n",
    "            # Lưu vào biến để sử dụng trong evaluation\n",
    "            duc_reference = reference_content\n",
    "            \n",
    "            print(f\"\\nBước 8 hoàn thành: Đã đọc và lưu DUC reference summary\")\n",
    "        else:\n",
    "            duc_reference = None\n",
    "            print(\"Không thể đọc DUC reference\")\n",
    "    else:\n",
    "        print(\"Không có file để xử lý\")\n",
    "        duc_reference = None\n",
    "else:\n",
    "    print(f\"Thư mục không tồn tại: {DUC_TEXT_PATH}\")\n",
    "    duc_reference = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8d9ca",
   "metadata": {},
   "source": [
    "## 9. Bước 9: Đánh Giá Bằng ROUGE Metrics\n",
    "\n",
    "**ROUGE (Recall-Oriented Understudy for Gisting Evaluation):**\n",
    "\n",
    "- **ROUGE-1**: Đo overlap của unigrams (từ đơn)\n",
    "- **ROUGE-2**: Đo overlap của bigrams (cặp từ)\n",
    "- **ROUGE-L**: Đo Longest Common Subsequence (LCS)\n",
    "\n",
    "**Công thức:**\n",
    "\n",
    "- **Precision** = (số từ chung) / (số từ trong summary)\n",
    "- **Recall** = (số từ chung) / (số từ trong reference)\n",
    "- **F1-Score** = 2 × (Precision × Recall) / (Precision + Recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f31592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge_1(generated_summary, reference_summary):\n",
    "    \"\"\"\n",
    "    Tính ROUGE-1 (unigram overlap) - viết tay công thức\n",
    "    \"\"\"\n",
    "    # Tách từ và làm sạch\n",
    "    gen_words = re.findall(r'\\b\\w+\\b', generated_summary.lower())\n",
    "    ref_words = re.findall(r'\\b\\w+\\b', reference_summary.lower())\n",
    "    \n",
    "    # Đếm từ\n",
    "    gen_word_count = Counter(gen_words)\n",
    "    ref_word_count = Counter(ref_words)\n",
    "    \n",
    "    # Tính overlap\n",
    "    overlap = 0\n",
    "    for word in gen_word_count:\n",
    "        if word in ref_word_count:\n",
    "            overlap += min(gen_word_count[word], ref_word_count[word])\n",
    "    \n",
    "    # Tính precision, recall, f1\n",
    "    precision = overlap / len(gen_words) if len(gen_words) > 0 else 0\n",
    "    recall = overlap / len(ref_words) if len(ref_words) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'overlap': overlap,\n",
    "        'gen_length': len(gen_words),\n",
    "        'ref_length': len(ref_words)\n",
    "    }\n",
    "\n",
    "def calculate_rouge_2(generated_summary, reference_summary):\n",
    "    \"\"\"\n",
    "    Tính ROUGE-2 (bigram overlap) - viết tay công thức\n",
    "    \"\"\"\n",
    "    # Tách từ\n",
    "    gen_words = re.findall(r'\\b\\w+\\b', generated_summary.lower())\n",
    "    ref_words = re.findall(r'\\b\\w+\\b', reference_summary.lower())\n",
    "    \n",
    "    # Tạo bigrams\n",
    "    gen_bigrams = []\n",
    "    for i in range(len(gen_words) - 1):\n",
    "        gen_bigrams.append((gen_words[i], gen_words[i+1]))\n",
    "    \n",
    "    ref_bigrams = []\n",
    "    for i in range(len(ref_words) - 1):\n",
    "        ref_bigrams.append((ref_words[i], ref_words[i+1]))\n",
    "    \n",
    "    # Đếm bigrams\n",
    "    gen_bigram_count = Counter(gen_bigrams)\n",
    "    ref_bigram_count = Counter(ref_bigrams)\n",
    "    \n",
    "    # Tính overlap\n",
    "    overlap = 0\n",
    "    for bigram in gen_bigram_count:\n",
    "        if bigram in ref_bigram_count:\n",
    "            overlap += min(gen_bigram_count[bigram], ref_bigram_count[bigram])\n",
    "    \n",
    "    # Tính precision, recall, f1\n",
    "    precision = overlap / len(gen_bigrams) if len(gen_bigrams) > 0 else 0\n",
    "    recall = overlap / len(ref_bigrams) if len(ref_bigrams) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'overlap': overlap,\n",
    "        'gen_length': len(gen_bigrams),\n",
    "        'ref_length': len(ref_bigrams)\n",
    "    }\n",
    "\n",
    "def calculate_lcs_length(seq1, seq2):\n",
    "    \"\"\"\n",
    "    Tính độ dài Longest Common Subsequence - viết tay bằng dynamic programming\n",
    "    \"\"\"\n",
    "    m, n = len(seq1), len(seq2)\n",
    "    \n",
    "    # Tạo bảng DP\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    \n",
    "    # Fill bảng DP\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if seq1[i-1] == seq2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
    "    \n",
    "    return dp[m][n]\n",
    "\n",
    "def calculate_rouge_l(generated_summary, reference_summary):\n",
    "    \"\"\"\n",
    "    Tính ROUGE-L (LCS-based) - viết tay công thức\n",
    "    \"\"\"\n",
    "    # Tách từ\n",
    "    gen_words = re.findall(r'\\b\\w+\\b', generated_summary.lower())\n",
    "    ref_words = re.findall(r'\\b\\w+\\b', reference_summary.lower())\n",
    "    \n",
    "    # Tính LCS\n",
    "    lcs_length = calculate_lcs_length(gen_words, ref_words)\n",
    "    \n",
    "    # Tính precision, recall, f1\n",
    "    precision = lcs_length / len(gen_words) if len(gen_words) > 0 else 0\n",
    "    recall = lcs_length / len(ref_words) if len(ref_words) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'lcs_length': lcs_length,\n",
    "        'gen_length': len(gen_words),\n",
    "        'ref_length': len(ref_words)\n",
    "    }\n",
    "\n",
    "def evaluate_summary(generated_summary, reference_summary):\n",
    "    \"\"\"\n",
    "    Đánh giá toàn diện bằng ROUGE metrics\n",
    "    \"\"\"\n",
    "    print(\"Đang đánh giá bằng ROUGE metrics...\")\n",
    "    \n",
    "    # Tính các ROUGE scores\n",
    "    rouge_1 = calculate_rouge_1(generated_summary, reference_summary)\n",
    "    rouge_2 = calculate_rouge_2(generated_summary, reference_summary)\n",
    "    rouge_l = calculate_rouge_l(generated_summary, reference_summary)\n",
    "    \n",
    "    # Hiển thị kết quả\n",
    "    print(f\"\\nKẾT QUẢ ĐÁNH GIÁ ROUGE:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nROUGE-1 (Unigram Overlap):\")\n",
    "    print(f\"   Precision: {rouge_1['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {rouge_1['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {rouge_1['f1']:.4f}\")\n",
    "    print(f\"   Overlap:   {rouge_1['overlap']}/{rouge_1['gen_length']} vs {rouge_1['ref_length']} words\")\n",
    "    \n",
    "    print(f\"\\nROUGE-2 (Bigram Overlap):\")\n",
    "    print(f\"   Precision: {rouge_2['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {rouge_2['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {rouge_2['f1']:.4f}\")\n",
    "    print(f\"   Overlap:   {rouge_2['overlap']}/{rouge_2['gen_length']} vs {rouge_2['ref_length']} bigrams\")\n",
    "    \n",
    "    print(f\"\\nROUGE-L (LCS-based):\")\n",
    "    print(f\"   Precision: {rouge_l['precision']:.4f}\")\n",
    "    print(f\"   Recall:    {rouge_l['recall']:.4f}\")\n",
    "    print(f\"   F1-Score:  {rouge_l['f1']:.4f}\")\n",
    "    print(f\"   LCS:       {rouge_l['lcs_length']}/{rouge_l['gen_length']} vs {rouge_l['ref_length']} words\")\n",
    "    \n",
    "    # Tính điểm tổng hợp\n",
    "    overall_f1 = (rouge_1['f1'] + rouge_2['f1'] + rouge_l['f1']) / 3\n",
    "    print(f\"\\nĐIỂM TỔNG HỢP:\")\n",
    "    print(f\"   Overall F1-Score: {overall_f1:.4f}\")\n",
    "    \n",
    "    # Đánh giá chất lượng\n",
    "    if overall_f1 >= 0.5:\n",
    "        quality = \"Xuất sắc\"\n",
    "    elif overall_f1 >= 0.3:\n",
    "        quality = \"Tốt\"\n",
    "    elif overall_f1 >= 0.2:\n",
    "        quality = \"Khá\"\n",
    "    elif overall_f1 >= 0.1:\n",
    "        quality = \"Trung bình\"\n",
    "    else:\n",
    "        quality = \"Cần cải thiện\"\n",
    "    \n",
    "    print(f\"   Chất lượng tóm tắt: {quality}\")\n",
    "    \n",
    "    return {\n",
    "        'rouge_1': rouge_1,\n",
    "        'rouge_2': rouge_2,\n",
    "        'rouge_l': rouge_l,\n",
    "        'overall_f1': overall_f1,\n",
    "        'quality': quality\n",
    "    }\n",
    "\n",
    "print(\"✓ Đã thêm các phương thức đánh giá ROUGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeff4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Đánh giá tóm tắt bằng ROUGE\n",
    "if 'summary' in locals() and summary and 'duc_reference' in locals() and duc_reference:\n",
    "    print(\"Bắt đầu đánh giá so sánh...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Hiển thị hai văn bản cần so sánh\n",
    "    print(\"Generated Summary:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(summary['text'][:300] + \"...\" if len(summary['text']) > 300 else summary['text'])\n",
    "    \n",
    "    print(f\"\\nDUC Reference Summary:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(duc_reference[:300] + \"...\" if len(duc_reference) > 300 else duc_reference)\n",
    "    \n",
    "    # Đánh giá ROUGE\n",
    "    evaluation_results = evaluate_summary(summary['text'], duc_reference)\n",
    "    \n",
    "    # Demo: Minh họa cách tính ROUGE-1 chi tiết\n",
    "    print(f\"\\nDEMO: Minh họa cách tính ROUGE-1\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    gen_words = re.findall(r'\\b\\w+\\b', summary['text'].lower())\n",
    "    ref_words = re.findall(r'\\b\\w+\\b', duc_reference.lower())\n",
    "    \n",
    "    print(f\"Generated words: {len(gen_words)} từ\")\n",
    "    print(f\"Reference words: {len(ref_words)} từ\")\n",
    "    print(f\"Từ chung (overlap): {evaluation_results['rouge_1']['overlap']} từ\")\n",
    "    \n",
    "    print(f\"\\nCông thức ROUGE-1:\")\n",
    "    print(f\"Precision = overlap / gen_length = {evaluation_results['rouge_1']['overlap']} / {len(gen_words)} = {evaluation_results['rouge_1']['precision']:.4f}\")\n",
    "    print(f\"Recall = overlap / ref_length = {evaluation_results['rouge_1']['overlap']} / {len(ref_words)} = {evaluation_results['rouge_1']['recall']:.4f}\")\n",
    "    print(f\"F1 = 2 × P × R / (P + R) = {evaluation_results['rouge_1']['f1']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nBước 9 hoàn thành: Đã đánh giá tóm tắt bằng ROUGE metrics\")\n",
    "    \n",
    "elif 'summary' not in locals() or not summary:\n",
    "    print(\"Chưa có bản tóm tắt để đánh giá\")\n",
    "elif 'duc_reference' not in locals() or not duc_reference:\n",
    "    print(\"Chưa có DUC reference để so sánh\")\n",
    "else:\n",
    "    print(\"Thiếu dữ liệu để đánh giá\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
